{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f34da127-daae-4837-9d81-8ab8fcd71dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"net_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_9 (Sequential)   (None, 32, 32, 64)        1984      \n",
      "                                                                 \n",
      " sequential_10 (Sequential)  (None, 32, 32, 128)       74240     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " residual_block_2 (ResidualB  multiple                 579840    \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " sequential_14 (Sequential)  (None, 16, 16, 256)       443392    \n",
      "                                                                 \n",
      " sequential_15 (Sequential)  (None, 8, 8, 384)         886272    \n",
      "                                                                 \n",
      " residual_block_3 (ResidualB  multiple                 2657280   \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " global_average_pooling2d_1   multiple                 0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  3850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,646,858\n",
      "Trainable params: 4,642,506\n",
      "Non-trainable params: 4,352\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def ConvBNReLU(filters, kernel_size=3, strides=1, padding='same', use_bias=False):\n",
    "    \"\"\"Creates a Sequential model with Conv2D, BatchNormalization, and ReLU layers.\"\"\"\n",
    "    return models.Sequential([\n",
    "        layers.Conv2D(filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ReLU()\n",
    "    ])\n",
    "\n",
    "class ResidualBlock(models.Model):\n",
    "    def __init__(self, in_channels, out_channels, strides=1):\n",
    "        super().__init__()\n",
    "        self.conv_res1 = ConvBNReLU(out_channels, strides=strides)\n",
    "        self.conv_res2 = ConvBNReLU(out_channels)\n",
    "        self.downsample = models.Sequential([\n",
    "            layers.Conv2D(out_channels, 1, strides=strides, use_bias=False),\n",
    "            layers.BatchNormalization()\n",
    "        ]) if strides != 1 or in_channels != out_channels else lambda x: x\n",
    "\n",
    "    def call(self, inputs):\n",
    "        residual = self.downsample(inputs)\n",
    "        out = self.conv_res1(inputs)\n",
    "        out = self.conv_res2(out)\n",
    "        out += residual\n",
    "        return layers.ReLU()(out)\n",
    "\n",
    "class Net(models.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = ConvBNReLU(64)\n",
    "        self.conv2 = ConvBNReLU(128)\n",
    "        self.pool = layers.MaxPooling2D(pool_size=2, strides=2)\n",
    "        self.res_block1 = ResidualBlock(128, 192)\n",
    "        self.conv3 = ConvBNReLU(256)\n",
    "        self.conv4 = ConvBNReLU(384)\n",
    "        self.res_block2 = ResidualBlock(384, 384)\n",
    "        self.gap = layers.GlobalAveragePooling2D()\n",
    "        self.fc = layers.Dense(10, activation='softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.res_block1(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.res_block2(x)\n",
    "        x = self.gap(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Create and build the model\n",
    "model = Net()\n",
    "model.build(input_shape=(None, 32, 32, 3))\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e44bf17-879a-450f-bfd9-5fe25e6c2776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize the images\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train, y_test = to_categorical(y_train, 10), to_categorical(y_test, 10)\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create an array of shuffled indices\n",
    "shuffled_indices = np.arange(x_train.shape[0])\n",
    "np.random.shuffle(shuffled_indices)\n",
    "\n",
    "# Shuffle x_train and y_train using the shuffled indices\n",
    "x_train = x_train[shuffled_indices]\n",
    "y_train = y_train[shuffled_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbb4a396-3799-4401-a798-af41461c0506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageEnhance, ImageOps\n",
    "import random\n",
    "\n",
    "class ShearX(object):\n",
    "    def __init__(self, fillcolor=(128, 128, 128)):\n",
    "        self.fillcolor = fillcolor\n",
    "\n",
    "    def __call__(self, x, magnitude):\n",
    "        return x.transform(\n",
    "            x.size, Image.AFFINE, (1, magnitude * random.choice([-1, 1]), 0, 0, 1, 0),\n",
    "            Image.BICUBIC, fillcolor=self.fillcolor)\n",
    "\n",
    "\n",
    "class ShearY(object):\n",
    "    def __init__(self, fillcolor=(128, 128, 128)):\n",
    "        self.fillcolor = fillcolor\n",
    "\n",
    "    def __call__(self, x, magnitude):\n",
    "        return x.transform(\n",
    "            x.size, Image.AFFINE, (1, 0, 0, magnitude * random.choice([-1, 1]), 1, 0),\n",
    "            Image.BICUBIC, fillcolor=self.fillcolor)\n",
    "\n",
    "\n",
    "class TranslateX(object):\n",
    "    def __init__(self, fillcolor=(128, 128, 128)):\n",
    "        self.fillcolor = fillcolor\n",
    "\n",
    "    def __call__(self, x, magnitude):\n",
    "        return x.transform(\n",
    "            x.size, Image.AFFINE, (1, 0, magnitude * x.size[0] * random.choice([-1, 1]), 0, 1, 0),\n",
    "            fillcolor=self.fillcolor)\n",
    "\n",
    "\n",
    "class TranslateY(object):\n",
    "    def __init__(self, fillcolor=(128, 128, 128)):\n",
    "        self.fillcolor = fillcolor\n",
    "\n",
    "    def __call__(self, x, magnitude):\n",
    "        return x.transform(\n",
    "            x.size, Image.AFFINE, (1, 0, 0, 0, 1, magnitude * x.size[1] * random.choice([-1, 1])),\n",
    "            fillcolor=self.fillcolor)\n",
    "\n",
    "\n",
    "class Rotate(object):\n",
    "    # from https://stackoverflow.com/questions/\n",
    "    # 5252170/specify-image-filling-color-when-rotating-in-python-with-pil-and-setting-expand\n",
    "    def __call__(self, x, magnitude):\n",
    "        rot = x.convert(\"RGBA\").rotate(magnitude * random.choice([-1, 1]))\n",
    "        return Image.composite(rot, Image.new(\"RGBA\", rot.size, (128,) * 4), rot).convert(x.mode)\n",
    "\n",
    "\n",
    "class Color(object):\n",
    "    def __call__(self, x, magnitude):\n",
    "        return ImageEnhance.Color(x).enhance(1 + magnitude * random.choice([-1, 1]))\n",
    "\n",
    "\n",
    "class Posterize(object):\n",
    "    def __call__(self, x, magnitude):\n",
    "        return ImageOps.posterize(x, magnitude)\n",
    "\n",
    "\n",
    "class Solarize(object):\n",
    "    def __call__(self, x, magnitude):\n",
    "        return ImageOps.solarize(x, magnitude)\n",
    "\n",
    "\n",
    "class Contrast(object):\n",
    "    def __call__(self, x, magnitude):\n",
    "        return ImageEnhance.Contrast(x).enhance(1 + magnitude * random.choice([-1, 1]))\n",
    "\n",
    "\n",
    "class Sharpness(object):\n",
    "    def __call__(self, x, magnitude):\n",
    "        return ImageEnhance.Sharpness(x).enhance(1 + magnitude * random.choice([-1, 1]))\n",
    "\n",
    "\n",
    "class Brightness(object):\n",
    "    def __call__(self, x, magnitude):\n",
    "        return ImageEnhance.Brightness(x).enhance(1 + magnitude * random.choice([-1, 1]))\n",
    "\n",
    "\n",
    "class AutoContrast(object):\n",
    "    def __call__(self, x, magnitude):\n",
    "        return ImageOps.autocontrast(x)\n",
    "\n",
    "\n",
    "class Equalize(object):\n",
    "    def __call__(self, x, magnitude):\n",
    "        return ImageOps.equalize(x)\n",
    "\n",
    "\n",
    "class Invert(object):\n",
    "    def __call__(self, x, magnitude):\n",
    "        return ImageOps.invert(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f4e12a5-2826-4f87-88a0-e57eb0b18a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10Policy(object):\n",
    "    \"\"\" Randomly choose one of the best 25 Sub-policies on CIFAR10.\n",
    "\n",
    "        Example:\n",
    "        >>> policy = CIFAR10Policy()\n",
    "        >>> transformed = policy(image)\n",
    "\n",
    "        Example as a PyTorch Transform:\n",
    "        >>> transform=transforms.Compose([\n",
    "        >>>     transforms.Resize(256),\n",
    "        >>>     CIFAR10Policy(),\n",
    "        >>>     transforms.ToTensor()])\n",
    "    \"\"\"\n",
    "    def __init__(self, fillcolor=(128, 128, 128)):\n",
    "        self.policies = [\n",
    "            SubPolicy(0.1, \"invert\", 7, 0.2, \"contrast\", 6, fillcolor),\n",
    "            SubPolicy(0.7, \"rotate\", 2, 0.3, \"translateX\", 9, fillcolor),\n",
    "            SubPolicy(0.8, \"sharpness\", 1, 0.9, \"sharpness\", 3, fillcolor),\n",
    "            SubPolicy(0.5, \"shearY\", 8, 0.7, \"translateY\", 9, fillcolor),\n",
    "            SubPolicy(0.5, \"autocontrast\", 8, 0.9, \"equalize\", 2, fillcolor),\n",
    "\n",
    "            SubPolicy(0.2, \"shearY\", 7, 0.3, \"posterize\", 7, fillcolor),\n",
    "            SubPolicy(0.4, \"color\", 3, 0.6, \"brightness\", 7, fillcolor),\n",
    "            SubPolicy(0.3, \"sharpness\", 9, 0.7, \"brightness\", 9, fillcolor),\n",
    "            SubPolicy(0.6, \"equalize\", 5, 0.5, \"equalize\", 1, fillcolor),\n",
    "            SubPolicy(0.6, \"contrast\", 7, 0.6, \"sharpness\", 5, fillcolor),\n",
    "\n",
    "            SubPolicy(0.7, \"color\", 7, 0.5, \"translateX\", 8, fillcolor),\n",
    "            SubPolicy(0.3, \"equalize\", 7, 0.4, \"autocontrast\", 8, fillcolor),\n",
    "            SubPolicy(0.4, \"translateY\", 3, 0.2, \"sharpness\", 6, fillcolor),\n",
    "            SubPolicy(0.9, \"brightness\", 6, 0.2, \"color\", 8, fillcolor),\n",
    "            SubPolicy(0.5, \"solarize\", 2, 0.0, \"invert\", 3, fillcolor),\n",
    "\n",
    "            SubPolicy(0.2, \"equalize\", 0, 0.6, \"autocontrast\", 0, fillcolor),\n",
    "            SubPolicy(0.2, \"equalize\", 8, 0.6, \"equalize\", 4, fillcolor),\n",
    "            SubPolicy(0.9, \"color\", 9, 0.6, \"equalize\", 6, fillcolor),\n",
    "            SubPolicy(0.8, \"autocontrast\", 4, 0.2, \"solarize\", 8, fillcolor),\n",
    "            SubPolicy(0.1, \"brightness\", 3, 0.7, \"color\", 0, fillcolor),\n",
    "\n",
    "            SubPolicy(0.4, \"solarize\", 5, 0.9, \"autocontrast\", 3, fillcolor),\n",
    "            SubPolicy(0.9, \"translateY\", 9, 0.7, \"translateY\", 9, fillcolor),\n",
    "            SubPolicy(0.9, \"autocontrast\", 2, 0.8, \"solarize\", 3, fillcolor),\n",
    "            SubPolicy(0.8, \"equalize\", 8, 0.1, \"invert\", 3, fillcolor),\n",
    "            SubPolicy(0.7, \"translateY\", 9, 0.9, \"autocontrast\", 1, fillcolor)\n",
    "        ]\n",
    "\n",
    "    def __call__(self, img):\n",
    "        policy_idx = random.randint(0, len(self.policies) - 1)\n",
    "        return self.policies[policy_idx](img)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"AutoAugment CIFAR10 Policy\"\n",
    "\n",
    "class SubPolicy(object):\n",
    "    def __init__(self, p1, operation1, magnitude_idx1, p2, operation2, magnitude_idx2, fillcolor=(128, 128, 128)):\n",
    "        ranges = {\n",
    "            \"shearX\": np.linspace(0, 0.3, 10),\n",
    "            \"shearY\": np.linspace(0, 0.3, 10),\n",
    "            \"translateX\": np.linspace(0, 150 / 331, 10),\n",
    "            \"translateY\": np.linspace(0, 150 / 331, 10),\n",
    "            \"rotate\": np.linspace(0, 30, 10),\n",
    "            \"color\": np.linspace(0.0, 0.9, 10),\n",
    "            \"posterize\": np.round(np.linspace(8, 4, 10), 0).astype(int),\n",
    "            \"solarize\": np.linspace(256, 0, 10),\n",
    "            \"contrast\": np.linspace(0.0, 0.9, 10),\n",
    "            \"sharpness\": np.linspace(0.0, 0.9, 10),\n",
    "            \"brightness\": np.linspace(0.0, 0.9, 10),\n",
    "            \"autocontrast\": [0] * 10,\n",
    "            \"equalize\": [0] * 10,\n",
    "            \"invert\": [0] * 10\n",
    "        }\n",
    "\n",
    "        func = {\n",
    "            \"shearX\": ShearX(fillcolor=fillcolor),\n",
    "            \"shearY\": ShearY(fillcolor=fillcolor),\n",
    "            \"translateX\": TranslateX(fillcolor=fillcolor),\n",
    "            \"translateY\": TranslateY(fillcolor=fillcolor),\n",
    "            \"rotate\": Rotate(),\n",
    "            \"color\": Color(),\n",
    "            \"posterize\": Posterize(),\n",
    "            \"solarize\": Solarize(),\n",
    "            \"contrast\": Contrast(),\n",
    "            \"sharpness\": Sharpness(),\n",
    "            \"brightness\": Brightness(),\n",
    "            \"autocontrast\": AutoContrast(),\n",
    "            \"equalize\": Equalize(),\n",
    "            \"invert\": Invert()\n",
    "        }\n",
    "\n",
    "        self.p1 = p1\n",
    "        self.operation1 = func[operation1]\n",
    "        self.magnitude1 = ranges[operation1][magnitude_idx1]\n",
    "        self.p2 = p2\n",
    "        self.operation2 = func[operation2]\n",
    "        self.magnitude2 = ranges[operation2][magnitude_idx2]\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.p1:\n",
    "            img = self.operation1(img, self.magnitude1)\n",
    "        if random.random() < self.p2:\n",
    "            img = self.operation2(img, self.magnitude2)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d772f2b-ff8b-4f83-babe-83aa97880269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_cutout(image, num_holes=1, max_h_size=8, max_w_size=8):\n",
    "    \"\"\"Applies Cutout augmentation to a single image.\"\"\"\n",
    "    # Convert PIL Image to numpy array\n",
    "    image_np = np.array(image)\n",
    "    \n",
    "    h, w = image_np.shape[:2]\n",
    "    mask = np.ones((h, w), np.float32)\n",
    "\n",
    "    for _ in range(num_holes):\n",
    "        y = np.random.randint(h)\n",
    "        x = np.random.randint(w)\n",
    "        \n",
    "        y1 = np.clip(y - max_h_size // 2, 0, h)\n",
    "        y2 = np.clip(y + max_h_size // 2, 0, h)\n",
    "        x1 = np.clip(x - max_w_size // 2, 0, w)\n",
    "        x2 = np.clip(x + max_w_size // 2, 0, w)\n",
    "\n",
    "        mask[y1: y2, x1: x2] = 0.\n",
    "\n",
    "    # Apply mask\n",
    "    image_np = image_np * mask[:, :, np.newaxis]\n",
    "\n",
    "    # Convert back to PIL Image\n",
    "    return Image.fromarray(image_np.astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d57cc6e-431f-4d2a-be3e-1b5fcd92f7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_image(image, pad_size=4, fill=0, padding_mode='reflect'):\n",
    "    \"\"\"Pad the given PIL Image on all sides with the given pad_size.\"\"\"\n",
    "    return ImageOps.expand(image, border=pad_size, fill=fill)\n",
    "\n",
    "def random_crop(image, crop_size=(32, 32)):\n",
    "    \"\"\"Crop a random part of the image to the given size.\"\"\"\n",
    "    width, height = image.size\n",
    "    new_width, new_height = crop_size\n",
    "\n",
    "    left = np.random.randint(0, width - new_width + 1)\n",
    "    top = np.random.randint(0, height - new_height + 1)\n",
    "\n",
    "    image = image.crop((left, top, left + new_width, top + new_height))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "369811bb-bba5-4a1b-bfb3-cb17daa003ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_horizontal_flip(image, p=0.5):\n",
    "    \"\"\"Randomly flip the image horizontally with a probability of p.\"\"\"\n",
    "    if random.random() < p:\n",
    "        return image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    return image\n",
    "\n",
    "def random_rotation(image, max_angle=0):\n",
    "    \"\"\"Randomly rotate the image within a given angle range.\"\"\"\n",
    "    angle = random.uniform(-max_angle, max_angle)\n",
    "    return image.rotate(angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae91220d-df14-4c1c-87d1-8d1e8a1f6c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class CustomImageDataGenerator(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size=64, augmentations=None):\n",
    "        self.x_set = x_set\n",
    "        self.y_set = y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.augmentations = augmentations if augmentations else []\n",
    "\n",
    "    def __len__(self):\n",
    "        return np.ceil(len(self.x_set) / self.batch_size).astype(int)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x_set[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y_set[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        # Convert numpy arrays to PIL Images, apply augmentations, and convert back to numpy arrays\n",
    "        x_batch_aug = np.array([self.apply_augmentations(Image.fromarray((image * 255).astype('uint8'))) for image in batch_x])\n",
    "        \n",
    "        # Convert PIL Images back to numpy arrays and normalize to [0, 1]\n",
    "        x_batch_aug = np.array([np.array(image) for image in x_batch_aug]).astype('float32') / 255.0\n",
    "        \n",
    "        return x_batch_aug, batch_y\n",
    "\n",
    "    def apply_augmentations(self, image):\n",
    "        augmented_image = image\n",
    "        for augmentation in self.augmentations:\n",
    "            augmented_image = augmentation(augmented_image)\n",
    "        return augmented_image\n",
    "\n",
    "# Assuming CIFAR10Policy and apply_cutout are defined elsewhere\n",
    "custom_augmentations = [pad_image, random_crop, random_horizontal_flip, random_rotation, CIFAR10Policy(), apply_cutout]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e59a9ff0-5233-4b97-8663-6b5f26010374",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.05\n",
    "momentum = 0.9\n",
    "weight_decay = 0.0005\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(\n",
    "    learning_rate=lr, \n",
    "    momentum=momentum, \n",
    "    nesterov=True,\n",
    "    decay=weight_decay\n",
    ")\n",
    "\n",
    "# Compile the model with the updated learning_rate parameter\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "715d317d-b5f2-4b3e-9f70-aaabb2249b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "390/390 [==============================] - ETA: 0s - loss: 2.3223 - accuracy: 0.2264\n",
      "Epoch 1: val_accuracy improved from -inf to 0.22360, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 41s 81ms/step - loss: 2.3223 - accuracy: 0.2264 - val_loss: 3.1475 - val_accuracy: 0.2236\n",
      "Epoch 2/250\n",
      "390/390 [==============================] - ETA: 0s - loss: 1.7236 - accuracy: 0.3758\n",
      "Epoch 2: val_accuracy improved from 0.22360 to 0.29070, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 30s 78ms/step - loss: 1.7236 - accuracy: 0.3758 - val_loss: 2.4833 - val_accuracy: 0.2907\n",
      "Epoch 3/250\n",
      "390/390 [==============================] - ETA: 0s - loss: 1.4349 - accuracy: 0.4867\n",
      "Epoch 3: val_accuracy improved from 0.29070 to 0.58080, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 31s 78ms/step - loss: 1.4349 - accuracy: 0.4867 - val_loss: 1.1640 - val_accuracy: 0.5808\n",
      "Epoch 4/250\n",
      "390/390 [==============================] - ETA: 0s - loss: 1.2412 - accuracy: 0.5612\n",
      "Epoch 4: val_accuracy did not improve from 0.58080\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 1.2412 - accuracy: 0.5612 - val_loss: 1.2180 - val_accuracy: 0.5778\n",
      "Epoch 5/250\n",
      "390/390 [==============================] - ETA: 0s - loss: 1.1033 - accuracy: 0.6119\n",
      "Epoch 5: val_accuracy improved from 0.58080 to 0.68010, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 31s 80ms/step - loss: 1.1033 - accuracy: 0.6119 - val_loss: 0.8939 - val_accuracy: 0.6801\n",
      "Epoch 6/250\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.9909 - accuracy: 0.6510\n",
      "Epoch 6: val_accuracy improved from 0.68010 to 0.72990, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 32s 83ms/step - loss: 0.9909 - accuracy: 0.6510 - val_loss: 0.7806 - val_accuracy: 0.7299\n",
      "Epoch 7/250\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.9106 - accuracy: 0.6822\n",
      "Epoch 7: val_accuracy did not improve from 0.72990\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.9106 - accuracy: 0.6822 - val_loss: 0.8069 - val_accuracy: 0.7204\n",
      "Epoch 8/250\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.8482 - accuracy: 0.7036\n",
      "Epoch 8: val_accuracy improved from 0.72990 to 0.74860, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 31s 80ms/step - loss: 0.8482 - accuracy: 0.7036 - val_loss: 0.7872 - val_accuracy: 0.7486\n",
      "Epoch 9/250\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.7996 - accuracy: 0.7211\n",
      "Epoch 9: val_accuracy improved from 0.74860 to 0.79650, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 30s 76ms/step - loss: 0.7996 - accuracy: 0.7211 - val_loss: 0.6012 - val_accuracy: 0.7965\n",
      "Epoch 10/250\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.7601 - accuracy: 0.7341\n",
      "Epoch 10: val_accuracy did not improve from 0.79650\n",
      "390/390 [==============================] - 27s 70ms/step - loss: 0.7601 - accuracy: 0.7341 - val_loss: 0.7210 - val_accuracy: 0.7603\n",
      "Epoch 11/250\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.7246 - accuracy: 0.7489\n",
      "Epoch 11: val_accuracy improved from 0.79650 to 0.81050, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 33s 83ms/step - loss: 0.7246 - accuracy: 0.7489 - val_loss: 0.5454 - val_accuracy: 0.8105\n",
      "Epoch 12/250\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.6896 - accuracy: 0.7585\n",
      "Epoch 12: val_accuracy did not improve from 0.81050\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.6896 - accuracy: 0.7585 - val_loss: 0.6031 - val_accuracy: 0.8031\n",
      "Epoch 13/250\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.6589 - accuracy: 0.7680\n",
      "Epoch 13: val_accuracy did not improve from 0.81050\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.6589 - accuracy: 0.7680 - val_loss: 0.5811 - val_accuracy: 0.8037\n",
      "Epoch 14/250\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.6376 - accuracy: 0.7755\n",
      "Epoch 14: val_accuracy improved from 0.81050 to 0.83200, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 35s 90ms/step - loss: 0.6376 - accuracy: 0.7755 - val_loss: 0.4877 - val_accuracy: 0.8320\n",
      "Epoch 15/250\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.6113 - accuracy: 0.7881\n",
      "Epoch 15: val_accuracy improved from 0.83200 to 0.83950, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 34s 87ms/step - loss: 0.6113 - accuracy: 0.7881 - val_loss: 0.4694 - val_accuracy: 0.8395\n",
      "Epoch 16/250\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.5994 - accuracy: 0.7906\n",
      "Epoch 16: val_accuracy did not improve from 0.83950\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.5994 - accuracy: 0.7906 - val_loss: 0.5313 - val_accuracy: 0.8261\n",
      "Epoch 17/250\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.5763 - accuracy: 0.7974\n",
      "Epoch 17: val_accuracy did not improve from 0.83950\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.5763 - accuracy: 0.7974 - val_loss: 0.4874 - val_accuracy: 0.8380\n",
      "Epoch 18/250\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.5646 - accuracy: 0.8033\n",
      "Epoch 18: val_accuracy improved from 0.83950 to 0.86500, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 34s 86ms/step - loss: 0.5646 - accuracy: 0.8033 - val_loss: 0.4010 - val_accuracy: 0.8650\n",
      "Epoch 19/250\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.5451 - accuracy: 0.8096\n",
      "Epoch 19: val_accuracy did not improve from 0.86500\n",
      "390/390 [==============================] - 32s 82ms/step - loss: 0.5451 - accuracy: 0.8096 - val_loss: 0.4025 - val_accuracy: 0.8636\n",
      "Epoch 20/250\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.5336 - accuracy: 0.8131\n",
      "Epoch 20: val_accuracy improved from 0.86500 to 0.86930, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 36s 91ms/step - loss: 0.5336 - accuracy: 0.8131 - val_loss: 0.4016 - val_accuracy: 0.8693\n",
      "Epoch 21/250\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.5177 - accuracy: 0.8179\n",
      "Epoch 21: val_accuracy did not improve from 0.86930\n",
      "390/390 [==============================] - 31s 78ms/step - loss: 0.5177 - accuracy: 0.8179 - val_loss: 0.4076 - val_accuracy: 0.8665\n",
      "Epoch 22/250\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.5089 - accuracy: 0.8223\n",
      "Epoch 22: val_accuracy did not improve from 0.86930\n",
      "390/390 [==============================] - 32s 82ms/step - loss: 0.5089 - accuracy: 0.8223 - val_loss: 0.4418 - val_accuracy: 0.8533\n",
      "Epoch 23/250\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4964 - accuracy: 0.8266\n",
      "Epoch 23: val_accuracy did not improve from 0.86930\n",
      "390/390 [==============================] - 32s 82ms/step - loss: 0.4964 - accuracy: 0.8266 - val_loss: 0.4455 - val_accuracy: 0.8548\n",
      "Epoch 24/250\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4930 - accuracy: 0.8258\n",
      "Epoch 24: val_accuracy improved from 0.86930 to 0.86950, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 35s 89ms/step - loss: 0.4930 - accuracy: 0.8258 - val_loss: 0.3946 - val_accuracy: 0.8695\n",
      "Epoch 25/250\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4792 - accuracy: 0.8304\n",
      "Epoch 25: val_accuracy improved from 0.86950 to 0.87510, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 35s 89ms/step - loss: 0.4792 - accuracy: 0.8304 - val_loss: 0.3738 - val_accuracy: 0.8751\n",
      "Epoch 26/250\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4635 - accuracy: 0.8369\n",
      "Epoch 26: val_accuracy did not improve from 0.87510\n",
      "390/390 [==============================] - 32s 83ms/step - loss: 0.4635 - accuracy: 0.8369 - val_loss: 0.4141 - val_accuracy: 0.8683\n",
      "Epoch 27/250\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4599 - accuracy: 0.8371\n",
      "Epoch 27: val_accuracy did not improve from 0.87510\n",
      "390/390 [==============================] - 31s 79ms/step - loss: 0.4599 - accuracy: 0.8371 - val_loss: 0.3806 - val_accuracy: 0.8726\n",
      "Epoch 28/250\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4447 - accuracy: 0.8429\n",
      "Epoch 28: val_accuracy did not improve from 0.87510\n",
      "390/390 [==============================] - 32s 82ms/step - loss: 0.4447 - accuracy: 0.8429 - val_loss: 0.4340 - val_accuracy: 0.8534\n",
      "Epoch 29/250\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4396 - accuracy: 0.8455\n",
      "Epoch 29: val_accuracy did not improve from 0.87510\n",
      "390/390 [==============================] - 32s 83ms/step - loss: 0.4396 - accuracy: 0.8455 - val_loss: 0.3805 - val_accuracy: 0.8715\n",
      "Epoch 30/250\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4345 - accuracy: 0.8463\n",
      "Epoch 30: val_accuracy improved from 0.87510 to 0.88390, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 33s 85ms/step - loss: 0.4345 - accuracy: 0.8463 - val_loss: 0.3520 - val_accuracy: 0.8839\n",
      "Epoch 31/250\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4231 - accuracy: 0.8519\n",
      "Epoch 31: val_accuracy did not improve from 0.88390\n",
      "390/390 [==============================] - 27s 69ms/step - loss: 0.4231 - accuracy: 0.8519 - val_loss: 0.3979 - val_accuracy: 0.8746\n",
      "Epoch 32/250\n",
      " 17/390 [>.............................] - ETA: 24s - loss: 0.3809 - accuracy: 0.8727"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m custom_data_generator \u001b[38;5;241m=\u001b[39m CustomImageDataGenerator(x_train, y_train, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, augmentations\u001b[38;5;241m=\u001b[39mcustom_augmentations)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Train the model using the custom data generator\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcustom_data_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\engine\\training.py:1570\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1568\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[0;32m   1569\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[1;32m-> 1570\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m   1572\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\callbacks.py:470\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 470\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\callbacks.py:317\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 317\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\callbacks.py:340\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    337\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    343\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\callbacks.py:388\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m    387\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 388\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\callbacks.py:1081\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1081\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\callbacks.py:1157\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1156\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\utils\\tf_utils.py:635\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m--> 635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\utils\\tf_utils.py:628\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m--> 628\u001b[0m         t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;66;03m# as-is.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1122\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1124\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define the ModelCheckpoint callback to save the model using the 'SavedModel' format\n",
    "checkpoint = ModelCheckpoint('best_model-r9', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max', save_format='tf')\n",
    "\n",
    "# Initialize the generator with the custom augmentations\n",
    "custom_data_generator = CustomImageDataGenerator(x_train, y_train, batch_size=128, augmentations=custom_augmentations)\n",
    "\n",
    "# Train the model using the custom data generator\n",
    "history = model.fit(custom_data_generator,\n",
    "                    steps_per_epoch=len(x_train) // 128,\n",
    "                    epochs=250, \n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[checkpoint])  # Include the checkpoint callback here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924ebe53-02de-4c46-a2b6-530104bc820a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38d18e6-2009-466f-8fca-06e56c431fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model-r9')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
