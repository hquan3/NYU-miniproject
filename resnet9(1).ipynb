{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f34da127-daae-4837-9d81-8ab8fcd71dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"net_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_36 (Sequential)  (None, 32, 32, 64)        1984      \n",
      "                                                                 \n",
      " sequential_37 (Sequential)  (None, 32, 32, 128)       74240     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " residual_block_8 (ResidualB  multiple                 295936    \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " sequential_40 (Sequential)  (None, 16, 16, 256)       295936    \n",
      "                                                                 \n",
      " sequential_41 (Sequential)  (None, 8, 8, 256)         590848    \n",
      "                                                                 \n",
      " residual_block_9 (ResidualB  multiple                 3676160   \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " global_average_pooling2d_4   multiple                 0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_4 (Dense)             multiple                  5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,940,234\n",
      "Trainable params: 4,935,242\n",
      "Non-trainable params: 4,992\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def ConvBNReLU(filters, kernel_size=3, strides=1, padding='same', use_bias=False):\n",
    "    \"\"\"Creates a Sequential model with Conv2D, BatchNormalization, and ReLU layers.\"\"\"\n",
    "    return models.Sequential([\n",
    "        layers.Conv2D(filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ReLU()\n",
    "    ])\n",
    "\n",
    "class ResidualBlock(models.Model):\n",
    "    def __init__(self, in_channels, out_channels, strides=1):\n",
    "        super().__init__()\n",
    "        self.conv_res1 = ConvBNReLU(out_channels, strides=strides)\n",
    "        self.conv_res2 = ConvBNReLU(out_channels)\n",
    "        self.downsample = models.Sequential([\n",
    "            layers.Conv2D(out_channels, 1, strides=strides, use_bias=False),\n",
    "            layers.BatchNormalization()\n",
    "        ]) if strides != 1 or in_channels != out_channels else lambda x: x\n",
    "\n",
    "    def call(self, inputs):\n",
    "        residual = self.downsample(inputs)\n",
    "        out = self.conv_res1(inputs)\n",
    "        out = self.conv_res2(out)\n",
    "        out += residual\n",
    "        return layers.ReLU()(out)\n",
    "\n",
    "class Net(models.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = ConvBNReLU(64)\n",
    "        self.conv2 = ConvBNReLU(128)\n",
    "        self.pool = layers.MaxPooling2D(pool_size=2, strides=2)\n",
    "        self.res_block1 = ResidualBlock(128, 128)\n",
    "        self.conv3 = ConvBNReLU(256)\n",
    "        self.conv4 = ConvBNReLU(256)\n",
    "        self.res_block2 = ResidualBlock(256, 512)\n",
    "        self.gap = layers.GlobalAveragePooling2D()\n",
    "        self.fc = layers.Dense(10, activation='softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.res_block1(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.res_block2(x)\n",
    "        x = self.gap(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Create and build the model\n",
    "model = Net()\n",
    "model.build(input_shape=(None, 32, 32, 3))\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5e44bf17-879a-450f-bfd9-5fe25e6c2776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize the images\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train, y_test = to_categorical(y_train, 10), to_categorical(y_test, 10)\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create an array of shuffled indices\n",
    "shuffled_indices = np.arange(x_train.shape[0])\n",
    "np.random.shuffle(shuffled_indices)\n",
    "\n",
    "# Shuffle x_train and y_train using the shuffled indices\n",
    "x_train = x_train[shuffled_indices]\n",
    "y_train = y_train[shuffled_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fbb4a396-3799-4401-a798-af41461c0506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageEnhance, ImageOps\n",
    "import random\n",
    "\n",
    "class ShearX(object):\n",
    "    def __init__(self, fillcolor=(128, 128, 128)):\n",
    "        self.fillcolor = fillcolor\n",
    "\n",
    "    def __call__(self, x, magnitude):\n",
    "        return x.transform(\n",
    "            x.size, Image.AFFINE, (1, magnitude * random.choice([-1, 1]), 0, 0, 1, 0),\n",
    "            Image.BICUBIC, fillcolor=self.fillcolor)\n",
    "\n",
    "\n",
    "class ShearY(object):\n",
    "    def __init__(self, fillcolor=(128, 128, 128)):\n",
    "        self.fillcolor = fillcolor\n",
    "\n",
    "    def __call__(self, x, magnitude):\n",
    "        return x.transform(\n",
    "            x.size, Image.AFFINE, (1, 0, 0, magnitude * random.choice([-1, 1]), 1, 0),\n",
    "            Image.BICUBIC, fillcolor=self.fillcolor)\n",
    "\n",
    "\n",
    "class TranslateX(object):\n",
    "    def __init__(self, fillcolor=(128, 128, 128)):\n",
    "        self.fillcolor = fillcolor\n",
    "\n",
    "    def __call__(self, x, magnitude):\n",
    "        return x.transform(\n",
    "            x.size, Image.AFFINE, (1, 0, magnitude * x.size[0] * random.choice([-1, 1]), 0, 1, 0),\n",
    "            fillcolor=self.fillcolor)\n",
    "\n",
    "\n",
    "class TranslateY(object):\n",
    "    def __init__(self, fillcolor=(128, 128, 128)):\n",
    "        self.fillcolor = fillcolor\n",
    "\n",
    "    def __call__(self, x, magnitude):\n",
    "        return x.transform(\n",
    "            x.size, Image.AFFINE, (1, 0, 0, 0, 1, magnitude * x.size[1] * random.choice([-1, 1])),\n",
    "            fillcolor=self.fillcolor)\n",
    "\n",
    "\n",
    "class Rotate(object):\n",
    "    # from https://stackoverflow.com/questions/\n",
    "    # 5252170/specify-image-filling-color-when-rotating-in-python-with-pil-and-setting-expand\n",
    "    def __call__(self, x, magnitude):\n",
    "        rot = x.convert(\"RGBA\").rotate(magnitude * random.choice([-1, 1]))\n",
    "        return Image.composite(rot, Image.new(\"RGBA\", rot.size, (128,) * 4), rot).convert(x.mode)\n",
    "\n",
    "\n",
    "class Color(object):\n",
    "    def __call__(self, x, magnitude):\n",
    "        return ImageEnhance.Color(x).enhance(1 + magnitude * random.choice([-1, 1]))\n",
    "\n",
    "\n",
    "class Posterize(object):\n",
    "    def __call__(self, x, magnitude):\n",
    "        return ImageOps.posterize(x, magnitude)\n",
    "\n",
    "\n",
    "class Solarize(object):\n",
    "    def __call__(self, x, magnitude):\n",
    "        return ImageOps.solarize(x, magnitude)\n",
    "\n",
    "\n",
    "class Contrast(object):\n",
    "    def __call__(self, x, magnitude):\n",
    "        return ImageEnhance.Contrast(x).enhance(1 + magnitude * random.choice([-1, 1]))\n",
    "\n",
    "\n",
    "class Sharpness(object):\n",
    "    def __call__(self, x, magnitude):\n",
    "        return ImageEnhance.Sharpness(x).enhance(1 + magnitude * random.choice([-1, 1]))\n",
    "\n",
    "\n",
    "class Brightness(object):\n",
    "    def __call__(self, x, magnitude):\n",
    "        return ImageEnhance.Brightness(x).enhance(1 + magnitude * random.choice([-1, 1]))\n",
    "\n",
    "\n",
    "class AutoContrast(object):\n",
    "    def __call__(self, x, magnitude):\n",
    "        return ImageOps.autocontrast(x)\n",
    "\n",
    "\n",
    "class Equalize(object):\n",
    "    def __call__(self, x, magnitude):\n",
    "        return ImageOps.equalize(x)\n",
    "\n",
    "\n",
    "class Invert(object):\n",
    "    def __call__(self, x, magnitude):\n",
    "        return ImageOps.invert(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4f4e12a5-2826-4f87-88a0-e57eb0b18a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10Policy(object):\n",
    "    \"\"\" Randomly choose one of the best 25 Sub-policies on CIFAR10.\n",
    "\n",
    "        Example:\n",
    "        >>> policy = CIFAR10Policy()\n",
    "        >>> transformed = policy(image)\n",
    "\n",
    "        Example as a PyTorch Transform:\n",
    "        >>> transform=transforms.Compose([\n",
    "        >>>     transforms.Resize(256),\n",
    "        >>>     CIFAR10Policy(),\n",
    "        >>>     transforms.ToTensor()])\n",
    "    \"\"\"\n",
    "    def __init__(self, fillcolor=(128, 128, 128)):\n",
    "        self.policies = [\n",
    "            SubPolicy(0.1, \"invert\", 7, 0.2, \"contrast\", 6, fillcolor),\n",
    "            SubPolicy(0.7, \"rotate\", 2, 0.3, \"translateX\", 9, fillcolor),\n",
    "            SubPolicy(0.8, \"sharpness\", 1, 0.9, \"sharpness\", 3, fillcolor),\n",
    "            SubPolicy(0.5, \"shearY\", 8, 0.7, \"translateY\", 9, fillcolor),\n",
    "            SubPolicy(0.5, \"autocontrast\", 8, 0.9, \"equalize\", 2, fillcolor),\n",
    "\n",
    "            SubPolicy(0.2, \"shearY\", 7, 0.3, \"posterize\", 7, fillcolor),\n",
    "            SubPolicy(0.4, \"color\", 3, 0.6, \"brightness\", 7, fillcolor),\n",
    "            SubPolicy(0.3, \"sharpness\", 9, 0.7, \"brightness\", 9, fillcolor),\n",
    "            SubPolicy(0.6, \"equalize\", 5, 0.5, \"equalize\", 1, fillcolor),\n",
    "            SubPolicy(0.6, \"contrast\", 7, 0.6, \"sharpness\", 5, fillcolor),\n",
    "\n",
    "            SubPolicy(0.7, \"color\", 7, 0.5, \"translateX\", 8, fillcolor),\n",
    "            SubPolicy(0.3, \"equalize\", 7, 0.4, \"autocontrast\", 8, fillcolor),\n",
    "            SubPolicy(0.4, \"translateY\", 3, 0.2, \"sharpness\", 6, fillcolor),\n",
    "            SubPolicy(0.9, \"brightness\", 6, 0.2, \"color\", 8, fillcolor),\n",
    "            SubPolicy(0.5, \"solarize\", 2, 0.0, \"invert\", 3, fillcolor),\n",
    "\n",
    "            SubPolicy(0.2, \"equalize\", 0, 0.6, \"autocontrast\", 0, fillcolor),\n",
    "            SubPolicy(0.2, \"equalize\", 8, 0.6, \"equalize\", 4, fillcolor),\n",
    "            SubPolicy(0.9, \"color\", 9, 0.6, \"equalize\", 6, fillcolor),\n",
    "            SubPolicy(0.8, \"autocontrast\", 4, 0.2, \"solarize\", 8, fillcolor),\n",
    "            SubPolicy(0.1, \"brightness\", 3, 0.7, \"color\", 0, fillcolor),\n",
    "\n",
    "            SubPolicy(0.4, \"solarize\", 5, 0.9, \"autocontrast\", 3, fillcolor),\n",
    "            SubPolicy(0.9, \"translateY\", 9, 0.7, \"translateY\", 9, fillcolor),\n",
    "            SubPolicy(0.9, \"autocontrast\", 2, 0.8, \"solarize\", 3, fillcolor),\n",
    "            SubPolicy(0.8, \"equalize\", 8, 0.1, \"invert\", 3, fillcolor),\n",
    "            SubPolicy(0.7, \"translateY\", 9, 0.9, \"autocontrast\", 1, fillcolor)\n",
    "        ]\n",
    "\n",
    "    def __call__(self, img):\n",
    "        policy_idx = random.randint(0, len(self.policies) - 1)\n",
    "        return self.policies[policy_idx](img)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"AutoAugment CIFAR10 Policy\"\n",
    "\n",
    "class SubPolicy(object):\n",
    "    def __init__(self, p1, operation1, magnitude_idx1, p2, operation2, magnitude_idx2, fillcolor=(128, 128, 128)):\n",
    "        ranges = {\n",
    "            \"shearX\": np.linspace(0, 0.3, 10),\n",
    "            \"shearY\": np.linspace(0, 0.3, 10),\n",
    "            \"translateX\": np.linspace(0, 150 / 331, 10),\n",
    "            \"translateY\": np.linspace(0, 150 / 331, 10),\n",
    "            \"rotate\": np.linspace(0, 30, 10),\n",
    "            \"color\": np.linspace(0.0, 0.9, 10),\n",
    "            \"posterize\": np.round(np.linspace(8, 4, 10), 0).astype(int),\n",
    "            \"solarize\": np.linspace(256, 0, 10),\n",
    "            \"contrast\": np.linspace(0.0, 0.9, 10),\n",
    "            \"sharpness\": np.linspace(0.0, 0.9, 10),\n",
    "            \"brightness\": np.linspace(0.0, 0.9, 10),\n",
    "            \"autocontrast\": [0] * 10,\n",
    "            \"equalize\": [0] * 10,\n",
    "            \"invert\": [0] * 10\n",
    "        }\n",
    "\n",
    "        func = {\n",
    "            \"shearX\": ShearX(fillcolor=fillcolor),\n",
    "            \"shearY\": ShearY(fillcolor=fillcolor),\n",
    "            \"translateX\": TranslateX(fillcolor=fillcolor),\n",
    "            \"translateY\": TranslateY(fillcolor=fillcolor),\n",
    "            \"rotate\": Rotate(),\n",
    "            \"color\": Color(),\n",
    "            \"posterize\": Posterize(),\n",
    "            \"solarize\": Solarize(),\n",
    "            \"contrast\": Contrast(),\n",
    "            \"sharpness\": Sharpness(),\n",
    "            \"brightness\": Brightness(),\n",
    "            \"autocontrast\": AutoContrast(),\n",
    "            \"equalize\": Equalize(),\n",
    "            \"invert\": Invert()\n",
    "        }\n",
    "\n",
    "        self.p1 = p1\n",
    "        self.operation1 = func[operation1]\n",
    "        self.magnitude1 = ranges[operation1][magnitude_idx1]\n",
    "        self.p2 = p2\n",
    "        self.operation2 = func[operation2]\n",
    "        self.magnitude2 = ranges[operation2][magnitude_idx2]\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.p1:\n",
    "            img = self.operation1(img, self.magnitude1)\n",
    "        if random.random() < self.p2:\n",
    "            img = self.operation2(img, self.magnitude2)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9d772f2b-ff8b-4f83-babe-83aa97880269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_cutout(image, num_holes=1, max_h_size=8, max_w_size=8):\n",
    "    \"\"\"Applies Cutout augmentation to a single image.\"\"\"\n",
    "\n",
    "    max_h_size = int(random.choice([1 + 0.1 * i for i in range(10)]) * max_h_size)\n",
    "    max_w_size = int(random.choice([1 + 0.1 * i for i in range(10)]) * max_w_size)\n",
    "    \n",
    "    # Convert PIL Image to numpy array\n",
    "    image_np = np.array(image)\n",
    "    \n",
    "    h, w = image_np.shape[:2]\n",
    "    mask = np.ones((h, w), np.float32)\n",
    "\n",
    "    for _ in range(num_holes):\n",
    "        y = np.random.randint(h)\n",
    "        x = np.random.randint(w)\n",
    "        \n",
    "        y1 = np.clip(y - max_h_size // 2, 0, h)\n",
    "        y2 = np.clip(y + max_h_size // 2, 0, h)\n",
    "        x1 = np.clip(x - max_w_size // 2, 0, w)\n",
    "        x2 = np.clip(x + max_w_size // 2, 0, w)\n",
    "\n",
    "        mask[y1: y2, x1: x2] = 0.\n",
    "\n",
    "    # Apply mask\n",
    "    image_np = image_np * mask[:, :, np.newaxis]\n",
    "\n",
    "    # Convert back to PIL Image\n",
    "    return Image.fromarray(image_np.astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9d57cc6e-431f-4d2a-be3e-1b5fcd92f7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_image(image, pad_size=4, fill=0, padding_mode='reflect'):\n",
    "    \"\"\"Pad the given PIL Image on all sides with the given pad_size.\"\"\"\n",
    "    pad_size = int(random.choice([1 + 0.1 * i for i in range(10)]) * pad_size)\n",
    "    return ImageOps.expand(image, border=pad_size, fill=fill)\n",
    "\n",
    "def random_crop(image, crop_size=(32, 32)):\n",
    "    \"\"\"Crop a random part of the image to the given size.\"\"\"\n",
    "    width, height = image.size\n",
    "    new_width, new_height = crop_size\n",
    "\n",
    "    left = np.random.randint(0, width - new_width + 1)\n",
    "    top = np.random.randint(0, height - new_height + 1)\n",
    "\n",
    "    image = image.crop((left, top, left + new_width, top + new_height))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a68f55a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_horizontal_flip(image, p=0.5):\n",
    "    \"\"\"Randomly flip the image horizontally with a probability of p.\"\"\"\n",
    "    if random.random() < p:\n",
    "        return image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    return image\n",
    "\n",
    "def random_rotation(image, max_angle=20):\n",
    "    \"\"\"Randomly rotate the image within a given angle range.\"\"\"\n",
    "    angle = random.uniform(-max_angle, max_angle)\n",
    "    return image.rotate(angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3e238af9-2305-4f09-9f5b-c254c5327c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class CustomImageDataGenerator(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size=64, augmentations=None):\n",
    "        self.x_set = x_set\n",
    "        self.y_set = y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.augmentations = augmentations if augmentations else []\n",
    "\n",
    "    def __len__(self):\n",
    "        return np.ceil(len(self.x_set) / self.batch_size).astype(int)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x_set[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y_set[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        # Convert numpy arrays to PIL Images, apply augmentations, and convert back to numpy arrays\n",
    "        x_batch_aug = np.array([self.apply_augmentations(Image.fromarray((image * 255).astype('uint8'))) for image in batch_x])\n",
    "        \n",
    "        # Convert PIL Images back to numpy arrays and normalize to [0, 1]\n",
    "        x_batch_aug = np.array([np.array(image) for image in x_batch_aug]).astype('float32') / 255.0\n",
    "        \n",
    "        return x_batch_aug, batch_y\n",
    "\n",
    "    def apply_augmentations(self, image):\n",
    "        augmented_image = image\n",
    "        for augmentation in self.augmentations:\n",
    "            augmented_image = augmentation(augmented_image)\n",
    "        return augmented_image\n",
    "\n",
    "# Assuming CIFAR10Policy and apply_cutout are defined elsewhere\n",
    "custom_augmentations = [pad_image, random_crop, random_horizontal_flip, random_rotation, CIFAR10Policy(), apply_cutout]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e59a9ff0-5233-4b97-8663-6b5f26010374",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.05\n",
    "momentum = 0.9\n",
    "weight_decay = 0.0005\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(\n",
    "    learning_rate=lr, \n",
    "    momentum=momentum, \n",
    "    nesterov=True,\n",
    "    decay=weight_decay\n",
    ")\n",
    "\n",
    "# Compile the model with the updated learning_rate parameter\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "715d317d-b5f2-4b3e-9f70-aaabb2249b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 1.9364 - accuracy: 0.3096\n",
      "Epoch 1: val_accuracy improved from -inf to 0.35610, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 28s 69ms/step - loss: 1.9364 - accuracy: 0.3096 - val_loss: 2.1725 - val_accuracy: 0.3561\n",
      "Epoch 2/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 1.5409 - accuracy: 0.4494\n",
      "Epoch 2: val_accuracy improved from 0.35610 to 0.55800, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 29s 73ms/step - loss: 1.5409 - accuracy: 0.4494 - val_loss: 1.2178 - val_accuracy: 0.5580\n",
      "Epoch 3/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 1.3488 - accuracy: 0.5201\n",
      "Epoch 3: val_accuracy improved from 0.55800 to 0.59960, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 28s 72ms/step - loss: 1.3488 - accuracy: 0.5201 - val_loss: 1.2005 - val_accuracy: 0.5996\n",
      "Epoch 4/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 1.2313 - accuracy: 0.5637\n",
      "Epoch 4: val_accuracy improved from 0.59960 to 0.67470, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 27s 68ms/step - loss: 1.2313 - accuracy: 0.5637 - val_loss: 0.9631 - val_accuracy: 0.6747\n",
      "Epoch 5/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 1.1424 - accuracy: 0.5956\n",
      "Epoch 5: val_accuracy improved from 0.67470 to 0.69510, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 25s 64ms/step - loss: 1.1424 - accuracy: 0.5956 - val_loss: 0.9245 - val_accuracy: 0.6951\n",
      "Epoch 6/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 1.0673 - accuracy: 0.6222\n",
      "Epoch 6: val_accuracy improved from 0.69510 to 0.70300, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 27s 68ms/step - loss: 1.0673 - accuracy: 0.6222 - val_loss: 0.9077 - val_accuracy: 0.7030\n",
      "Epoch 7/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 1.0188 - accuracy: 0.6423\n",
      "Epoch 7: val_accuracy improved from 0.70300 to 0.73010, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 29s 73ms/step - loss: 1.0188 - accuracy: 0.6423 - val_loss: 0.7752 - val_accuracy: 0.7301\n",
      "Epoch 8/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.9693 - accuracy: 0.6595\n",
      "Epoch 8: val_accuracy improved from 0.73010 to 0.78070, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 27s 68ms/step - loss: 0.9693 - accuracy: 0.6595 - val_loss: 0.6390 - val_accuracy: 0.7807\n",
      "Epoch 9/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.9298 - accuracy: 0.6736\n",
      "Epoch 9: val_accuracy improved from 0.78070 to 0.79230, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 27s 70ms/step - loss: 0.9298 - accuracy: 0.6736 - val_loss: 0.6181 - val_accuracy: 0.7923\n",
      "Epoch 10/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.8976 - accuracy: 0.6849\n",
      "Epoch 10: val_accuracy improved from 0.79230 to 0.79640, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 27s 68ms/step - loss: 0.8976 - accuracy: 0.6849 - val_loss: 0.6069 - val_accuracy: 0.7964\n",
      "Epoch 11/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.8683 - accuracy: 0.6940\n",
      "Epoch 11: val_accuracy did not improve from 0.79640\n",
      "390/390 [==============================] - 23s 59ms/step - loss: 0.8683 - accuracy: 0.6940 - val_loss: 0.6789 - val_accuracy: 0.7779\n",
      "Epoch 12/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.8454 - accuracy: 0.7005\n",
      "Epoch 12: val_accuracy improved from 0.79640 to 0.80970, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 25s 63ms/step - loss: 0.8454 - accuracy: 0.7005 - val_loss: 0.5468 - val_accuracy: 0.8097\n",
      "Epoch 13/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.8149 - accuracy: 0.7168\n",
      "Epoch 13: val_accuracy did not improve from 0.80970\n",
      "390/390 [==============================] - 23s 58ms/step - loss: 0.8149 - accuracy: 0.7168 - val_loss: 0.6340 - val_accuracy: 0.7867\n",
      "Epoch 14/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.7976 - accuracy: 0.7220\n",
      "Epoch 14: val_accuracy did not improve from 0.80970\n",
      "390/390 [==============================] - 23s 58ms/step - loss: 0.7976 - accuracy: 0.7220 - val_loss: 0.5683 - val_accuracy: 0.8055\n",
      "Epoch 15/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.7737 - accuracy: 0.7292\n",
      "Epoch 15: val_accuracy improved from 0.80970 to 0.81030, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 27s 70ms/step - loss: 0.7737 - accuracy: 0.7292 - val_loss: 0.5417 - val_accuracy: 0.8103\n",
      "Epoch 16/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.7663 - accuracy: 0.7304\n",
      "Epoch 16: val_accuracy improved from 0.81030 to 0.82250, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 26s 67ms/step - loss: 0.7663 - accuracy: 0.7304 - val_loss: 0.5335 - val_accuracy: 0.8225\n",
      "Epoch 17/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.7471 - accuracy: 0.7396\n",
      "Epoch 17: val_accuracy improved from 0.82250 to 0.84120, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 26s 67ms/step - loss: 0.7471 - accuracy: 0.7396 - val_loss: 0.4685 - val_accuracy: 0.8412\n",
      "Epoch 18/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.7320 - accuracy: 0.7445\n",
      "Epoch 18: val_accuracy did not improve from 0.84120\n",
      "390/390 [==============================] - 23s 58ms/step - loss: 0.7320 - accuracy: 0.7445 - val_loss: 0.4910 - val_accuracy: 0.8361\n",
      "Epoch 19/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.7190 - accuracy: 0.7470\n",
      "Epoch 19: val_accuracy did not improve from 0.84120\n",
      "390/390 [==============================] - 24s 60ms/step - loss: 0.7190 - accuracy: 0.7470 - val_loss: 0.4808 - val_accuracy: 0.8378\n",
      "Epoch 20/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.7090 - accuracy: 0.7497\n",
      "Epoch 20: val_accuracy did not improve from 0.84120\n",
      "390/390 [==============================] - 23s 58ms/step - loss: 0.7090 - accuracy: 0.7497 - val_loss: 0.4643 - val_accuracy: 0.8383\n",
      "Epoch 21/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.6950 - accuracy: 0.7579\n",
      "Epoch 21: val_accuracy improved from 0.84120 to 0.84620, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 27s 70ms/step - loss: 0.6950 - accuracy: 0.7579 - val_loss: 0.4552 - val_accuracy: 0.8462\n",
      "Epoch 22/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.6866 - accuracy: 0.7586\n",
      "Epoch 22: val_accuracy improved from 0.84620 to 0.84630, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 27s 70ms/step - loss: 0.6866 - accuracy: 0.7586 - val_loss: 0.4525 - val_accuracy: 0.8463\n",
      "Epoch 23/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.6695 - accuracy: 0.7672\n",
      "Epoch 23: val_accuracy did not improve from 0.84630\n",
      "390/390 [==============================] - 23s 59ms/step - loss: 0.6695 - accuracy: 0.7672 - val_loss: 0.4781 - val_accuracy: 0.8402\n",
      "Epoch 24/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.6662 - accuracy: 0.7671\n",
      "Epoch 24: val_accuracy improved from 0.84630 to 0.85460, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 27s 70ms/step - loss: 0.6662 - accuracy: 0.7671 - val_loss: 0.4372 - val_accuracy: 0.8546\n",
      "Epoch 25/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.6551 - accuracy: 0.7707\n",
      "Epoch 25: val_accuracy did not improve from 0.85460\n",
      "390/390 [==============================] - 23s 59ms/step - loss: 0.6551 - accuracy: 0.7707 - val_loss: 0.4267 - val_accuracy: 0.8538\n",
      "Epoch 26/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.6437 - accuracy: 0.7754\n",
      "Epoch 26: val_accuracy improved from 0.85460 to 0.86040, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 27s 70ms/step - loss: 0.6437 - accuracy: 0.7754 - val_loss: 0.4203 - val_accuracy: 0.8604\n",
      "Epoch 27/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.6375 - accuracy: 0.7750\n",
      "Epoch 27: val_accuracy improved from 0.86040 to 0.86170, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 27s 68ms/step - loss: 0.6375 - accuracy: 0.7750 - val_loss: 0.4079 - val_accuracy: 0.8617\n",
      "Epoch 28/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.6216 - accuracy: 0.7823\n",
      "Epoch 28: val_accuracy did not improve from 0.86170\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.6216 - accuracy: 0.7823 - val_loss: 0.4468 - val_accuracy: 0.8481\n",
      "Epoch 29/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.6210 - accuracy: 0.7818\n",
      "Epoch 29: val_accuracy improved from 0.86170 to 0.86320, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 26s 67ms/step - loss: 0.6210 - accuracy: 0.7818 - val_loss: 0.4045 - val_accuracy: 0.8632\n",
      "Epoch 30/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.6101 - accuracy: 0.7856\n",
      "Epoch 30: val_accuracy improved from 0.86320 to 0.87220, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 26s 67ms/step - loss: 0.6101 - accuracy: 0.7856 - val_loss: 0.3737 - val_accuracy: 0.8722\n",
      "Epoch 31/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.6079 - accuracy: 0.7875\n",
      "Epoch 31: val_accuracy did not improve from 0.87220\n",
      "390/390 [==============================] - 23s 58ms/step - loss: 0.6079 - accuracy: 0.7875 - val_loss: 0.3905 - val_accuracy: 0.8685\n",
      "Epoch 32/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.5935 - accuracy: 0.7915\n",
      "Epoch 32: val_accuracy improved from 0.87220 to 0.87370, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 26s 68ms/step - loss: 0.5935 - accuracy: 0.7915 - val_loss: 0.3711 - val_accuracy: 0.8737\n",
      "Epoch 33/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.5929 - accuracy: 0.7915\n",
      "Epoch 33: val_accuracy improved from 0.87370 to 0.87700, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 27s 70ms/step - loss: 0.5929 - accuracy: 0.7915 - val_loss: 0.3657 - val_accuracy: 0.8770\n",
      "Epoch 34/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.5801 - accuracy: 0.7967\n",
      "Epoch 34: val_accuracy did not improve from 0.87700\n",
      "390/390 [==============================] - 23s 58ms/step - loss: 0.5801 - accuracy: 0.7967 - val_loss: 0.3640 - val_accuracy: 0.8754\n",
      "Epoch 35/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.5788 - accuracy: 0.7956\n",
      "Epoch 35: val_accuracy did not improve from 0.87700\n",
      "390/390 [==============================] - 23s 58ms/step - loss: 0.5788 - accuracy: 0.7956 - val_loss: 0.4002 - val_accuracy: 0.8641\n",
      "Epoch 36/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.5761 - accuracy: 0.7975\n",
      "Epoch 36: val_accuracy improved from 0.87700 to 0.88310, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 27s 70ms/step - loss: 0.5761 - accuracy: 0.7975 - val_loss: 0.3481 - val_accuracy: 0.8831\n",
      "Epoch 37/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.5675 - accuracy: 0.8007\n",
      "Epoch 37: val_accuracy did not improve from 0.88310\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.5675 - accuracy: 0.8007 - val_loss: 0.3460 - val_accuracy: 0.8818\n",
      "Epoch 38/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.5769 - accuracy: 0.7981\n",
      "Epoch 38: val_accuracy improved from 0.88310 to 0.88510, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 27s 70ms/step - loss: 0.5769 - accuracy: 0.7981 - val_loss: 0.3367 - val_accuracy: 0.8851\n",
      "Epoch 39/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.5580 - accuracy: 0.8034\n",
      "Epoch 39: val_accuracy did not improve from 0.88510\n",
      "390/390 [==============================] - 23s 58ms/step - loss: 0.5580 - accuracy: 0.8034 - val_loss: 0.4350 - val_accuracy: 0.8613\n",
      "Epoch 40/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.5535 - accuracy: 0.8046\n",
      "Epoch 40: val_accuracy improved from 0.88510 to 0.88840, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 27s 69ms/step - loss: 0.5535 - accuracy: 0.8046 - val_loss: 0.3345 - val_accuracy: 0.8884\n",
      "Epoch 41/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.5529 - accuracy: 0.8065\n",
      "Epoch 41: val_accuracy did not improve from 0.88840\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.5529 - accuracy: 0.8065 - val_loss: 0.3928 - val_accuracy: 0.8695\n",
      "Epoch 42/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.5477 - accuracy: 0.8084\n",
      "Epoch 42: val_accuracy did not improve from 0.88840\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.5477 - accuracy: 0.8084 - val_loss: 0.3915 - val_accuracy: 0.8690\n",
      "Epoch 43/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.5415 - accuracy: 0.8113\n",
      "Epoch 43: val_accuracy did not improve from 0.88840\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.5415 - accuracy: 0.8113 - val_loss: 0.3405 - val_accuracy: 0.8828\n",
      "Epoch 44/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.5422 - accuracy: 0.8084\n",
      "Epoch 44: val_accuracy did not improve from 0.88840\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.5422 - accuracy: 0.8084 - val_loss: 0.3639 - val_accuracy: 0.8810\n",
      "Epoch 45/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.5363 - accuracy: 0.8121\n",
      "Epoch 45: val_accuracy improved from 0.88840 to 0.89080, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 27s 70ms/step - loss: 0.5363 - accuracy: 0.8121 - val_loss: 0.3322 - val_accuracy: 0.8908\n",
      "Epoch 46/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.5273 - accuracy: 0.8141\n",
      "Epoch 46: val_accuracy did not improve from 0.89080\n",
      "390/390 [==============================] - 25s 62ms/step - loss: 0.5273 - accuracy: 0.8141 - val_loss: 0.3439 - val_accuracy: 0.8864\n",
      "Epoch 47/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.5250 - accuracy: 0.8167\n",
      "Epoch 47: val_accuracy improved from 0.89080 to 0.89380, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 27s 70ms/step - loss: 0.5250 - accuracy: 0.8167 - val_loss: 0.3156 - val_accuracy: 0.8938\n",
      "Epoch 48/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.5174 - accuracy: 0.8181\n",
      "Epoch 48: val_accuracy did not improve from 0.89380\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.5174 - accuracy: 0.8181 - val_loss: 0.3232 - val_accuracy: 0.8902\n",
      "Epoch 49/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.5223 - accuracy: 0.8163\n",
      "Epoch 49: val_accuracy did not improve from 0.89380\n",
      "390/390 [==============================] - 23s 60ms/step - loss: 0.5223 - accuracy: 0.8163 - val_loss: 0.3185 - val_accuracy: 0.8898\n",
      "Epoch 50/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.5158 - accuracy: 0.8199\n",
      "Epoch 50: val_accuracy did not improve from 0.89380\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.5158 - accuracy: 0.8199 - val_loss: 0.3446 - val_accuracy: 0.8844\n",
      "Epoch 51/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.5094 - accuracy: 0.8222\n",
      "Epoch 51: val_accuracy did not improve from 0.89380\n",
      "390/390 [==============================] - 23s 59ms/step - loss: 0.5094 - accuracy: 0.8222 - val_loss: 0.3215 - val_accuracy: 0.8893\n",
      "Epoch 52/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.5047 - accuracy: 0.8227\n",
      "Epoch 52: val_accuracy did not improve from 0.89380\n",
      "390/390 [==============================] - 23s 60ms/step - loss: 0.5047 - accuracy: 0.8227 - val_loss: 0.3340 - val_accuracy: 0.8872\n",
      "Epoch 53/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.5051 - accuracy: 0.8228\n",
      "Epoch 53: val_accuracy did not improve from 0.89380\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.5051 - accuracy: 0.8228 - val_loss: 0.3235 - val_accuracy: 0.8915\n",
      "Epoch 54/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.5026 - accuracy: 0.8222\n",
      "Epoch 54: val_accuracy improved from 0.89380 to 0.89420, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 28s 73ms/step - loss: 0.5026 - accuracy: 0.8222 - val_loss: 0.3062 - val_accuracy: 0.8942\n",
      "Epoch 55/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4963 - accuracy: 0.8246\n",
      "Epoch 55: val_accuracy improved from 0.89420 to 0.89520, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 28s 71ms/step - loss: 0.4963 - accuracy: 0.8246 - val_loss: 0.3084 - val_accuracy: 0.8952\n",
      "Epoch 56/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4875 - accuracy: 0.8276\n",
      "Epoch 56: val_accuracy did not improve from 0.89520\n",
      "390/390 [==============================] - 23s 60ms/step - loss: 0.4875 - accuracy: 0.8276 - val_loss: 0.3131 - val_accuracy: 0.8949\n",
      "Epoch 57/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4936 - accuracy: 0.8282\n",
      "Epoch 57: val_accuracy did not improve from 0.89520\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.4936 - accuracy: 0.8282 - val_loss: 0.3212 - val_accuracy: 0.8945\n",
      "Epoch 58/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4864 - accuracy: 0.8297\n",
      "Epoch 58: val_accuracy did not improve from 0.89520\n",
      "390/390 [==============================] - 23s 59ms/step - loss: 0.4864 - accuracy: 0.8297 - val_loss: 0.3248 - val_accuracy: 0.8952\n",
      "Epoch 59/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4825 - accuracy: 0.8293\n",
      "Epoch 59: val_accuracy improved from 0.89520 to 0.89580, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 28s 73ms/step - loss: 0.4825 - accuracy: 0.8293 - val_loss: 0.3162 - val_accuracy: 0.8958\n",
      "Epoch 60/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4827 - accuracy: 0.8294\n",
      "Epoch 60: val_accuracy did not improve from 0.89580\n",
      "390/390 [==============================] - 23s 60ms/step - loss: 0.4827 - accuracy: 0.8294 - val_loss: 0.3308 - val_accuracy: 0.8877\n",
      "Epoch 61/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4779 - accuracy: 0.8328\n",
      "Epoch 61: val_accuracy improved from 0.89580 to 0.89970, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 28s 72ms/step - loss: 0.4779 - accuracy: 0.8328 - val_loss: 0.2949 - val_accuracy: 0.8997\n",
      "Epoch 62/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4783 - accuracy: 0.8320\n",
      "Epoch 62: val_accuracy improved from 0.89970 to 0.90110, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 29s 73ms/step - loss: 0.4783 - accuracy: 0.8320 - val_loss: 0.2937 - val_accuracy: 0.9011\n",
      "Epoch 63/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4723 - accuracy: 0.8345\n",
      "Epoch 63: val_accuracy improved from 0.90110 to 0.90130, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 27s 70ms/step - loss: 0.4723 - accuracy: 0.8345 - val_loss: 0.2962 - val_accuracy: 0.9013\n",
      "Epoch 64/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4748 - accuracy: 0.8331\n",
      "Epoch 64: val_accuracy did not improve from 0.90130\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.4748 - accuracy: 0.8331 - val_loss: 0.3016 - val_accuracy: 0.8959\n",
      "Epoch 65/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4717 - accuracy: 0.8338\n",
      "Epoch 65: val_accuracy improved from 0.90130 to 0.90190, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 29s 73ms/step - loss: 0.4717 - accuracy: 0.8338 - val_loss: 0.2925 - val_accuracy: 0.9019\n",
      "Epoch 66/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4726 - accuracy: 0.8346\n",
      "Epoch 66: val_accuracy improved from 0.90190 to 0.90680, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 29s 74ms/step - loss: 0.4726 - accuracy: 0.8346 - val_loss: 0.2915 - val_accuracy: 0.9068\n",
      "Epoch 67/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4619 - accuracy: 0.8389\n",
      "Epoch 67: val_accuracy did not improve from 0.90680\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.4619 - accuracy: 0.8389 - val_loss: 0.2948 - val_accuracy: 0.9031\n",
      "Epoch 68/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4635 - accuracy: 0.8373\n",
      "Epoch 68: val_accuracy did not improve from 0.90680\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.4635 - accuracy: 0.8373 - val_loss: 0.3585 - val_accuracy: 0.8824\n",
      "Epoch 69/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4559 - accuracy: 0.8402\n",
      "Epoch 69: val_accuracy improved from 0.90680 to 0.91070, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 27s 70ms/step - loss: 0.4559 - accuracy: 0.8402 - val_loss: 0.2795 - val_accuracy: 0.9107\n",
      "Epoch 70/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4590 - accuracy: 0.8395\n",
      "Epoch 70: val_accuracy did not improve from 0.91070\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.4590 - accuracy: 0.8395 - val_loss: 0.2939 - val_accuracy: 0.8991\n",
      "Epoch 71/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4552 - accuracy: 0.8399\n",
      "Epoch 71: val_accuracy did not improve from 0.91070\n",
      "390/390 [==============================] - 21s 54ms/step - loss: 0.4552 - accuracy: 0.8399 - val_loss: 0.3071 - val_accuracy: 0.8986\n",
      "Epoch 72/500\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.4503 - accuracy: 0.8422\n",
      "Epoch 72: val_accuracy did not improve from 0.91070\n",
      "390/390 [==============================] - 21s 54ms/step - loss: 0.4501 - accuracy: 0.8423 - val_loss: 0.2917 - val_accuracy: 0.9011\n",
      "Epoch 73/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4480 - accuracy: 0.8434\n",
      "Epoch 73: val_accuracy did not improve from 0.91070\n",
      "390/390 [==============================] - 23s 58ms/step - loss: 0.4480 - accuracy: 0.8434 - val_loss: 0.2822 - val_accuracy: 0.9063\n",
      "Epoch 74/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4474 - accuracy: 0.8411\n",
      "Epoch 74: val_accuracy did not improve from 0.91070\n",
      "390/390 [==============================] - 23s 58ms/step - loss: 0.4474 - accuracy: 0.8411 - val_loss: 0.2945 - val_accuracy: 0.9037\n",
      "Epoch 75/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4465 - accuracy: 0.8437\n",
      "Epoch 75: val_accuracy did not improve from 0.91070\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.4465 - accuracy: 0.8437 - val_loss: 0.3171 - val_accuracy: 0.8936\n",
      "Epoch 76/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4449 - accuracy: 0.8426\n",
      "Epoch 76: val_accuracy did not improve from 0.91070\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.4449 - accuracy: 0.8426 - val_loss: 0.3013 - val_accuracy: 0.9009\n",
      "Epoch 77/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4375 - accuracy: 0.8468\n",
      "Epoch 77: val_accuracy did not improve from 0.91070\n",
      "390/390 [==============================] - 23s 60ms/step - loss: 0.4375 - accuracy: 0.8468 - val_loss: 0.2732 - val_accuracy: 0.9093\n",
      "Epoch 78/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4400 - accuracy: 0.8449\n",
      "Epoch 78: val_accuracy did not improve from 0.91070\n",
      "390/390 [==============================] - 23s 58ms/step - loss: 0.4400 - accuracy: 0.8449 - val_loss: 0.2774 - val_accuracy: 0.9064\n",
      "Epoch 79/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4377 - accuracy: 0.8459\n",
      "Epoch 79: val_accuracy did not improve from 0.91070\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.4377 - accuracy: 0.8459 - val_loss: 0.3007 - val_accuracy: 0.9033\n",
      "Epoch 80/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4374 - accuracy: 0.8472\n",
      "Epoch 80: val_accuracy did not improve from 0.91070\n",
      "390/390 [==============================] - 23s 60ms/step - loss: 0.4374 - accuracy: 0.8472 - val_loss: 0.2776 - val_accuracy: 0.9098\n",
      "Epoch 81/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4340 - accuracy: 0.8466\n",
      "Epoch 81: val_accuracy did not improve from 0.91070\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.4340 - accuracy: 0.8466 - val_loss: 0.2848 - val_accuracy: 0.9059\n",
      "Epoch 82/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4350 - accuracy: 0.8459\n",
      "Epoch 82: val_accuracy improved from 0.91070 to 0.91130, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 28s 71ms/step - loss: 0.4350 - accuracy: 0.8459 - val_loss: 0.2734 - val_accuracy: 0.9113\n",
      "Epoch 83/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4349 - accuracy: 0.8483\n",
      "Epoch 83: val_accuracy did not improve from 0.91130\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.4349 - accuracy: 0.8483 - val_loss: 0.2969 - val_accuracy: 0.9041\n",
      "Epoch 84/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4268 - accuracy: 0.8505\n",
      "Epoch 84: val_accuracy did not improve from 0.91130\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.4268 - accuracy: 0.8505 - val_loss: 0.2688 - val_accuracy: 0.9104\n",
      "Epoch 85/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4316 - accuracy: 0.8504\n",
      "Epoch 85: val_accuracy did not improve from 0.91130\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.4316 - accuracy: 0.8504 - val_loss: 0.2979 - val_accuracy: 0.9043\n",
      "Epoch 86/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4226 - accuracy: 0.8509\n",
      "Epoch 86: val_accuracy improved from 0.91130 to 0.91690, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 28s 73ms/step - loss: 0.4226 - accuracy: 0.8509 - val_loss: 0.2593 - val_accuracy: 0.9169\n",
      "Epoch 87/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4225 - accuracy: 0.8519\n",
      "Epoch 87: val_accuracy did not improve from 0.91690\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.4225 - accuracy: 0.8519 - val_loss: 0.3051 - val_accuracy: 0.9037\n",
      "Epoch 88/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4201 - accuracy: 0.8526\n",
      "Epoch 88: val_accuracy did not improve from 0.91690\n",
      "390/390 [==============================] - 25s 64ms/step - loss: 0.4201 - accuracy: 0.8526 - val_loss: 0.2594 - val_accuracy: 0.9160\n",
      "Epoch 89/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4250 - accuracy: 0.8495\n",
      "Epoch 89: val_accuracy did not improve from 0.91690\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.4250 - accuracy: 0.8495 - val_loss: 0.2844 - val_accuracy: 0.9074\n",
      "Epoch 90/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4191 - accuracy: 0.8515\n",
      "Epoch 90: val_accuracy did not improve from 0.91690\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.4191 - accuracy: 0.8515 - val_loss: 0.2751 - val_accuracy: 0.9099\n",
      "Epoch 91/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4192 - accuracy: 0.8531\n",
      "Epoch 91: val_accuracy did not improve from 0.91690\n",
      "390/390 [==============================] - 23s 60ms/step - loss: 0.4192 - accuracy: 0.8531 - val_loss: 0.2740 - val_accuracy: 0.9105\n",
      "Epoch 92/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4155 - accuracy: 0.8552\n",
      "Epoch 92: val_accuracy did not improve from 0.91690\n",
      "390/390 [==============================] - 23s 59ms/step - loss: 0.4155 - accuracy: 0.8552 - val_loss: 0.2701 - val_accuracy: 0.9118\n",
      "Epoch 93/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4073 - accuracy: 0.8565\n",
      "Epoch 93: val_accuracy did not improve from 0.91690\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.4073 - accuracy: 0.8565 - val_loss: 0.2886 - val_accuracy: 0.9030\n",
      "Epoch 94/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4157 - accuracy: 0.8518\n",
      "Epoch 94: val_accuracy did not improve from 0.91690\n",
      "390/390 [==============================] - 24s 63ms/step - loss: 0.4157 - accuracy: 0.8518 - val_loss: 0.2814 - val_accuracy: 0.9071\n",
      "Epoch 95/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4155 - accuracy: 0.8550\n",
      "Epoch 95: val_accuracy did not improve from 0.91690\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.4155 - accuracy: 0.8550 - val_loss: 0.2729 - val_accuracy: 0.9111\n",
      "Epoch 96/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4085 - accuracy: 0.8554\n",
      "Epoch 96: val_accuracy did not improve from 0.91690\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.4085 - accuracy: 0.8554 - val_loss: 0.2636 - val_accuracy: 0.9152\n",
      "Epoch 97/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4112 - accuracy: 0.8550\n",
      "Epoch 97: val_accuracy did not improve from 0.91690\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.4112 - accuracy: 0.8550 - val_loss: 0.2715 - val_accuracy: 0.9121\n",
      "Epoch 98/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4103 - accuracy: 0.8569\n",
      "Epoch 98: val_accuracy did not improve from 0.91690\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.4103 - accuracy: 0.8569 - val_loss: 0.2722 - val_accuracy: 0.9142\n",
      "Epoch 99/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4030 - accuracy: 0.8598\n",
      "Epoch 99: val_accuracy did not improve from 0.91690\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.4030 - accuracy: 0.8598 - val_loss: 0.2610 - val_accuracy: 0.9163\n",
      "Epoch 100/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3978 - accuracy: 0.8601\n",
      "Epoch 100: val_accuracy did not improve from 0.91690\n",
      "390/390 [==============================] - 23s 59ms/step - loss: 0.3978 - accuracy: 0.8601 - val_loss: 0.2644 - val_accuracy: 0.9150\n",
      "Epoch 101/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4026 - accuracy: 0.8575\n",
      "Epoch 101: val_accuracy did not improve from 0.91690\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.4026 - accuracy: 0.8575 - val_loss: 0.2785 - val_accuracy: 0.9112\n",
      "Epoch 102/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4003 - accuracy: 0.8594\n",
      "Epoch 102: val_accuracy did not improve from 0.91690\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.4003 - accuracy: 0.8594 - val_loss: 0.2603 - val_accuracy: 0.9142\n",
      "Epoch 103/500\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.4000 - accuracy: 0.8590\n",
      "Epoch 103: val_accuracy did not improve from 0.91690\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.3997 - accuracy: 0.8591 - val_loss: 0.2979 - val_accuracy: 0.9058\n",
      "Epoch 104/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3954 - accuracy: 0.8606\n",
      "Epoch 104: val_accuracy did not improve from 0.91690\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.3954 - accuracy: 0.8606 - val_loss: 0.2616 - val_accuracy: 0.9150\n",
      "Epoch 105/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3970 - accuracy: 0.8610\n",
      "Epoch 105: val_accuracy improved from 0.91690 to 0.91750, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 28s 71ms/step - loss: 0.3970 - accuracy: 0.8610 - val_loss: 0.2563 - val_accuracy: 0.9175\n",
      "Epoch 106/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4025 - accuracy: 0.8584\n",
      "Epoch 106: val_accuracy did not improve from 0.91750\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.4025 - accuracy: 0.8584 - val_loss: 0.2894 - val_accuracy: 0.9105\n",
      "Epoch 107/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3973 - accuracy: 0.8592\n",
      "Epoch 107: val_accuracy did not improve from 0.91750\n",
      "390/390 [==============================] - 23s 58ms/step - loss: 0.3973 - accuracy: 0.8592 - val_loss: 0.2818 - val_accuracy: 0.9061\n",
      "Epoch 108/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3956 - accuracy: 0.8626\n",
      "Epoch 108: val_accuracy did not improve from 0.91750\n",
      "390/390 [==============================] - 23s 58ms/step - loss: 0.3956 - accuracy: 0.8626 - val_loss: 0.2782 - val_accuracy: 0.9133\n",
      "Epoch 109/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3951 - accuracy: 0.8601\n",
      "Epoch 109: val_accuracy did not improve from 0.91750\n",
      "390/390 [==============================] - 23s 59ms/step - loss: 0.3951 - accuracy: 0.8601 - val_loss: 0.2889 - val_accuracy: 0.9075\n",
      "Epoch 110/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3895 - accuracy: 0.8637\n",
      "Epoch 110: val_accuracy improved from 0.91750 to 0.91760, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 28s 70ms/step - loss: 0.3895 - accuracy: 0.8637 - val_loss: 0.2672 - val_accuracy: 0.9176\n",
      "Epoch 111/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3891 - accuracy: 0.8649\n",
      "Epoch 111: val_accuracy improved from 0.91760 to 0.91770, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 26s 68ms/step - loss: 0.3891 - accuracy: 0.8649 - val_loss: 0.2545 - val_accuracy: 0.9177\n",
      "Epoch 112/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3830 - accuracy: 0.8647\n",
      "Epoch 112: val_accuracy did not improve from 0.91770\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.3830 - accuracy: 0.8647 - val_loss: 0.2621 - val_accuracy: 0.9154\n",
      "Epoch 113/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3866 - accuracy: 0.8643\n",
      "Epoch 113: val_accuracy did not improve from 0.91770\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.3866 - accuracy: 0.8643 - val_loss: 0.2566 - val_accuracy: 0.9168\n",
      "Epoch 114/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3877 - accuracy: 0.8645\n",
      "Epoch 114: val_accuracy did not improve from 0.91770\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.3877 - accuracy: 0.8645 - val_loss: 0.2796 - val_accuracy: 0.9120\n",
      "Epoch 115/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3852 - accuracy: 0.8645\n",
      "Epoch 115: val_accuracy improved from 0.91770 to 0.91800, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 28s 71ms/step - loss: 0.3852 - accuracy: 0.8645 - val_loss: 0.2545 - val_accuracy: 0.9180\n",
      "Epoch 116/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3867 - accuracy: 0.8634\n",
      "Epoch 116: val_accuracy did not improve from 0.91800\n",
      "390/390 [==============================] - 24s 60ms/step - loss: 0.3867 - accuracy: 0.8634 - val_loss: 0.2741 - val_accuracy: 0.9132\n",
      "Epoch 117/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3844 - accuracy: 0.8657\n",
      "Epoch 117: val_accuracy improved from 0.91800 to 0.92160, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 28s 72ms/step - loss: 0.3844 - accuracy: 0.8657 - val_loss: 0.2463 - val_accuracy: 0.9216\n",
      "Epoch 118/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3798 - accuracy: 0.8669\n",
      "Epoch 118: val_accuracy did not improve from 0.92160\n",
      "390/390 [==============================] - 23s 58ms/step - loss: 0.3798 - accuracy: 0.8669 - val_loss: 0.2661 - val_accuracy: 0.9159\n",
      "Epoch 119/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3787 - accuracy: 0.8687\n",
      "Epoch 119: val_accuracy did not improve from 0.92160\n",
      "390/390 [==============================] - 23s 59ms/step - loss: 0.3787 - accuracy: 0.8687 - val_loss: 0.2593 - val_accuracy: 0.9170\n",
      "Epoch 120/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3830 - accuracy: 0.8642\n",
      "Epoch 120: val_accuracy did not improve from 0.92160\n",
      "390/390 [==============================] - 23s 59ms/step - loss: 0.3830 - accuracy: 0.8642 - val_loss: 0.2712 - val_accuracy: 0.9136\n",
      "Epoch 121/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3761 - accuracy: 0.8663\n",
      "Epoch 121: val_accuracy did not improve from 0.92160\n",
      "390/390 [==============================] - 23s 59ms/step - loss: 0.3761 - accuracy: 0.8663 - val_loss: 0.2604 - val_accuracy: 0.9163\n",
      "Epoch 122/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3676 - accuracy: 0.8702\n",
      "Epoch 122: val_accuracy did not improve from 0.92160\n",
      "390/390 [==============================] - 24s 60ms/step - loss: 0.3676 - accuracy: 0.8702 - val_loss: 0.2654 - val_accuracy: 0.9150\n",
      "Epoch 123/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3732 - accuracy: 0.8696\n",
      "Epoch 123: val_accuracy did not improve from 0.92160\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.3732 - accuracy: 0.8696 - val_loss: 0.2430 - val_accuracy: 0.9203\n",
      "Epoch 124/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3813 - accuracy: 0.8658\n",
      "Epoch 124: val_accuracy did not improve from 0.92160\n",
      "390/390 [==============================] - 23s 58ms/step - loss: 0.3813 - accuracy: 0.8658 - val_loss: 0.2666 - val_accuracy: 0.9161\n",
      "Epoch 125/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3725 - accuracy: 0.8688\n",
      "Epoch 125: val_accuracy did not improve from 0.92160\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.3725 - accuracy: 0.8688 - val_loss: 0.2639 - val_accuracy: 0.9153\n",
      "Epoch 126/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3753 - accuracy: 0.8663\n",
      "Epoch 126: val_accuracy did not improve from 0.92160\n",
      "390/390 [==============================] - 23s 58ms/step - loss: 0.3753 - accuracy: 0.8663 - val_loss: 0.2602 - val_accuracy: 0.9157\n",
      "Epoch 127/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3795 - accuracy: 0.8656\n",
      "Epoch 127: val_accuracy improved from 0.92160 to 0.92270, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 27s 68ms/step - loss: 0.3795 - accuracy: 0.8656 - val_loss: 0.2401 - val_accuracy: 0.9227\n",
      "Epoch 128/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3762 - accuracy: 0.8686\n",
      "Epoch 128: val_accuracy did not improve from 0.92270\n",
      "390/390 [==============================] - 23s 58ms/step - loss: 0.3762 - accuracy: 0.8686 - val_loss: 0.2479 - val_accuracy: 0.9209\n",
      "Epoch 129/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3721 - accuracy: 0.8692\n",
      "Epoch 129: val_accuracy did not improve from 0.92270\n",
      "390/390 [==============================] - 23s 58ms/step - loss: 0.3721 - accuracy: 0.8692 - val_loss: 0.2557 - val_accuracy: 0.9196\n",
      "Epoch 130/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3741 - accuracy: 0.8689\n",
      "Epoch 130: val_accuracy did not improve from 0.92270\n",
      "390/390 [==============================] - 23s 58ms/step - loss: 0.3741 - accuracy: 0.8689 - val_loss: 0.2541 - val_accuracy: 0.9173\n",
      "Epoch 131/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3700 - accuracy: 0.8709\n",
      "Epoch 131: val_accuracy did not improve from 0.92270\n",
      "390/390 [==============================] - 23s 58ms/step - loss: 0.3700 - accuracy: 0.8709 - val_loss: 0.2611 - val_accuracy: 0.9159\n",
      "Epoch 132/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3699 - accuracy: 0.8704\n",
      "Epoch 132: val_accuracy did not improve from 0.92270\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.3699 - accuracy: 0.8704 - val_loss: 0.2497 - val_accuracy: 0.9215\n",
      "Epoch 133/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3661 - accuracy: 0.8707\n",
      "Epoch 133: val_accuracy did not improve from 0.92270\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.3661 - accuracy: 0.8707 - val_loss: 0.2466 - val_accuracy: 0.9201\n",
      "Epoch 134/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3706 - accuracy: 0.8711\n",
      "Epoch 134: val_accuracy did not improve from 0.92270\n",
      "390/390 [==============================] - 23s 60ms/step - loss: 0.3706 - accuracy: 0.8711 - val_loss: 0.2528 - val_accuracy: 0.9225\n",
      "Epoch 135/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3651 - accuracy: 0.8727\n",
      "Epoch 135: val_accuracy did not improve from 0.92270\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.3651 - accuracy: 0.8727 - val_loss: 0.2446 - val_accuracy: 0.9218\n",
      "Epoch 136/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3624 - accuracy: 0.8727\n",
      "Epoch 136: val_accuracy did not improve from 0.92270\n",
      "390/390 [==============================] - 23s 58ms/step - loss: 0.3624 - accuracy: 0.8727 - val_loss: 0.2493 - val_accuracy: 0.9205\n",
      "Epoch 137/500\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.3602 - accuracy: 0.8732\n",
      "Epoch 137: val_accuracy improved from 0.92270 to 0.92500, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 24s 62ms/step - loss: 0.3602 - accuracy: 0.8733 - val_loss: 0.2367 - val_accuracy: 0.9250\n",
      "Epoch 138/500\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.3607 - accuracy: 0.8725\n",
      "Epoch 138: val_accuracy did not improve from 0.92500\n",
      "390/390 [==============================] - 21s 52ms/step - loss: 0.3605 - accuracy: 0.8725 - val_loss: 0.2412 - val_accuracy: 0.9243\n",
      "Epoch 139/500\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.3663 - accuracy: 0.8711\n",
      "Epoch 139: val_accuracy did not improve from 0.92500\n",
      "390/390 [==============================] - 20s 52ms/step - loss: 0.3659 - accuracy: 0.8714 - val_loss: 0.2458 - val_accuracy: 0.9211\n",
      "Epoch 140/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3631 - accuracy: 0.8713\n",
      "Epoch 140: val_accuracy did not improve from 0.92500\n",
      "390/390 [==============================] - 21s 53ms/step - loss: 0.3631 - accuracy: 0.8713 - val_loss: 0.2802 - val_accuracy: 0.9122\n",
      "Epoch 141/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3593 - accuracy: 0.8735\n",
      "Epoch 141: val_accuracy did not improve from 0.92500\n",
      "390/390 [==============================] - 22s 55ms/step - loss: 0.3593 - accuracy: 0.8735 - val_loss: 0.2378 - val_accuracy: 0.9231\n",
      "Epoch 142/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3601 - accuracy: 0.8731\n",
      "Epoch 142: val_accuracy did not improve from 0.92500\n",
      "390/390 [==============================] - 23s 58ms/step - loss: 0.3601 - accuracy: 0.8731 - val_loss: 0.2509 - val_accuracy: 0.9193\n",
      "Epoch 143/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3583 - accuracy: 0.8746\n",
      "Epoch 143: val_accuracy did not improve from 0.92500\n",
      "390/390 [==============================] - 23s 58ms/step - loss: 0.3583 - accuracy: 0.8746 - val_loss: 0.2492 - val_accuracy: 0.9223\n",
      "Epoch 144/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3560 - accuracy: 0.8756\n",
      "Epoch 144: val_accuracy did not improve from 0.92500\n",
      "390/390 [==============================] - 23s 60ms/step - loss: 0.3560 - accuracy: 0.8756 - val_loss: 0.2603 - val_accuracy: 0.9184\n",
      "Epoch 145/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3534 - accuracy: 0.8760\n",
      "Epoch 145: val_accuracy did not improve from 0.92500\n",
      "390/390 [==============================] - 23s 59ms/step - loss: 0.3534 - accuracy: 0.8760 - val_loss: 0.2704 - val_accuracy: 0.9174\n",
      "Epoch 146/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3595 - accuracy: 0.8740\n",
      "Epoch 146: val_accuracy did not improve from 0.92500\n",
      "390/390 [==============================] - 23s 58ms/step - loss: 0.3595 - accuracy: 0.8740 - val_loss: 0.2601 - val_accuracy: 0.9176\n",
      "Epoch 147/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3551 - accuracy: 0.8729\n",
      "Epoch 147: val_accuracy did not improve from 0.92500\n",
      "390/390 [==============================] - 23s 59ms/step - loss: 0.3551 - accuracy: 0.8729 - val_loss: 0.2448 - val_accuracy: 0.9245\n",
      "Epoch 148/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3588 - accuracy: 0.8734\n",
      "Epoch 148: val_accuracy did not improve from 0.92500\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.3588 - accuracy: 0.8734 - val_loss: 0.2482 - val_accuracy: 0.9207\n",
      "Epoch 149/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3511 - accuracy: 0.8767\n",
      "Epoch 149: val_accuracy did not improve from 0.92500\n",
      "390/390 [==============================] - 23s 58ms/step - loss: 0.3511 - accuracy: 0.8767 - val_loss: 0.2593 - val_accuracy: 0.9194\n",
      "Epoch 150/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3514 - accuracy: 0.8760\n",
      "Epoch 150: val_accuracy did not improve from 0.92500\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.3514 - accuracy: 0.8760 - val_loss: 0.2375 - val_accuracy: 0.9250\n",
      "Epoch 151/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3513 - accuracy: 0.8764\n",
      "Epoch 151: val_accuracy did not improve from 0.92500\n",
      "390/390 [==============================] - 23s 58ms/step - loss: 0.3513 - accuracy: 0.8764 - val_loss: 0.2526 - val_accuracy: 0.9205\n",
      "Epoch 152/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3538 - accuracy: 0.8752\n",
      "Epoch 152: val_accuracy did not improve from 0.92500\n",
      "390/390 [==============================] - 23s 59ms/step - loss: 0.3538 - accuracy: 0.8752 - val_loss: 0.2537 - val_accuracy: 0.9189\n",
      "Epoch 153/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3506 - accuracy: 0.8761\n",
      "Epoch 153: val_accuracy did not improve from 0.92500\n",
      "390/390 [==============================] - 23s 60ms/step - loss: 0.3506 - accuracy: 0.8761 - val_loss: 0.2380 - val_accuracy: 0.9246\n",
      "Epoch 154/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3540 - accuracy: 0.8760\n",
      "Epoch 154: val_accuracy did not improve from 0.92500\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.3540 - accuracy: 0.8760 - val_loss: 0.2530 - val_accuracy: 0.9216\n",
      "Epoch 155/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3446 - accuracy: 0.8797\n",
      "Epoch 155: val_accuracy did not improve from 0.92500\n",
      "390/390 [==============================] - 24s 60ms/step - loss: 0.3446 - accuracy: 0.8797 - val_loss: 0.2363 - val_accuracy: 0.9246\n",
      "Epoch 156/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3548 - accuracy: 0.8760\n",
      "Epoch 156: val_accuracy did not improve from 0.92500\n",
      "390/390 [==============================] - 23s 59ms/step - loss: 0.3548 - accuracy: 0.8760 - val_loss: 0.2705 - val_accuracy: 0.9131\n",
      "Epoch 157/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3421 - accuracy: 0.8802\n",
      "Epoch 157: val_accuracy did not improve from 0.92500\n",
      "390/390 [==============================] - 23s 58ms/step - loss: 0.3421 - accuracy: 0.8802 - val_loss: 0.2533 - val_accuracy: 0.9213\n",
      "Epoch 158/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3481 - accuracy: 0.8776\n",
      "Epoch 158: val_accuracy did not improve from 0.92500\n",
      "390/390 [==============================] - 23s 58ms/step - loss: 0.3481 - accuracy: 0.8776 - val_loss: 0.2423 - val_accuracy: 0.9248\n",
      "Epoch 159/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3476 - accuracy: 0.8778\n",
      "Epoch 159: val_accuracy did not improve from 0.92500\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.3476 - accuracy: 0.8778 - val_loss: 0.2522 - val_accuracy: 0.9205\n",
      "Epoch 160/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3510 - accuracy: 0.8775\n",
      "Epoch 160: val_accuracy did not improve from 0.92500\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.3510 - accuracy: 0.8775 - val_loss: 0.2464 - val_accuracy: 0.9218\n",
      "Epoch 161/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3479 - accuracy: 0.8782\n",
      "Epoch 161: val_accuracy improved from 0.92500 to 0.92590, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 26s 68ms/step - loss: 0.3479 - accuracy: 0.8782 - val_loss: 0.2365 - val_accuracy: 0.9259\n",
      "Epoch 162/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3455 - accuracy: 0.8774\n",
      "Epoch 162: val_accuracy improved from 0.92590 to 0.92610, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 28s 72ms/step - loss: 0.3455 - accuracy: 0.8774 - val_loss: 0.2309 - val_accuracy: 0.9261\n",
      "Epoch 163/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3429 - accuracy: 0.8786\n",
      "Epoch 163: val_accuracy did not improve from 0.92610\n",
      "390/390 [==============================] - 24s 60ms/step - loss: 0.3429 - accuracy: 0.8786 - val_loss: 0.2581 - val_accuracy: 0.9181\n",
      "Epoch 164/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3485 - accuracy: 0.8763\n",
      "Epoch 164: val_accuracy did not improve from 0.92610\n",
      "390/390 [==============================] - 23s 60ms/step - loss: 0.3485 - accuracy: 0.8763 - val_loss: 0.2454 - val_accuracy: 0.9233\n",
      "Epoch 165/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3394 - accuracy: 0.8816\n",
      "Epoch 165: val_accuracy did not improve from 0.92610\n",
      "390/390 [==============================] - 24s 60ms/step - loss: 0.3394 - accuracy: 0.8816 - val_loss: 0.2448 - val_accuracy: 0.9233\n",
      "Epoch 166/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3449 - accuracy: 0.8800\n",
      "Epoch 166: val_accuracy did not improve from 0.92610\n",
      "390/390 [==============================] - 23s 58ms/step - loss: 0.3449 - accuracy: 0.8800 - val_loss: 0.2349 - val_accuracy: 0.9240\n",
      "Epoch 167/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3411 - accuracy: 0.8807\n",
      "Epoch 167: val_accuracy did not improve from 0.92610\n",
      "390/390 [==============================] - 23s 59ms/step - loss: 0.3411 - accuracy: 0.8807 - val_loss: 0.2359 - val_accuracy: 0.9250\n",
      "Epoch 168/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3372 - accuracy: 0.8822\n",
      "Epoch 168: val_accuracy did not improve from 0.92610\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.3372 - accuracy: 0.8822 - val_loss: 0.2380 - val_accuracy: 0.9243\n",
      "Epoch 169/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3455 - accuracy: 0.8781\n",
      "Epoch 169: val_accuracy did not improve from 0.92610\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.3455 - accuracy: 0.8781 - val_loss: 0.2476 - val_accuracy: 0.9231\n",
      "Epoch 170/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3370 - accuracy: 0.8814\n",
      "Epoch 170: val_accuracy did not improve from 0.92610\n",
      "390/390 [==============================] - 24s 63ms/step - loss: 0.3370 - accuracy: 0.8814 - val_loss: 0.2443 - val_accuracy: 0.9243\n",
      "Epoch 171/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3366 - accuracy: 0.8825\n",
      "Epoch 171: val_accuracy did not improve from 0.92610\n",
      "390/390 [==============================] - 23s 58ms/step - loss: 0.3366 - accuracy: 0.8825 - val_loss: 0.2424 - val_accuracy: 0.9252\n",
      "Epoch 172/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3342 - accuracy: 0.8842\n",
      "Epoch 172: val_accuracy did not improve from 0.92610\n",
      "390/390 [==============================] - 23s 58ms/step - loss: 0.3342 - accuracy: 0.8842 - val_loss: 0.2437 - val_accuracy: 0.9240\n",
      "Epoch 173/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3340 - accuracy: 0.8809\n",
      "Epoch 173: val_accuracy did not improve from 0.92610\n",
      "390/390 [==============================] - 23s 59ms/step - loss: 0.3340 - accuracy: 0.8809 - val_loss: 0.2438 - val_accuracy: 0.9259\n",
      "Epoch 174/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3345 - accuracy: 0.8835\n",
      "Epoch 174: val_accuracy did not improve from 0.92610\n",
      "390/390 [==============================] - 24s 60ms/step - loss: 0.3345 - accuracy: 0.8835 - val_loss: 0.2603 - val_accuracy: 0.9222\n",
      "Epoch 175/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3325 - accuracy: 0.8835\n",
      "Epoch 175: val_accuracy did not improve from 0.92610\n",
      "390/390 [==============================] - 23s 59ms/step - loss: 0.3325 - accuracy: 0.8835 - val_loss: 0.2434 - val_accuracy: 0.9241\n",
      "Epoch 176/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3308 - accuracy: 0.8826\n",
      "Epoch 176: val_accuracy did not improve from 0.92610\n",
      "390/390 [==============================] - 23s 58ms/step - loss: 0.3308 - accuracy: 0.8826 - val_loss: 0.2587 - val_accuracy: 0.9193\n",
      "Epoch 177/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3331 - accuracy: 0.8835\n",
      "Epoch 177: val_accuracy did not improve from 0.92610\n",
      "390/390 [==============================] - 23s 58ms/step - loss: 0.3331 - accuracy: 0.8835 - val_loss: 0.2390 - val_accuracy: 0.9246\n",
      "Epoch 178/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3320 - accuracy: 0.8832\n",
      "Epoch 178: val_accuracy did not improve from 0.92610\n",
      "390/390 [==============================] - 23s 58ms/step - loss: 0.3320 - accuracy: 0.8832 - val_loss: 0.2627 - val_accuracy: 0.9174\n",
      "Epoch 179/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3275 - accuracy: 0.8854\n",
      "Epoch 179: val_accuracy improved from 0.92610 to 0.92710, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 26s 67ms/step - loss: 0.3275 - accuracy: 0.8854 - val_loss: 0.2372 - val_accuracy: 0.9271\n",
      "Epoch 180/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3297 - accuracy: 0.8829\n",
      "Epoch 180: val_accuracy did not improve from 0.92710\n",
      "390/390 [==============================] - 23s 58ms/step - loss: 0.3297 - accuracy: 0.8829 - val_loss: 0.2535 - val_accuracy: 0.9228\n",
      "Epoch 181/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3307 - accuracy: 0.8833\n",
      "Epoch 181: val_accuracy did not improve from 0.92710\n",
      "390/390 [==============================] - 23s 58ms/step - loss: 0.3307 - accuracy: 0.8833 - val_loss: 0.2333 - val_accuracy: 0.9264\n",
      "Epoch 182/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3344 - accuracy: 0.8830\n",
      "Epoch 182: val_accuracy did not improve from 0.92710\n",
      "390/390 [==============================] - 23s 58ms/step - loss: 0.3344 - accuracy: 0.8830 - val_loss: 0.2463 - val_accuracy: 0.9234\n",
      "Epoch 183/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3332 - accuracy: 0.8837\n",
      "Epoch 183: val_accuracy did not improve from 0.92710\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.3332 - accuracy: 0.8837 - val_loss: 0.2473 - val_accuracy: 0.9252\n",
      "Epoch 184/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3272 - accuracy: 0.8849\n",
      "Epoch 184: val_accuracy improved from 0.92710 to 0.92890, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 28s 73ms/step - loss: 0.3272 - accuracy: 0.8849 - val_loss: 0.2345 - val_accuracy: 0.9289\n",
      "Epoch 185/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3276 - accuracy: 0.8855\n",
      "Epoch 185: val_accuracy did not improve from 0.92890\n",
      "390/390 [==============================] - 24s 60ms/step - loss: 0.3276 - accuracy: 0.8855 - val_loss: 0.2633 - val_accuracy: 0.9184\n",
      "Epoch 186/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3309 - accuracy: 0.8847\n",
      "Epoch 186: val_accuracy did not improve from 0.92890\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.3309 - accuracy: 0.8847 - val_loss: 0.2581 - val_accuracy: 0.9204\n",
      "Epoch 187/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3267 - accuracy: 0.8851\n",
      "Epoch 187: val_accuracy did not improve from 0.92890\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.3267 - accuracy: 0.8851 - val_loss: 0.2415 - val_accuracy: 0.9256\n",
      "Epoch 188/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3302 - accuracy: 0.8860\n",
      "Epoch 188: val_accuracy did not improve from 0.92890\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.3302 - accuracy: 0.8860 - val_loss: 0.2366 - val_accuracy: 0.9256\n",
      "Epoch 189/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3301 - accuracy: 0.8848\n",
      "Epoch 189: val_accuracy did not improve from 0.92890\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.3301 - accuracy: 0.8848 - val_loss: 0.2499 - val_accuracy: 0.9230\n",
      "Epoch 190/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3256 - accuracy: 0.8865\n",
      "Epoch 190: val_accuracy did not improve from 0.92890\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.3256 - accuracy: 0.8865 - val_loss: 0.2316 - val_accuracy: 0.9287\n",
      "Epoch 191/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3276 - accuracy: 0.8851\n",
      "Epoch 191: val_accuracy did not improve from 0.92890\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.3276 - accuracy: 0.8851 - val_loss: 0.2419 - val_accuracy: 0.9264\n",
      "Epoch 192/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3284 - accuracy: 0.8846\n",
      "Epoch 192: val_accuracy did not improve from 0.92890\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.3284 - accuracy: 0.8846 - val_loss: 0.2366 - val_accuracy: 0.9276\n",
      "Epoch 193/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3223 - accuracy: 0.8871\n",
      "Epoch 193: val_accuracy improved from 0.92890 to 0.93010, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 28s 72ms/step - loss: 0.3223 - accuracy: 0.8871 - val_loss: 0.2300 - val_accuracy: 0.9301\n",
      "Epoch 194/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3230 - accuracy: 0.8865\n",
      "Epoch 194: val_accuracy did not improve from 0.93010\n",
      "390/390 [==============================] - 25s 64ms/step - loss: 0.3230 - accuracy: 0.8865 - val_loss: 0.2450 - val_accuracy: 0.9234\n",
      "Epoch 195/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3250 - accuracy: 0.8867\n",
      "Epoch 195: val_accuracy did not improve from 0.93010\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.3250 - accuracy: 0.8867 - val_loss: 0.2318 - val_accuracy: 0.9278\n",
      "Epoch 196/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3294 - accuracy: 0.8838\n",
      "Epoch 196: val_accuracy did not improve from 0.93010\n",
      "390/390 [==============================] - 25s 64ms/step - loss: 0.3294 - accuracy: 0.8838 - val_loss: 0.2301 - val_accuracy: 0.9282\n",
      "Epoch 197/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3243 - accuracy: 0.8870\n",
      "Epoch 197: val_accuracy did not improve from 0.93010\n",
      "390/390 [==============================] - 25s 64ms/step - loss: 0.3243 - accuracy: 0.8870 - val_loss: 0.2505 - val_accuracy: 0.9218\n",
      "Epoch 198/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3204 - accuracy: 0.8877\n",
      "Epoch 198: val_accuracy did not improve from 0.93010\n",
      "390/390 [==============================] - 25s 64ms/step - loss: 0.3204 - accuracy: 0.8877 - val_loss: 0.2384 - val_accuracy: 0.9259\n",
      "Epoch 199/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3221 - accuracy: 0.8882\n",
      "Epoch 199: val_accuracy did not improve from 0.93010\n",
      "390/390 [==============================] - 25s 64ms/step - loss: 0.3221 - accuracy: 0.8882 - val_loss: 0.2360 - val_accuracy: 0.9289\n",
      "Epoch 200/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3269 - accuracy: 0.8851\n",
      "Epoch 200: val_accuracy did not improve from 0.93010\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.3269 - accuracy: 0.8851 - val_loss: 0.2331 - val_accuracy: 0.9272\n",
      "Epoch 201/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3230 - accuracy: 0.8870\n",
      "Epoch 201: val_accuracy did not improve from 0.93010\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.3230 - accuracy: 0.8870 - val_loss: 0.2401 - val_accuracy: 0.9244\n",
      "Epoch 202/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3204 - accuracy: 0.8877\n",
      "Epoch 202: val_accuracy did not improve from 0.93010\n",
      "390/390 [==============================] - 24s 60ms/step - loss: 0.3204 - accuracy: 0.8877 - val_loss: 0.2302 - val_accuracy: 0.9277\n",
      "Epoch 203/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3220 - accuracy: 0.8860\n",
      "Epoch 203: val_accuracy did not improve from 0.93010\n",
      "390/390 [==============================] - 23s 60ms/step - loss: 0.3220 - accuracy: 0.8860 - val_loss: 0.2317 - val_accuracy: 0.9299\n",
      "Epoch 204/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3206 - accuracy: 0.8893\n",
      "Epoch 204: val_accuracy did not improve from 0.93010\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.3206 - accuracy: 0.8893 - val_loss: 0.2325 - val_accuracy: 0.9275\n",
      "Epoch 205/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3168 - accuracy: 0.8882\n",
      "Epoch 205: val_accuracy did not improve from 0.93010\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.3168 - accuracy: 0.8882 - val_loss: 0.2355 - val_accuracy: 0.9279\n",
      "Epoch 206/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3173 - accuracy: 0.8880\n",
      "Epoch 206: val_accuracy did not improve from 0.93010\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.3173 - accuracy: 0.8880 - val_loss: 0.2335 - val_accuracy: 0.9270\n",
      "Epoch 207/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3192 - accuracy: 0.8873\n",
      "Epoch 207: val_accuracy did not improve from 0.93010\n",
      "390/390 [==============================] - 27s 68ms/step - loss: 0.3192 - accuracy: 0.8873 - val_loss: 0.2290 - val_accuracy: 0.9272\n",
      "Epoch 208/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3191 - accuracy: 0.8876\n",
      "Epoch 208: val_accuracy did not improve from 0.93010\n",
      "390/390 [==============================] - 26s 67ms/step - loss: 0.3191 - accuracy: 0.8876 - val_loss: 0.2349 - val_accuracy: 0.9290\n",
      "Epoch 209/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3163 - accuracy: 0.8885\n",
      "Epoch 209: val_accuracy did not improve from 0.93010\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.3163 - accuracy: 0.8885 - val_loss: 0.2498 - val_accuracy: 0.9233\n",
      "Epoch 210/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3166 - accuracy: 0.8887\n",
      "Epoch 210: val_accuracy did not improve from 0.93010\n",
      "390/390 [==============================] - 26s 66ms/step - loss: 0.3166 - accuracy: 0.8887 - val_loss: 0.2392 - val_accuracy: 0.9275\n",
      "Epoch 211/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3182 - accuracy: 0.8874\n",
      "Epoch 211: val_accuracy did not improve from 0.93010\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.3182 - accuracy: 0.8874 - val_loss: 0.2329 - val_accuracy: 0.9293\n",
      "Epoch 212/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3154 - accuracy: 0.8886\n",
      "Epoch 212: val_accuracy did not improve from 0.93010\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.3154 - accuracy: 0.8886 - val_loss: 0.2320 - val_accuracy: 0.9293\n",
      "Epoch 213/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3194 - accuracy: 0.8884\n",
      "Epoch 213: val_accuracy did not improve from 0.93010\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.3194 - accuracy: 0.8884 - val_loss: 0.2470 - val_accuracy: 0.9242\n",
      "Epoch 214/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3178 - accuracy: 0.8890\n",
      "Epoch 214: val_accuracy did not improve from 0.93010\n",
      "390/390 [==============================] - 27s 68ms/step - loss: 0.3178 - accuracy: 0.8890 - val_loss: 0.2415 - val_accuracy: 0.9260\n",
      "Epoch 215/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3142 - accuracy: 0.8902\n",
      "Epoch 215: val_accuracy did not improve from 0.93010\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.3142 - accuracy: 0.8902 - val_loss: 0.2358 - val_accuracy: 0.9256\n",
      "Epoch 216/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3159 - accuracy: 0.8892\n",
      "Epoch 216: val_accuracy did not improve from 0.93010\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.3159 - accuracy: 0.8892 - val_loss: 0.2356 - val_accuracy: 0.9272\n",
      "Epoch 217/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3093 - accuracy: 0.8915\n",
      "Epoch 217: val_accuracy did not improve from 0.93010\n",
      "390/390 [==============================] - 24s 60ms/step - loss: 0.3093 - accuracy: 0.8915 - val_loss: 0.2342 - val_accuracy: 0.9265\n",
      "Epoch 218/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3119 - accuracy: 0.8905\n",
      "Epoch 218: val_accuracy did not improve from 0.93010\n",
      "390/390 [==============================] - 23s 59ms/step - loss: 0.3119 - accuracy: 0.8905 - val_loss: 0.2310 - val_accuracy: 0.9278\n",
      "Epoch 219/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3123 - accuracy: 0.8904\n",
      "Epoch 219: val_accuracy did not improve from 0.93010\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.3123 - accuracy: 0.8904 - val_loss: 0.2290 - val_accuracy: 0.9274\n",
      "Epoch 220/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3108 - accuracy: 0.8906\n",
      "Epoch 220: val_accuracy did not improve from 0.93010\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.3108 - accuracy: 0.8906 - val_loss: 0.2388 - val_accuracy: 0.9260\n",
      "Epoch 221/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3107 - accuracy: 0.8910\n",
      "Epoch 221: val_accuracy did not improve from 0.93010\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.3107 - accuracy: 0.8910 - val_loss: 0.2317 - val_accuracy: 0.9276\n",
      "Epoch 222/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3108 - accuracy: 0.8911\n",
      "Epoch 222: val_accuracy did not improve from 0.93010\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.3108 - accuracy: 0.8911 - val_loss: 0.2349 - val_accuracy: 0.9287\n",
      "Epoch 223/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3147 - accuracy: 0.8902\n",
      "Epoch 223: val_accuracy did not improve from 0.93010\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.3147 - accuracy: 0.8902 - val_loss: 0.2349 - val_accuracy: 0.9284\n",
      "Epoch 224/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3139 - accuracy: 0.8898\n",
      "Epoch 224: val_accuracy did not improve from 0.93010\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.3139 - accuracy: 0.8898 - val_loss: 0.2334 - val_accuracy: 0.9298\n",
      "Epoch 225/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3135 - accuracy: 0.8900\n",
      "Epoch 225: val_accuracy did not improve from 0.93010\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.3135 - accuracy: 0.8900 - val_loss: 0.2391 - val_accuracy: 0.9283\n",
      "Epoch 226/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3072 - accuracy: 0.8923\n",
      "Epoch 226: val_accuracy did not improve from 0.93010\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.3072 - accuracy: 0.8923 - val_loss: 0.2356 - val_accuracy: 0.9276\n",
      "Epoch 227/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3110 - accuracy: 0.8904\n",
      "Epoch 227: val_accuracy did not improve from 0.93010\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.3110 - accuracy: 0.8904 - val_loss: 0.2348 - val_accuracy: 0.9283\n",
      "Epoch 228/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3048 - accuracy: 0.8936\n",
      "Epoch 228: val_accuracy did not improve from 0.93010\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.3048 - accuracy: 0.8936 - val_loss: 0.2378 - val_accuracy: 0.9294\n",
      "Epoch 229/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3080 - accuracy: 0.8930\n",
      "Epoch 229: val_accuracy did not improve from 0.93010\n",
      "390/390 [==============================] - 25s 64ms/step - loss: 0.3080 - accuracy: 0.8930 - val_loss: 0.2337 - val_accuracy: 0.9282\n",
      "Epoch 230/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3052 - accuracy: 0.8926\n",
      "Epoch 230: val_accuracy did not improve from 0.93010\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.3052 - accuracy: 0.8926 - val_loss: 0.2430 - val_accuracy: 0.9255\n",
      "Epoch 231/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3106 - accuracy: 0.8921\n",
      "Epoch 231: val_accuracy improved from 0.93010 to 0.93130, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 28s 72ms/step - loss: 0.3106 - accuracy: 0.8921 - val_loss: 0.2296 - val_accuracy: 0.9313\n",
      "Epoch 232/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3040 - accuracy: 0.8944\n",
      "Epoch 232: val_accuracy did not improve from 0.93130\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.3040 - accuracy: 0.8944 - val_loss: 0.2206 - val_accuracy: 0.9310\n",
      "Epoch 233/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3039 - accuracy: 0.8938\n",
      "Epoch 233: val_accuracy did not improve from 0.93130\n",
      "390/390 [==============================] - 24s 63ms/step - loss: 0.3039 - accuracy: 0.8938 - val_loss: 0.2444 - val_accuracy: 0.9262\n",
      "Epoch 234/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3088 - accuracy: 0.8923\n",
      "Epoch 234: val_accuracy did not improve from 0.93130\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.3088 - accuracy: 0.8923 - val_loss: 0.2265 - val_accuracy: 0.9301\n",
      "Epoch 235/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3046 - accuracy: 0.8941\n",
      "Epoch 235: val_accuracy did not improve from 0.93130\n",
      "390/390 [==============================] - 23s 59ms/step - loss: 0.3046 - accuracy: 0.8941 - val_loss: 0.2316 - val_accuracy: 0.9283\n",
      "Epoch 236/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3100 - accuracy: 0.8903\n",
      "Epoch 236: val_accuracy did not improve from 0.93130\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.3100 - accuracy: 0.8903 - val_loss: 0.2412 - val_accuracy: 0.9262\n",
      "Epoch 237/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3074 - accuracy: 0.8918\n",
      "Epoch 237: val_accuracy did not improve from 0.93130\n",
      "390/390 [==============================] - 26s 67ms/step - loss: 0.3074 - accuracy: 0.8918 - val_loss: 0.2424 - val_accuracy: 0.9254\n",
      "Epoch 238/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3033 - accuracy: 0.8942\n",
      "Epoch 238: val_accuracy did not improve from 0.93130\n",
      "390/390 [==============================] - 25s 64ms/step - loss: 0.3033 - accuracy: 0.8942 - val_loss: 0.2337 - val_accuracy: 0.9289\n",
      "Epoch 239/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3014 - accuracy: 0.8949\n",
      "Epoch 239: val_accuracy did not improve from 0.93130\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.3014 - accuracy: 0.8949 - val_loss: 0.2306 - val_accuracy: 0.9291\n",
      "Epoch 240/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3042 - accuracy: 0.8921\n",
      "Epoch 240: val_accuracy did not improve from 0.93130\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.3042 - accuracy: 0.8921 - val_loss: 0.2345 - val_accuracy: 0.9281\n",
      "Epoch 241/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3030 - accuracy: 0.8939\n",
      "Epoch 241: val_accuracy did not improve from 0.93130\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.3030 - accuracy: 0.8939 - val_loss: 0.2417 - val_accuracy: 0.9245\n",
      "Epoch 242/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2974 - accuracy: 0.8952\n",
      "Epoch 242: val_accuracy did not improve from 0.93130\n",
      "390/390 [==============================] - 23s 59ms/step - loss: 0.2974 - accuracy: 0.8952 - val_loss: 0.2374 - val_accuracy: 0.9267\n",
      "Epoch 243/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3034 - accuracy: 0.8929\n",
      "Epoch 243: val_accuracy did not improve from 0.93130\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.3034 - accuracy: 0.8929 - val_loss: 0.2326 - val_accuracy: 0.9292\n",
      "Epoch 244/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3021 - accuracy: 0.8941\n",
      "Epoch 244: val_accuracy did not improve from 0.93130\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.3021 - accuracy: 0.8941 - val_loss: 0.2310 - val_accuracy: 0.9296\n",
      "Epoch 245/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3020 - accuracy: 0.8942\n",
      "Epoch 245: val_accuracy did not improve from 0.93130\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.3020 - accuracy: 0.8942 - val_loss: 0.2269 - val_accuracy: 0.9303\n",
      "Epoch 246/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3030 - accuracy: 0.8943\n",
      "Epoch 246: val_accuracy did not improve from 0.93130\n",
      "390/390 [==============================] - 24s 63ms/step - loss: 0.3030 - accuracy: 0.8943 - val_loss: 0.2340 - val_accuracy: 0.9286\n",
      "Epoch 247/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3015 - accuracy: 0.8941\n",
      "Epoch 247: val_accuracy did not improve from 0.93130\n",
      "390/390 [==============================] - 24s 60ms/step - loss: 0.3015 - accuracy: 0.8941 - val_loss: 0.2444 - val_accuracy: 0.9268\n",
      "Epoch 248/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3004 - accuracy: 0.8958\n",
      "Epoch 248: val_accuracy did not improve from 0.93130\n",
      "390/390 [==============================] - 25s 64ms/step - loss: 0.3004 - accuracy: 0.8958 - val_loss: 0.2303 - val_accuracy: 0.9304\n",
      "Epoch 249/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2941 - accuracy: 0.8965\n",
      "Epoch 249: val_accuracy did not improve from 0.93130\n",
      "390/390 [==============================] - 25s 64ms/step - loss: 0.2941 - accuracy: 0.8965 - val_loss: 0.2257 - val_accuracy: 0.9298\n",
      "Epoch 250/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3055 - accuracy: 0.8937\n",
      "Epoch 250: val_accuracy did not improve from 0.93130\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.3055 - accuracy: 0.8937 - val_loss: 0.2309 - val_accuracy: 0.9312\n",
      "Epoch 251/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2992 - accuracy: 0.8953\n",
      "Epoch 251: val_accuracy did not improve from 0.93130\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.2992 - accuracy: 0.8953 - val_loss: 0.2384 - val_accuracy: 0.9270\n",
      "Epoch 252/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3047 - accuracy: 0.8937\n",
      "Epoch 252: val_accuracy did not improve from 0.93130\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.3047 - accuracy: 0.8937 - val_loss: 0.2381 - val_accuracy: 0.9281\n",
      "Epoch 253/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2958 - accuracy: 0.8965\n",
      "Epoch 253: val_accuracy did not improve from 0.93130\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.2958 - accuracy: 0.8965 - val_loss: 0.2279 - val_accuracy: 0.9303\n",
      "Epoch 254/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2925 - accuracy: 0.8978\n",
      "Epoch 254: val_accuracy did not improve from 0.93130\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.2925 - accuracy: 0.8978 - val_loss: 0.2458 - val_accuracy: 0.9259\n",
      "Epoch 255/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2962 - accuracy: 0.8977\n",
      "Epoch 255: val_accuracy did not improve from 0.93130\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.2962 - accuracy: 0.8977 - val_loss: 0.2325 - val_accuracy: 0.9289\n",
      "Epoch 256/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2987 - accuracy: 0.8937\n",
      "Epoch 256: val_accuracy did not improve from 0.93130\n",
      "390/390 [==============================] - 23s 59ms/step - loss: 0.2987 - accuracy: 0.8937 - val_loss: 0.2242 - val_accuracy: 0.9304\n",
      "Epoch 257/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2990 - accuracy: 0.8954\n",
      "Epoch 257: val_accuracy did not improve from 0.93130\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.2990 - accuracy: 0.8954 - val_loss: 0.2377 - val_accuracy: 0.9278\n",
      "Epoch 258/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2974 - accuracy: 0.8954\n",
      "Epoch 258: val_accuracy did not improve from 0.93130\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.2974 - accuracy: 0.8954 - val_loss: 0.2307 - val_accuracy: 0.9287\n",
      "Epoch 259/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2922 - accuracy: 0.8975\n",
      "Epoch 259: val_accuracy improved from 0.93130 to 0.93140, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 28s 72ms/step - loss: 0.2922 - accuracy: 0.8975 - val_loss: 0.2286 - val_accuracy: 0.9314\n",
      "Epoch 260/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2971 - accuracy: 0.8965\n",
      "Epoch 260: val_accuracy did not improve from 0.93140\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.2971 - accuracy: 0.8965 - val_loss: 0.2313 - val_accuracy: 0.9298\n",
      "Epoch 261/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3002 - accuracy: 0.8945\n",
      "Epoch 261: val_accuracy did not improve from 0.93140\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.3002 - accuracy: 0.8945 - val_loss: 0.2313 - val_accuracy: 0.9302\n",
      "Epoch 262/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2953 - accuracy: 0.8961\n",
      "Epoch 262: val_accuracy did not improve from 0.93140\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.2953 - accuracy: 0.8961 - val_loss: 0.2301 - val_accuracy: 0.9302\n",
      "Epoch 263/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2944 - accuracy: 0.8963\n",
      "Epoch 263: val_accuracy did not improve from 0.93140\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.2944 - accuracy: 0.8963 - val_loss: 0.2374 - val_accuracy: 0.9264\n",
      "Epoch 264/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2993 - accuracy: 0.8968\n",
      "Epoch 264: val_accuracy did not improve from 0.93140\n",
      "390/390 [==============================] - 23s 59ms/step - loss: 0.2993 - accuracy: 0.8968 - val_loss: 0.2272 - val_accuracy: 0.9300\n",
      "Epoch 265/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2896 - accuracy: 0.8988\n",
      "Epoch 265: val_accuracy did not improve from 0.93140\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.2896 - accuracy: 0.8988 - val_loss: 0.2272 - val_accuracy: 0.9285\n",
      "Epoch 266/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2968 - accuracy: 0.8950\n",
      "Epoch 266: val_accuracy did not improve from 0.93140\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.2968 - accuracy: 0.8950 - val_loss: 0.2290 - val_accuracy: 0.9300\n",
      "Epoch 267/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2929 - accuracy: 0.8978\n",
      "Epoch 267: val_accuracy improved from 0.93140 to 0.93320, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 29s 73ms/step - loss: 0.2929 - accuracy: 0.8978 - val_loss: 0.2259 - val_accuracy: 0.9332\n",
      "Epoch 268/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2959 - accuracy: 0.8960\n",
      "Epoch 268: val_accuracy did not improve from 0.93320\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.2959 - accuracy: 0.8960 - val_loss: 0.2271 - val_accuracy: 0.9295\n",
      "Epoch 269/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2879 - accuracy: 0.8999\n",
      "Epoch 269: val_accuracy did not improve from 0.93320\n",
      "390/390 [==============================] - 23s 60ms/step - loss: 0.2879 - accuracy: 0.8999 - val_loss: 0.2271 - val_accuracy: 0.9293\n",
      "Epoch 270/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2920 - accuracy: 0.8986\n",
      "Epoch 270: val_accuracy did not improve from 0.93320\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.2920 - accuracy: 0.8986 - val_loss: 0.2245 - val_accuracy: 0.9306\n",
      "Epoch 271/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2978 - accuracy: 0.8962\n",
      "Epoch 271: val_accuracy did not improve from 0.93320\n",
      "390/390 [==============================] - 23s 60ms/step - loss: 0.2978 - accuracy: 0.8962 - val_loss: 0.2269 - val_accuracy: 0.9285\n",
      "Epoch 272/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2892 - accuracy: 0.8990\n",
      "Epoch 272: val_accuracy did not improve from 0.93320\n",
      "390/390 [==============================] - 23s 59ms/step - loss: 0.2892 - accuracy: 0.8990 - val_loss: 0.2305 - val_accuracy: 0.9303\n",
      "Epoch 273/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2883 - accuracy: 0.8978\n",
      "Epoch 273: val_accuracy did not improve from 0.93320\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.2883 - accuracy: 0.8978 - val_loss: 0.2270 - val_accuracy: 0.9315\n",
      "Epoch 274/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2907 - accuracy: 0.8984\n",
      "Epoch 274: val_accuracy did not improve from 0.93320\n",
      "390/390 [==============================] - 24s 63ms/step - loss: 0.2907 - accuracy: 0.8984 - val_loss: 0.2253 - val_accuracy: 0.9300\n",
      "Epoch 275/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2933 - accuracy: 0.8970\n",
      "Epoch 275: val_accuracy did not improve from 0.93320\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.2933 - accuracy: 0.8970 - val_loss: 0.2265 - val_accuracy: 0.9299\n",
      "Epoch 276/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2947 - accuracy: 0.8965\n",
      "Epoch 276: val_accuracy did not improve from 0.93320\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.2947 - accuracy: 0.8965 - val_loss: 0.2297 - val_accuracy: 0.9309\n",
      "Epoch 277/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2861 - accuracy: 0.9005\n",
      "Epoch 277: val_accuracy did not improve from 0.93320\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.2861 - accuracy: 0.9005 - val_loss: 0.2394 - val_accuracy: 0.9310\n",
      "Epoch 278/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2895 - accuracy: 0.8972\n",
      "Epoch 278: val_accuracy did not improve from 0.93320\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.2895 - accuracy: 0.8972 - val_loss: 0.2285 - val_accuracy: 0.9302\n",
      "Epoch 279/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2913 - accuracy: 0.8969\n",
      "Epoch 279: val_accuracy did not improve from 0.93320\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.2913 - accuracy: 0.8969 - val_loss: 0.2285 - val_accuracy: 0.9289\n",
      "Epoch 280/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2888 - accuracy: 0.8988\n",
      "Epoch 280: val_accuracy did not improve from 0.93320\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.2888 - accuracy: 0.8988 - val_loss: 0.2271 - val_accuracy: 0.9313\n",
      "Epoch 281/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2880 - accuracy: 0.8991\n",
      "Epoch 281: val_accuracy improved from 0.93320 to 0.93330, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 28s 72ms/step - loss: 0.2880 - accuracy: 0.8991 - val_loss: 0.2189 - val_accuracy: 0.9333\n",
      "Epoch 282/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2881 - accuracy: 0.9001\n",
      "Epoch 282: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 25s 64ms/step - loss: 0.2881 - accuracy: 0.9001 - val_loss: 0.2260 - val_accuracy: 0.9316\n",
      "Epoch 283/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2891 - accuracy: 0.9000\n",
      "Epoch 283: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.2891 - accuracy: 0.9000 - val_loss: 0.2343 - val_accuracy: 0.9289\n",
      "Epoch 284/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2840 - accuracy: 0.9001\n",
      "Epoch 284: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.2840 - accuracy: 0.9001 - val_loss: 0.2289 - val_accuracy: 0.9311\n",
      "Epoch 285/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2840 - accuracy: 0.9009\n",
      "Epoch 285: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.2840 - accuracy: 0.9009 - val_loss: 0.2301 - val_accuracy: 0.9295\n",
      "Epoch 286/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2847 - accuracy: 0.8998\n",
      "Epoch 286: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.2847 - accuracy: 0.8998 - val_loss: 0.2284 - val_accuracy: 0.9313\n",
      "Epoch 287/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2892 - accuracy: 0.8985\n",
      "Epoch 287: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.2892 - accuracy: 0.8985 - val_loss: 0.2267 - val_accuracy: 0.9307\n",
      "Epoch 288/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2878 - accuracy: 0.9007\n",
      "Epoch 288: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.2878 - accuracy: 0.9007 - val_loss: 0.2294 - val_accuracy: 0.9303\n",
      "Epoch 289/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2833 - accuracy: 0.9006\n",
      "Epoch 289: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 25s 64ms/step - loss: 0.2833 - accuracy: 0.9006 - val_loss: 0.2462 - val_accuracy: 0.9241\n",
      "Epoch 290/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2854 - accuracy: 0.8994\n",
      "Epoch 290: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.2854 - accuracy: 0.8994 - val_loss: 0.2289 - val_accuracy: 0.9306\n",
      "Epoch 291/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2898 - accuracy: 0.8989\n",
      "Epoch 291: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.2898 - accuracy: 0.8989 - val_loss: 0.2336 - val_accuracy: 0.9306\n",
      "Epoch 292/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2857 - accuracy: 0.9014\n",
      "Epoch 292: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.2857 - accuracy: 0.9014 - val_loss: 0.2241 - val_accuracy: 0.9309\n",
      "Epoch 293/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2822 - accuracy: 0.9015\n",
      "Epoch 293: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 22s 55ms/step - loss: 0.2822 - accuracy: 0.9015 - val_loss: 0.2348 - val_accuracy: 0.9264\n",
      "Epoch 294/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2866 - accuracy: 0.8994\n",
      "Epoch 294: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 21s 53ms/step - loss: 0.2866 - accuracy: 0.8994 - val_loss: 0.2357 - val_accuracy: 0.9293\n",
      "Epoch 295/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2856 - accuracy: 0.9000\n",
      "Epoch 295: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 22s 56ms/step - loss: 0.2856 - accuracy: 0.9000 - val_loss: 0.2211 - val_accuracy: 0.9317\n",
      "Epoch 296/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2903 - accuracy: 0.8981\n",
      "Epoch 296: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 21s 55ms/step - loss: 0.2903 - accuracy: 0.8981 - val_loss: 0.2322 - val_accuracy: 0.9305\n",
      "Epoch 297/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2805 - accuracy: 0.9024\n",
      "Epoch 297: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 22s 57ms/step - loss: 0.2805 - accuracy: 0.9024 - val_loss: 0.2378 - val_accuracy: 0.9289\n",
      "Epoch 298/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2839 - accuracy: 0.9008\n",
      "Epoch 298: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.2839 - accuracy: 0.9008 - val_loss: 0.2242 - val_accuracy: 0.9317\n",
      "Epoch 299/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2895 - accuracy: 0.8978\n",
      "Epoch 299: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 23s 59ms/step - loss: 0.2895 - accuracy: 0.8978 - val_loss: 0.2267 - val_accuracy: 0.9318\n",
      "Epoch 300/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2899 - accuracy: 0.8972\n",
      "Epoch 300: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 24s 60ms/step - loss: 0.2899 - accuracy: 0.8972 - val_loss: 0.2277 - val_accuracy: 0.9327\n",
      "Epoch 301/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2846 - accuracy: 0.9004\n",
      "Epoch 301: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.2846 - accuracy: 0.9004 - val_loss: 0.2364 - val_accuracy: 0.9308\n",
      "Epoch 302/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2845 - accuracy: 0.8994\n",
      "Epoch 302: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 24s 63ms/step - loss: 0.2845 - accuracy: 0.8994 - val_loss: 0.2301 - val_accuracy: 0.9296\n",
      "Epoch 303/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2841 - accuracy: 0.9002\n",
      "Epoch 303: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.2841 - accuracy: 0.9002 - val_loss: 0.2295 - val_accuracy: 0.9298\n",
      "Epoch 304/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2792 - accuracy: 0.9023\n",
      "Epoch 304: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.2792 - accuracy: 0.9023 - val_loss: 0.2320 - val_accuracy: 0.9289\n",
      "Epoch 305/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2844 - accuracy: 0.9007\n",
      "Epoch 305: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 24s 63ms/step - loss: 0.2844 - accuracy: 0.9007 - val_loss: 0.2287 - val_accuracy: 0.9298\n",
      "Epoch 306/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2822 - accuracy: 0.9010\n",
      "Epoch 306: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.2822 - accuracy: 0.9010 - val_loss: 0.2216 - val_accuracy: 0.9325\n",
      "Epoch 307/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2850 - accuracy: 0.9012\n",
      "Epoch 307: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.2850 - accuracy: 0.9012 - val_loss: 0.2293 - val_accuracy: 0.9315\n",
      "Epoch 308/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2812 - accuracy: 0.9024\n",
      "Epoch 308: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 24s 63ms/step - loss: 0.2812 - accuracy: 0.9024 - val_loss: 0.2367 - val_accuracy: 0.9299\n",
      "Epoch 309/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2835 - accuracy: 0.9008\n",
      "Epoch 309: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.2835 - accuracy: 0.9008 - val_loss: 0.2332 - val_accuracy: 0.9295\n",
      "Epoch 310/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2786 - accuracy: 0.9029\n",
      "Epoch 310: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 24s 60ms/step - loss: 0.2786 - accuracy: 0.9029 - val_loss: 0.2259 - val_accuracy: 0.9294\n",
      "Epoch 311/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2840 - accuracy: 0.9006\n",
      "Epoch 311: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.2840 - accuracy: 0.9006 - val_loss: 0.2248 - val_accuracy: 0.9317\n",
      "Epoch 312/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2829 - accuracy: 0.9008\n",
      "Epoch 312: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.2829 - accuracy: 0.9008 - val_loss: 0.2290 - val_accuracy: 0.9299\n",
      "Epoch 313/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2814 - accuracy: 0.9027\n",
      "Epoch 313: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.2814 - accuracy: 0.9027 - val_loss: 0.2277 - val_accuracy: 0.9307\n",
      "Epoch 314/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2787 - accuracy: 0.9027\n",
      "Epoch 314: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.2787 - accuracy: 0.9027 - val_loss: 0.2319 - val_accuracy: 0.9294\n",
      "Epoch 315/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2754 - accuracy: 0.9056\n",
      "Epoch 315: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 25s 64ms/step - loss: 0.2754 - accuracy: 0.9056 - val_loss: 0.2308 - val_accuracy: 0.9305\n",
      "Epoch 316/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2725 - accuracy: 0.9053\n",
      "Epoch 316: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.2725 - accuracy: 0.9053 - val_loss: 0.2264 - val_accuracy: 0.9317\n",
      "Epoch 317/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2731 - accuracy: 0.9044\n",
      "Epoch 317: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 24s 63ms/step - loss: 0.2731 - accuracy: 0.9044 - val_loss: 0.2325 - val_accuracy: 0.9285\n",
      "Epoch 318/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2793 - accuracy: 0.9028\n",
      "Epoch 318: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.2793 - accuracy: 0.9028 - val_loss: 0.2278 - val_accuracy: 0.9302\n",
      "Epoch 319/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2782 - accuracy: 0.9026\n",
      "Epoch 319: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.2782 - accuracy: 0.9026 - val_loss: 0.2324 - val_accuracy: 0.9300\n",
      "Epoch 320/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2822 - accuracy: 0.9020\n",
      "Epoch 320: val_accuracy did not improve from 0.93330\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.2822 - accuracy: 0.9020 - val_loss: 0.2274 - val_accuracy: 0.9311\n",
      "Epoch 321/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2808 - accuracy: 0.9020\n",
      "Epoch 321: val_accuracy improved from 0.93330 to 0.93420, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 28s 72ms/step - loss: 0.2808 - accuracy: 0.9020 - val_loss: 0.2261 - val_accuracy: 0.9342\n",
      "Epoch 322/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2706 - accuracy: 0.9051\n",
      "Epoch 322: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.2706 - accuracy: 0.9051 - val_loss: 0.2420 - val_accuracy: 0.9281\n",
      "Epoch 323/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2772 - accuracy: 0.9035\n",
      "Epoch 323: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.2772 - accuracy: 0.9035 - val_loss: 0.2272 - val_accuracy: 0.9310\n",
      "Epoch 324/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2760 - accuracy: 0.9031\n",
      "Epoch 324: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.2760 - accuracy: 0.9031 - val_loss: 0.2292 - val_accuracy: 0.9316\n",
      "Epoch 325/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2814 - accuracy: 0.9014\n",
      "Epoch 325: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 24s 60ms/step - loss: 0.2814 - accuracy: 0.9014 - val_loss: 0.2343 - val_accuracy: 0.9267\n",
      "Epoch 326/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2803 - accuracy: 0.9026\n",
      "Epoch 326: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.2803 - accuracy: 0.9026 - val_loss: 0.2228 - val_accuracy: 0.9336\n",
      "Epoch 327/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2781 - accuracy: 0.9021\n",
      "Epoch 327: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 23s 60ms/step - loss: 0.2781 - accuracy: 0.9021 - val_loss: 0.2280 - val_accuracy: 0.9311\n",
      "Epoch 328/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2777 - accuracy: 0.9022\n",
      "Epoch 328: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 23s 59ms/step - loss: 0.2777 - accuracy: 0.9022 - val_loss: 0.2285 - val_accuracy: 0.9298\n",
      "Epoch 329/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2711 - accuracy: 0.9050\n",
      "Epoch 329: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.2711 - accuracy: 0.9050 - val_loss: 0.2331 - val_accuracy: 0.9290\n",
      "Epoch 330/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2747 - accuracy: 0.9040\n",
      "Epoch 330: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 23s 60ms/step - loss: 0.2747 - accuracy: 0.9040 - val_loss: 0.2272 - val_accuracy: 0.9308\n",
      "Epoch 331/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2745 - accuracy: 0.9041\n",
      "Epoch 331: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.2745 - accuracy: 0.9041 - val_loss: 0.2274 - val_accuracy: 0.9312\n",
      "Epoch 332/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2750 - accuracy: 0.9036\n",
      "Epoch 332: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 24s 63ms/step - loss: 0.2750 - accuracy: 0.9036 - val_loss: 0.2352 - val_accuracy: 0.9284\n",
      "Epoch 333/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2731 - accuracy: 0.9042\n",
      "Epoch 333: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 24s 63ms/step - loss: 0.2731 - accuracy: 0.9042 - val_loss: 0.2218 - val_accuracy: 0.9333\n",
      "Epoch 334/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2698 - accuracy: 0.9059\n",
      "Epoch 334: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 25s 63ms/step - loss: 0.2698 - accuracy: 0.9059 - val_loss: 0.2297 - val_accuracy: 0.9313\n",
      "Epoch 335/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2725 - accuracy: 0.9055\n",
      "Epoch 335: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 24s 63ms/step - loss: 0.2725 - accuracy: 0.9055 - val_loss: 0.2282 - val_accuracy: 0.9308\n",
      "Epoch 336/500\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2742 - accuracy: 0.9050\n",
      "Epoch 336: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 22s 57ms/step - loss: 0.2743 - accuracy: 0.9050 - val_loss: 0.2296 - val_accuracy: 0.9305\n",
      "Epoch 337/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2797 - accuracy: 0.9014\n",
      "Epoch 337: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 22s 56ms/step - loss: 0.2797 - accuracy: 0.9014 - val_loss: 0.2313 - val_accuracy: 0.9313\n",
      "Epoch 338/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2743 - accuracy: 0.9029\n",
      "Epoch 338: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 21s 54ms/step - loss: 0.2743 - accuracy: 0.9029 - val_loss: 0.2258 - val_accuracy: 0.9318\n",
      "Epoch 339/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2766 - accuracy: 0.9037\n",
      "Epoch 339: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 22s 56ms/step - loss: 0.2766 - accuracy: 0.9037 - val_loss: 0.2308 - val_accuracy: 0.9310\n",
      "Epoch 340/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2760 - accuracy: 0.9030\n",
      "Epoch 340: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 23s 59ms/step - loss: 0.2760 - accuracy: 0.9030 - val_loss: 0.2285 - val_accuracy: 0.9308\n",
      "Epoch 341/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2736 - accuracy: 0.9041\n",
      "Epoch 341: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.2736 - accuracy: 0.9041 - val_loss: 0.2250 - val_accuracy: 0.9310\n",
      "Epoch 342/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2736 - accuracy: 0.9035\n",
      "Epoch 342: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 22s 57ms/step - loss: 0.2736 - accuracy: 0.9035 - val_loss: 0.2223 - val_accuracy: 0.9333\n",
      "Epoch 343/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2760 - accuracy: 0.9033\n",
      "Epoch 343: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 23s 58ms/step - loss: 0.2760 - accuracy: 0.9033 - val_loss: 0.2240 - val_accuracy: 0.9319\n",
      "Epoch 344/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2697 - accuracy: 0.9056\n",
      "Epoch 344: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.2697 - accuracy: 0.9056 - val_loss: 0.2343 - val_accuracy: 0.9304\n",
      "Epoch 345/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2695 - accuracy: 0.9067\n",
      "Epoch 345: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.2695 - accuracy: 0.9067 - val_loss: 0.2291 - val_accuracy: 0.9301\n",
      "Epoch 346/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2708 - accuracy: 0.9051\n",
      "Epoch 346: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.2708 - accuracy: 0.9051 - val_loss: 0.2282 - val_accuracy: 0.9306\n",
      "Epoch 347/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2683 - accuracy: 0.9058\n",
      "Epoch 347: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.2683 - accuracy: 0.9058 - val_loss: 0.2279 - val_accuracy: 0.9300\n",
      "Epoch 348/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2769 - accuracy: 0.9026\n",
      "Epoch 348: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.2769 - accuracy: 0.9026 - val_loss: 0.2314 - val_accuracy: 0.9287\n",
      "Epoch 349/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2766 - accuracy: 0.9041\n",
      "Epoch 349: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.2766 - accuracy: 0.9041 - val_loss: 0.2290 - val_accuracy: 0.9306\n",
      "Epoch 350/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2706 - accuracy: 0.9048\n",
      "Epoch 350: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 24s 60ms/step - loss: 0.2706 - accuracy: 0.9048 - val_loss: 0.2301 - val_accuracy: 0.9306\n",
      "Epoch 351/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2708 - accuracy: 0.9048\n",
      "Epoch 351: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.2708 - accuracy: 0.9048 - val_loss: 0.2306 - val_accuracy: 0.9298\n",
      "Epoch 352/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2715 - accuracy: 0.9044\n",
      "Epoch 352: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.2715 - accuracy: 0.9044 - val_loss: 0.2272 - val_accuracy: 0.9319\n",
      "Epoch 353/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2682 - accuracy: 0.9054\n",
      "Epoch 353: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.2682 - accuracy: 0.9054 - val_loss: 0.2265 - val_accuracy: 0.9322\n",
      "Epoch 354/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2691 - accuracy: 0.9071\n",
      "Epoch 354: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.2691 - accuracy: 0.9071 - val_loss: 0.2285 - val_accuracy: 0.9309\n",
      "Epoch 355/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2694 - accuracy: 0.9056\n",
      "Epoch 355: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.2694 - accuracy: 0.9056 - val_loss: 0.2258 - val_accuracy: 0.9330\n",
      "Epoch 356/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2710 - accuracy: 0.9062\n",
      "Epoch 356: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.2710 - accuracy: 0.9062 - val_loss: 0.2312 - val_accuracy: 0.9294\n",
      "Epoch 357/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2729 - accuracy: 0.9046\n",
      "Epoch 357: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.2729 - accuracy: 0.9046 - val_loss: 0.2233 - val_accuracy: 0.9321\n",
      "Epoch 358/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2688 - accuracy: 0.9065\n",
      "Epoch 358: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 24s 62ms/step - loss: 0.2688 - accuracy: 0.9065 - val_loss: 0.2266 - val_accuracy: 0.9339\n",
      "Epoch 359/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2740 - accuracy: 0.9041\n",
      "Epoch 359: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.2740 - accuracy: 0.9041 - val_loss: 0.2270 - val_accuracy: 0.9331\n",
      "Epoch 360/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2710 - accuracy: 0.9052\n",
      "Epoch 360: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.2710 - accuracy: 0.9052 - val_loss: 0.2294 - val_accuracy: 0.9327\n",
      "Epoch 361/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2721 - accuracy: 0.9060\n",
      "Epoch 361: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.2721 - accuracy: 0.9060 - val_loss: 0.2338 - val_accuracy: 0.9314\n",
      "Epoch 362/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2695 - accuracy: 0.9044\n",
      "Epoch 362: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.2695 - accuracy: 0.9044 - val_loss: 0.2263 - val_accuracy: 0.9329\n",
      "Epoch 363/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2692 - accuracy: 0.9053\n",
      "Epoch 363: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 24s 60ms/step - loss: 0.2692 - accuracy: 0.9053 - val_loss: 0.2238 - val_accuracy: 0.9316\n",
      "Epoch 364/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2684 - accuracy: 0.9068\n",
      "Epoch 364: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 23s 60ms/step - loss: 0.2684 - accuracy: 0.9068 - val_loss: 0.2294 - val_accuracy: 0.9309\n",
      "Epoch 365/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2729 - accuracy: 0.9039\n",
      "Epoch 365: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.2729 - accuracy: 0.9039 - val_loss: 0.2344 - val_accuracy: 0.9301\n",
      "Epoch 366/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2730 - accuracy: 0.9053\n",
      "Epoch 366: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 23s 60ms/step - loss: 0.2730 - accuracy: 0.9053 - val_loss: 0.2234 - val_accuracy: 0.9323\n",
      "Epoch 367/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2690 - accuracy: 0.9066\n",
      "Epoch 367: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 24s 61ms/step - loss: 0.2690 - accuracy: 0.9066 - val_loss: 0.2310 - val_accuracy: 0.9314\n",
      "Epoch 368/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2719 - accuracy: 0.9058\n",
      "Epoch 368: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 22s 56ms/step - loss: 0.2719 - accuracy: 0.9058 - val_loss: 0.2282 - val_accuracy: 0.9312\n",
      "Epoch 369/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2681 - accuracy: 0.9065\n",
      "Epoch 369: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 22s 56ms/step - loss: 0.2681 - accuracy: 0.9065 - val_loss: 0.2353 - val_accuracy: 0.9303\n",
      "Epoch 370/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2710 - accuracy: 0.9049\n",
      "Epoch 370: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 22s 58ms/step - loss: 0.2710 - accuracy: 0.9049 - val_loss: 0.2259 - val_accuracy: 0.9309\n",
      "Epoch 371/500\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2637 - accuracy: 0.9079\n",
      "Epoch 371: val_accuracy did not improve from 0.93420\n",
      "390/390 [==============================] - 24s 60ms/step - loss: 0.2637 - accuracy: 0.9079 - val_loss: 0.2329 - val_accuracy: 0.9316\n",
      "Epoch 371: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Define the ModelCheckpoint callback to save the model using the 'SavedModel' format\n",
    "checkpoint = ModelCheckpoint('best_model-r9', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max', save_format='tf')\n",
    "\n",
    "# Define the EarlyStopping callback to stop training when there's no increase in val_accuracy for 50 epochs\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=50, verbose=1, mode='max')\n",
    "\n",
    "# Initialize the generator with the custom augmentations\n",
    "custom_data_generator = CustomImageDataGenerator(x_train, y_train, batch_size=128, augmentations=custom_augmentations)\n",
    "\n",
    "# Train the model using the custom data generator\n",
    "history = model.fit(custom_data_generator,\n",
    "                    steps_per_epoch=len(x_train) // 128,\n",
    "                    epochs=500, \n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[checkpoint, early_stopping])  # Include both checkpoint and early stopping callbacks here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4c14e30d-a88c-4955-a402-838fda2f3b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "811f8ab7-0326-42f7-99b0-606277f0a2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_horizontal_flip(image, p=0.5):\n",
    "    \"\"\"Randomly flip the image horizontally with a probability of p.\"\"\"\n",
    "    if random.random() < p:\n",
    "        return image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    return image\n",
    "\n",
    "def random_rotation(image, max_angle=0):\n",
    "    \"\"\"Randomly rotate the image within a given angle range.\"\"\"\n",
    "    angle = random.uniform(-max_angle, max_angle)\n",
    "    return image.rotate(angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "00eabd5a-ae81-4f61-9676-8028c555dc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2443 - accuracy: 0.9137\n",
      "Epoch 1: val_accuracy improved from -inf to 0.93480, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 24s 122ms/step - loss: 0.2443 - accuracy: 0.9137 - val_loss: 0.2225 - val_accuracy: 0.9348\n",
      "Epoch 2/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2440 - accuracy: 0.9155\n",
      "Epoch 2: val_accuracy improved from 0.93480 to 0.93620, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 24s 121ms/step - loss: 0.2440 - accuracy: 0.9155 - val_loss: 0.2227 - val_accuracy: 0.9362\n",
      "Epoch 3/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2440 - accuracy: 0.9131\n",
      "Epoch 3: val_accuracy did not improve from 0.93620\n",
      "195/195 [==============================] - 21s 104ms/step - loss: 0.2440 - accuracy: 0.9131 - val_loss: 0.2209 - val_accuracy: 0.9346\n",
      "Epoch 4/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2419 - accuracy: 0.9141\n",
      "Epoch 4: val_accuracy did not improve from 0.93620\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2419 - accuracy: 0.9141 - val_loss: 0.2230 - val_accuracy: 0.9356\n",
      "Epoch 5/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2464 - accuracy: 0.9146\n",
      "Epoch 5: val_accuracy did not improve from 0.93620\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2464 - accuracy: 0.9146 - val_loss: 0.2230 - val_accuracy: 0.9350\n",
      "Epoch 6/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2438 - accuracy: 0.9142\n",
      "Epoch 6: val_accuracy did not improve from 0.93620\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2438 - accuracy: 0.9142 - val_loss: 0.2233 - val_accuracy: 0.9339\n",
      "Epoch 7/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2410 - accuracy: 0.9148\n",
      "Epoch 7: val_accuracy did not improve from 0.93620\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2410 - accuracy: 0.9148 - val_loss: 0.2241 - val_accuracy: 0.9358\n",
      "Epoch 8/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2428 - accuracy: 0.9151\n",
      "Epoch 8: val_accuracy improved from 0.93620 to 0.93650, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 24s 122ms/step - loss: 0.2428 - accuracy: 0.9151 - val_loss: 0.2207 - val_accuracy: 0.9365\n",
      "Epoch 9/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2418 - accuracy: 0.9148\n",
      "Epoch 9: val_accuracy improved from 0.93650 to 0.93740, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 24s 122ms/step - loss: 0.2418 - accuracy: 0.9148 - val_loss: 0.2207 - val_accuracy: 0.9374\n",
      "Epoch 10/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2411 - accuracy: 0.9144\n",
      "Epoch 10: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 21s 104ms/step - loss: 0.2411 - accuracy: 0.9144 - val_loss: 0.2203 - val_accuracy: 0.9372\n",
      "Epoch 11/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2398 - accuracy: 0.9159\n",
      "Epoch 11: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2398 - accuracy: 0.9159 - val_loss: 0.2183 - val_accuracy: 0.9358\n",
      "Epoch 12/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2456 - accuracy: 0.9147\n",
      "Epoch 12: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 21s 107ms/step - loss: 0.2456 - accuracy: 0.9147 - val_loss: 0.2186 - val_accuracy: 0.9362\n",
      "Epoch 13/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2417 - accuracy: 0.9152\n",
      "Epoch 13: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 21s 106ms/step - loss: 0.2417 - accuracy: 0.9152 - val_loss: 0.2192 - val_accuracy: 0.9354\n",
      "Epoch 14/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2416 - accuracy: 0.9151\n",
      "Epoch 14: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 105ms/step - loss: 0.2416 - accuracy: 0.9151 - val_loss: 0.2258 - val_accuracy: 0.9350\n",
      "Epoch 15/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2420 - accuracy: 0.9166\n",
      "Epoch 15: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2420 - accuracy: 0.9166 - val_loss: 0.2202 - val_accuracy: 0.9366\n",
      "Epoch 16/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2491 - accuracy: 0.9134\n",
      "Epoch 16: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2491 - accuracy: 0.9134 - val_loss: 0.2197 - val_accuracy: 0.9350\n",
      "Epoch 17/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2440 - accuracy: 0.9146\n",
      "Epoch 17: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2440 - accuracy: 0.9146 - val_loss: 0.2230 - val_accuracy: 0.9359\n",
      "Epoch 18/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2450 - accuracy: 0.9139\n",
      "Epoch 18: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2450 - accuracy: 0.9139 - val_loss: 0.2200 - val_accuracy: 0.9367\n",
      "Epoch 19/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2409 - accuracy: 0.9159\n",
      "Epoch 19: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2409 - accuracy: 0.9159 - val_loss: 0.2240 - val_accuracy: 0.9356\n",
      "Epoch 20/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2408 - accuracy: 0.9164\n",
      "Epoch 20: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2408 - accuracy: 0.9164 - val_loss: 0.2241 - val_accuracy: 0.9357\n",
      "Epoch 21/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2410 - accuracy: 0.9160\n",
      "Epoch 21: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2410 - accuracy: 0.9160 - val_loss: 0.2193 - val_accuracy: 0.9364\n",
      "Epoch 22/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2409 - accuracy: 0.9156\n",
      "Epoch 22: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2409 - accuracy: 0.9156 - val_loss: 0.2204 - val_accuracy: 0.9345\n",
      "Epoch 23/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2409 - accuracy: 0.9172\n",
      "Epoch 23: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2409 - accuracy: 0.9172 - val_loss: 0.2257 - val_accuracy: 0.9347\n",
      "Epoch 24/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2392 - accuracy: 0.9161\n",
      "Epoch 24: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 21s 105ms/step - loss: 0.2392 - accuracy: 0.9161 - val_loss: 0.2207 - val_accuracy: 0.9341\n",
      "Epoch 25/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2389 - accuracy: 0.9161\n",
      "Epoch 25: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2389 - accuracy: 0.9161 - val_loss: 0.2238 - val_accuracy: 0.9350\n",
      "Epoch 26/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2443 - accuracy: 0.9164\n",
      "Epoch 26: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2443 - accuracy: 0.9164 - val_loss: 0.2223 - val_accuracy: 0.9350\n",
      "Epoch 27/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2394 - accuracy: 0.9166\n",
      "Epoch 27: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2394 - accuracy: 0.9166 - val_loss: 0.2213 - val_accuracy: 0.9356\n",
      "Epoch 28/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2408 - accuracy: 0.9164\n",
      "Epoch 28: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2408 - accuracy: 0.9164 - val_loss: 0.2203 - val_accuracy: 0.9369\n",
      "Epoch 29/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2394 - accuracy: 0.9161\n",
      "Epoch 29: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2394 - accuracy: 0.9161 - val_loss: 0.2184 - val_accuracy: 0.9361\n",
      "Epoch 30/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2396 - accuracy: 0.9153\n",
      "Epoch 30: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2396 - accuracy: 0.9153 - val_loss: 0.2216 - val_accuracy: 0.9361\n",
      "Epoch 31/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2404 - accuracy: 0.9156\n",
      "Epoch 31: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2404 - accuracy: 0.9156 - val_loss: 0.2252 - val_accuracy: 0.9326\n",
      "Epoch 32/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2357 - accuracy: 0.9166\n",
      "Epoch 32: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2357 - accuracy: 0.9166 - val_loss: 0.2201 - val_accuracy: 0.9374\n",
      "Epoch 33/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2384 - accuracy: 0.9167\n",
      "Epoch 33: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2384 - accuracy: 0.9167 - val_loss: 0.2228 - val_accuracy: 0.9346\n",
      "Epoch 34/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2393 - accuracy: 0.9170\n",
      "Epoch 34: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2393 - accuracy: 0.9170 - val_loss: 0.2213 - val_accuracy: 0.9350\n",
      "Epoch 35/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2431 - accuracy: 0.9152\n",
      "Epoch 35: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2431 - accuracy: 0.9152 - val_loss: 0.2244 - val_accuracy: 0.9345\n",
      "Epoch 36/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2396 - accuracy: 0.9172\n",
      "Epoch 36: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2396 - accuracy: 0.9172 - val_loss: 0.2264 - val_accuracy: 0.9354\n",
      "Epoch 37/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2453 - accuracy: 0.9156\n",
      "Epoch 37: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2453 - accuracy: 0.9156 - val_loss: 0.2202 - val_accuracy: 0.9373\n",
      "Epoch 38/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2447 - accuracy: 0.9156\n",
      "Epoch 38: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2447 - accuracy: 0.9156 - val_loss: 0.2220 - val_accuracy: 0.9369\n",
      "Epoch 39/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2410 - accuracy: 0.9163\n",
      "Epoch 39: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 21s 105ms/step - loss: 0.2410 - accuracy: 0.9163 - val_loss: 0.2173 - val_accuracy: 0.9373\n",
      "Epoch 40/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2353 - accuracy: 0.9172\n",
      "Epoch 40: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2353 - accuracy: 0.9172 - val_loss: 0.2210 - val_accuracy: 0.9353\n",
      "Epoch 41/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2340 - accuracy: 0.9183\n",
      "Epoch 41: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2340 - accuracy: 0.9183 - val_loss: 0.2253 - val_accuracy: 0.9346\n",
      "Epoch 42/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2406 - accuracy: 0.9162\n",
      "Epoch 42: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2406 - accuracy: 0.9162 - val_loss: 0.2254 - val_accuracy: 0.9354\n",
      "Epoch 43/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2404 - accuracy: 0.9165\n",
      "Epoch 43: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2404 - accuracy: 0.9165 - val_loss: 0.2275 - val_accuracy: 0.9340\n",
      "Epoch 44/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2405 - accuracy: 0.9162\n",
      "Epoch 44: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2405 - accuracy: 0.9162 - val_loss: 0.2258 - val_accuracy: 0.9364\n",
      "Epoch 45/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2373 - accuracy: 0.9166\n",
      "Epoch 45: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2373 - accuracy: 0.9166 - val_loss: 0.2251 - val_accuracy: 0.9351\n",
      "Epoch 46/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2347 - accuracy: 0.9180\n",
      "Epoch 46: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2347 - accuracy: 0.9180 - val_loss: 0.2229 - val_accuracy: 0.9351\n",
      "Epoch 47/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2390 - accuracy: 0.9170\n",
      "Epoch 47: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2390 - accuracy: 0.9170 - val_loss: 0.2258 - val_accuracy: 0.9352\n",
      "Epoch 48/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2418 - accuracy: 0.9154\n",
      "Epoch 48: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2418 - accuracy: 0.9154 - val_loss: 0.2217 - val_accuracy: 0.9357\n",
      "Epoch 49/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2394 - accuracy: 0.9170\n",
      "Epoch 49: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2394 - accuracy: 0.9170 - val_loss: 0.2251 - val_accuracy: 0.9332\n",
      "Epoch 50/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2413 - accuracy: 0.9158\n",
      "Epoch 50: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2413 - accuracy: 0.9158 - val_loss: 0.2245 - val_accuracy: 0.9353\n",
      "Epoch 51/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2422 - accuracy: 0.9149\n",
      "Epoch 51: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2422 - accuracy: 0.9149 - val_loss: 0.2248 - val_accuracy: 0.9353\n",
      "Epoch 52/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2381 - accuracy: 0.9173\n",
      "Epoch 52: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2381 - accuracy: 0.9173 - val_loss: 0.2266 - val_accuracy: 0.9351\n",
      "Epoch 53/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2404 - accuracy: 0.9162\n",
      "Epoch 53: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2404 - accuracy: 0.9162 - val_loss: 0.2247 - val_accuracy: 0.9354\n",
      "Epoch 54/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2407 - accuracy: 0.9162\n",
      "Epoch 54: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 21s 105ms/step - loss: 0.2407 - accuracy: 0.9162 - val_loss: 0.2203 - val_accuracy: 0.9362\n",
      "Epoch 55/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2386 - accuracy: 0.9168\n",
      "Epoch 55: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2386 - accuracy: 0.9168 - val_loss: 0.2250 - val_accuracy: 0.9366\n",
      "Epoch 56/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2376 - accuracy: 0.9163\n",
      "Epoch 56: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2376 - accuracy: 0.9163 - val_loss: 0.2251 - val_accuracy: 0.9356\n",
      "Epoch 57/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2416 - accuracy: 0.9158\n",
      "Epoch 57: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2416 - accuracy: 0.9158 - val_loss: 0.2294 - val_accuracy: 0.9331\n",
      "Epoch 58/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2363 - accuracy: 0.9174\n",
      "Epoch 58: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2363 - accuracy: 0.9174 - val_loss: 0.2235 - val_accuracy: 0.9354\n",
      "Epoch 59/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2408 - accuracy: 0.9161\n",
      "Epoch 59: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2408 - accuracy: 0.9161 - val_loss: 0.2236 - val_accuracy: 0.9350\n",
      "Epoch 60/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2394 - accuracy: 0.9170\n",
      "Epoch 60: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2394 - accuracy: 0.9170 - val_loss: 0.2252 - val_accuracy: 0.9346\n",
      "Epoch 61/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2408 - accuracy: 0.9164\n",
      "Epoch 61: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2408 - accuracy: 0.9164 - val_loss: 0.2278 - val_accuracy: 0.9350\n",
      "Epoch 62/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2384 - accuracy: 0.9172\n",
      "Epoch 62: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2384 - accuracy: 0.9172 - val_loss: 0.2243 - val_accuracy: 0.9345\n",
      "Epoch 63/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2361 - accuracy: 0.9167\n",
      "Epoch 63: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2361 - accuracy: 0.9167 - val_loss: 0.2261 - val_accuracy: 0.9358\n",
      "Epoch 64/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2385 - accuracy: 0.9163\n",
      "Epoch 64: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2385 - accuracy: 0.9163 - val_loss: 0.2278 - val_accuracy: 0.9352\n",
      "Epoch 65/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2392 - accuracy: 0.9171\n",
      "Epoch 65: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2392 - accuracy: 0.9171 - val_loss: 0.2267 - val_accuracy: 0.9367\n",
      "Epoch 66/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2421 - accuracy: 0.9148\n",
      "Epoch 66: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2421 - accuracy: 0.9148 - val_loss: 0.2278 - val_accuracy: 0.9349\n",
      "Epoch 67/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2367 - accuracy: 0.9175\n",
      "Epoch 67: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2367 - accuracy: 0.9175 - val_loss: 0.2258 - val_accuracy: 0.9352\n",
      "Epoch 68/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2425 - accuracy: 0.9146\n",
      "Epoch 68: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2425 - accuracy: 0.9146 - val_loss: 0.2237 - val_accuracy: 0.9342\n",
      "Epoch 69/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2392 - accuracy: 0.9163\n",
      "Epoch 69: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2392 - accuracy: 0.9163 - val_loss: 0.2230 - val_accuracy: 0.9356\n",
      "Epoch 70/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2374 - accuracy: 0.9159\n",
      "Epoch 70: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 105ms/step - loss: 0.2374 - accuracy: 0.9159 - val_loss: 0.2220 - val_accuracy: 0.9344\n",
      "Epoch 71/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2358 - accuracy: 0.9178\n",
      "Epoch 71: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2358 - accuracy: 0.9178 - val_loss: 0.2234 - val_accuracy: 0.9353\n",
      "Epoch 72/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2348 - accuracy: 0.9172\n",
      "Epoch 72: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2348 - accuracy: 0.9172 - val_loss: 0.2229 - val_accuracy: 0.9354\n",
      "Epoch 73/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2378 - accuracy: 0.9165\n",
      "Epoch 73: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2378 - accuracy: 0.9165 - val_loss: 0.2233 - val_accuracy: 0.9354\n",
      "Epoch 74/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2343 - accuracy: 0.9178\n",
      "Epoch 74: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2343 - accuracy: 0.9178 - val_loss: 0.2204 - val_accuracy: 0.9361\n",
      "Epoch 75/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2411 - accuracy: 0.9156\n",
      "Epoch 75: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2411 - accuracy: 0.9156 - val_loss: 0.2224 - val_accuracy: 0.9368\n",
      "Epoch 76/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2389 - accuracy: 0.9171\n",
      "Epoch 76: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2389 - accuracy: 0.9171 - val_loss: 0.2244 - val_accuracy: 0.9361\n",
      "Epoch 77/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2384 - accuracy: 0.9174\n",
      "Epoch 77: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2384 - accuracy: 0.9174 - val_loss: 0.2205 - val_accuracy: 0.9356\n",
      "Epoch 78/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2377 - accuracy: 0.9171\n",
      "Epoch 78: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2377 - accuracy: 0.9171 - val_loss: 0.2235 - val_accuracy: 0.9361\n",
      "Epoch 79/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2352 - accuracy: 0.9184\n",
      "Epoch 79: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 105ms/step - loss: 0.2352 - accuracy: 0.9184 - val_loss: 0.2207 - val_accuracy: 0.9368\n",
      "Epoch 80/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2381 - accuracy: 0.9179\n",
      "Epoch 80: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2381 - accuracy: 0.9179 - val_loss: 0.2215 - val_accuracy: 0.9354\n",
      "Epoch 81/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2365 - accuracy: 0.9178\n",
      "Epoch 81: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2365 - accuracy: 0.9178 - val_loss: 0.2270 - val_accuracy: 0.9341\n",
      "Epoch 82/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2382 - accuracy: 0.9153\n",
      "Epoch 82: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2382 - accuracy: 0.9153 - val_loss: 0.2222 - val_accuracy: 0.9360\n",
      "Epoch 83/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2416 - accuracy: 0.9155\n",
      "Epoch 83: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 105ms/step - loss: 0.2416 - accuracy: 0.9155 - val_loss: 0.2251 - val_accuracy: 0.9343\n",
      "Epoch 84/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2363 - accuracy: 0.9173\n",
      "Epoch 84: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2363 - accuracy: 0.9173 - val_loss: 0.2239 - val_accuracy: 0.9340\n",
      "Epoch 85/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2375 - accuracy: 0.9181\n",
      "Epoch 85: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2375 - accuracy: 0.9181 - val_loss: 0.2243 - val_accuracy: 0.9353\n",
      "Epoch 86/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2390 - accuracy: 0.9164\n",
      "Epoch 86: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2390 - accuracy: 0.9164 - val_loss: 0.2207 - val_accuracy: 0.9357\n",
      "Epoch 87/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2375 - accuracy: 0.9166\n",
      "Epoch 87: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2375 - accuracy: 0.9166 - val_loss: 0.2221 - val_accuracy: 0.9351\n",
      "Epoch 88/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2383 - accuracy: 0.9176\n",
      "Epoch 88: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2383 - accuracy: 0.9176 - val_loss: 0.2236 - val_accuracy: 0.9366\n",
      "Epoch 89/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2385 - accuracy: 0.9155\n",
      "Epoch 89: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2385 - accuracy: 0.9155 - val_loss: 0.2257 - val_accuracy: 0.9360\n",
      "Epoch 90/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2355 - accuracy: 0.9172\n",
      "Epoch 90: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2355 - accuracy: 0.9172 - val_loss: 0.2249 - val_accuracy: 0.9342\n",
      "Epoch 91/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2367 - accuracy: 0.9183\n",
      "Epoch 91: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2367 - accuracy: 0.9183 - val_loss: 0.2222 - val_accuracy: 0.9357\n",
      "Epoch 92/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2317 - accuracy: 0.9188\n",
      "Epoch 92: val_accuracy did not improve from 0.93740\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2317 - accuracy: 0.9188 - val_loss: 0.2254 - val_accuracy: 0.9355\n",
      "Epoch 93/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2414 - accuracy: 0.9159\n",
      "Epoch 93: val_accuracy improved from 0.93740 to 0.93760, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 24s 122ms/step - loss: 0.2414 - accuracy: 0.9159 - val_loss: 0.2224 - val_accuracy: 0.9376\n",
      "Epoch 94/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2367 - accuracy: 0.9166\n",
      "Epoch 94: val_accuracy did not improve from 0.93760\n",
      "195/195 [==============================] - 21s 105ms/step - loss: 0.2367 - accuracy: 0.9166 - val_loss: 0.2243 - val_accuracy: 0.9352\n",
      "Epoch 95/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2366 - accuracy: 0.9179\n",
      "Epoch 95: val_accuracy did not improve from 0.93760\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2366 - accuracy: 0.9179 - val_loss: 0.2185 - val_accuracy: 0.9370\n",
      "Epoch 96/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2390 - accuracy: 0.9157\n",
      "Epoch 96: val_accuracy improved from 0.93760 to 0.93810, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 24s 122ms/step - loss: 0.2390 - accuracy: 0.9157 - val_loss: 0.2206 - val_accuracy: 0.9381\n",
      "Epoch 97/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2369 - accuracy: 0.9153\n",
      "Epoch 97: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 21s 105ms/step - loss: 0.2369 - accuracy: 0.9153 - val_loss: 0.2223 - val_accuracy: 0.9366\n",
      "Epoch 98/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2360 - accuracy: 0.9168\n",
      "Epoch 98: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2360 - accuracy: 0.9168 - val_loss: 0.2226 - val_accuracy: 0.9358\n",
      "Epoch 99/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2403 - accuracy: 0.9161\n",
      "Epoch 99: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2403 - accuracy: 0.9161 - val_loss: 0.2228 - val_accuracy: 0.9369\n",
      "Epoch 100/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2349 - accuracy: 0.9188\n",
      "Epoch 100: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2349 - accuracy: 0.9188 - val_loss: 0.2222 - val_accuracy: 0.9355\n",
      "Epoch 101/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2390 - accuracy: 0.9157\n",
      "Epoch 101: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2390 - accuracy: 0.9157 - val_loss: 0.2234 - val_accuracy: 0.9368\n",
      "Epoch 102/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2348 - accuracy: 0.9183\n",
      "Epoch 102: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2348 - accuracy: 0.9183 - val_loss: 0.2224 - val_accuracy: 0.9360\n",
      "Epoch 103/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2364 - accuracy: 0.9188\n",
      "Epoch 103: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2364 - accuracy: 0.9188 - val_loss: 0.2225 - val_accuracy: 0.9358\n",
      "Epoch 104/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2407 - accuracy: 0.9162\n",
      "Epoch 104: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 21s 105ms/step - loss: 0.2407 - accuracy: 0.9162 - val_loss: 0.2245 - val_accuracy: 0.9368\n",
      "Epoch 105/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2404 - accuracy: 0.9168\n",
      "Epoch 105: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2404 - accuracy: 0.9168 - val_loss: 0.2213 - val_accuracy: 0.9368\n",
      "Epoch 106/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2382 - accuracy: 0.9161\n",
      "Epoch 106: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2382 - accuracy: 0.9161 - val_loss: 0.2253 - val_accuracy: 0.9356\n",
      "Epoch 107/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2358 - accuracy: 0.9176\n",
      "Epoch 107: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2358 - accuracy: 0.9176 - val_loss: 0.2252 - val_accuracy: 0.9361\n",
      "Epoch 108/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2363 - accuracy: 0.9186\n",
      "Epoch 108: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2363 - accuracy: 0.9186 - val_loss: 0.2238 - val_accuracy: 0.9349\n",
      "Epoch 109/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2371 - accuracy: 0.9172\n",
      "Epoch 109: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2371 - accuracy: 0.9172 - val_loss: 0.2244 - val_accuracy: 0.9345\n",
      "Epoch 110/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2377 - accuracy: 0.9168\n",
      "Epoch 110: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2377 - accuracy: 0.9168 - val_loss: 0.2243 - val_accuracy: 0.9362\n",
      "Epoch 111/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2322 - accuracy: 0.9197\n",
      "Epoch 111: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2322 - accuracy: 0.9197 - val_loss: 0.2249 - val_accuracy: 0.9341\n",
      "Epoch 112/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2325 - accuracy: 0.9189\n",
      "Epoch 112: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2325 - accuracy: 0.9189 - val_loss: 0.2206 - val_accuracy: 0.9355\n",
      "Epoch 113/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2315 - accuracy: 0.9193\n",
      "Epoch 113: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2315 - accuracy: 0.9193 - val_loss: 0.2210 - val_accuracy: 0.9361\n",
      "Epoch 114/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2381 - accuracy: 0.9177\n",
      "Epoch 114: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2381 - accuracy: 0.9177 - val_loss: 0.2219 - val_accuracy: 0.9364\n",
      "Epoch 115/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2325 - accuracy: 0.9186\n",
      "Epoch 115: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2325 - accuracy: 0.9186 - val_loss: 0.2262 - val_accuracy: 0.9355\n",
      "Epoch 116/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2357 - accuracy: 0.9184\n",
      "Epoch 116: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2357 - accuracy: 0.9184 - val_loss: 0.2248 - val_accuracy: 0.9354\n",
      "Epoch 117/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2353 - accuracy: 0.9172\n",
      "Epoch 117: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2353 - accuracy: 0.9172 - val_loss: 0.2237 - val_accuracy: 0.9353\n",
      "Epoch 118/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2338 - accuracy: 0.9198\n",
      "Epoch 118: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2338 - accuracy: 0.9198 - val_loss: 0.2236 - val_accuracy: 0.9352\n",
      "Epoch 119/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2366 - accuracy: 0.9183\n",
      "Epoch 119: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2366 - accuracy: 0.9183 - val_loss: 0.2212 - val_accuracy: 0.9361\n",
      "Epoch 120/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2337 - accuracy: 0.9183\n",
      "Epoch 120: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 105ms/step - loss: 0.2337 - accuracy: 0.9183 - val_loss: 0.2236 - val_accuracy: 0.9356\n",
      "Epoch 121/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2365 - accuracy: 0.9182\n",
      "Epoch 121: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2365 - accuracy: 0.9182 - val_loss: 0.2268 - val_accuracy: 0.9342\n",
      "Epoch 122/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2380 - accuracy: 0.9169\n",
      "Epoch 122: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2380 - accuracy: 0.9169 - val_loss: 0.2240 - val_accuracy: 0.9349\n",
      "Epoch 123/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2382 - accuracy: 0.9170\n",
      "Epoch 123: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2382 - accuracy: 0.9170 - val_loss: 0.2208 - val_accuracy: 0.9358\n",
      "Epoch 124/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2315 - accuracy: 0.9196\n",
      "Epoch 124: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2315 - accuracy: 0.9196 - val_loss: 0.2237 - val_accuracy: 0.9361\n",
      "Epoch 125/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2341 - accuracy: 0.9188\n",
      "Epoch 125: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2341 - accuracy: 0.9188 - val_loss: 0.2219 - val_accuracy: 0.9353\n",
      "Epoch 126/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2344 - accuracy: 0.9175\n",
      "Epoch 126: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2344 - accuracy: 0.9175 - val_loss: 0.2245 - val_accuracy: 0.9353\n",
      "Epoch 127/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2377 - accuracy: 0.9169\n",
      "Epoch 127: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2377 - accuracy: 0.9169 - val_loss: 0.2264 - val_accuracy: 0.9347\n",
      "Epoch 128/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2417 - accuracy: 0.9162\n",
      "Epoch 128: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2417 - accuracy: 0.9162 - val_loss: 0.2286 - val_accuracy: 0.9340\n",
      "Epoch 129/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2357 - accuracy: 0.9179\n",
      "Epoch 129: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2357 - accuracy: 0.9179 - val_loss: 0.2238 - val_accuracy: 0.9357\n",
      "Epoch 130/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2412 - accuracy: 0.9160\n",
      "Epoch 130: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2412 - accuracy: 0.9160 - val_loss: 0.2270 - val_accuracy: 0.9340\n",
      "Epoch 131/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2350 - accuracy: 0.9183\n",
      "Epoch 131: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2350 - accuracy: 0.9183 - val_loss: 0.2223 - val_accuracy: 0.9358\n",
      "Epoch 132/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2384 - accuracy: 0.9171\n",
      "Epoch 132: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2384 - accuracy: 0.9171 - val_loss: 0.2273 - val_accuracy: 0.9336\n",
      "Epoch 133/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2327 - accuracy: 0.9186\n",
      "Epoch 133: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2327 - accuracy: 0.9186 - val_loss: 0.2210 - val_accuracy: 0.9357\n",
      "Epoch 134/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2367 - accuracy: 0.9166\n",
      "Epoch 134: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2367 - accuracy: 0.9166 - val_loss: 0.2242 - val_accuracy: 0.9356\n",
      "Epoch 135/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2361 - accuracy: 0.9171\n",
      "Epoch 135: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 21s 105ms/step - loss: 0.2361 - accuracy: 0.9171 - val_loss: 0.2263 - val_accuracy: 0.9344\n",
      "Epoch 136/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2359 - accuracy: 0.9174\n",
      "Epoch 136: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2359 - accuracy: 0.9174 - val_loss: 0.2247 - val_accuracy: 0.9358\n",
      "Epoch 137/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2343 - accuracy: 0.9174\n",
      "Epoch 137: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2343 - accuracy: 0.9174 - val_loss: 0.2241 - val_accuracy: 0.9337\n",
      "Epoch 138/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2332 - accuracy: 0.9172\n",
      "Epoch 138: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2332 - accuracy: 0.9172 - val_loss: 0.2220 - val_accuracy: 0.9334\n",
      "Epoch 139/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2352 - accuracy: 0.9186\n",
      "Epoch 139: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2352 - accuracy: 0.9186 - val_loss: 0.2230 - val_accuracy: 0.9351\n",
      "Epoch 140/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2353 - accuracy: 0.9166\n",
      "Epoch 140: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2353 - accuracy: 0.9166 - val_loss: 0.2207 - val_accuracy: 0.9369\n",
      "Epoch 141/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2328 - accuracy: 0.9177\n",
      "Epoch 141: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2328 - accuracy: 0.9177 - val_loss: 0.2222 - val_accuracy: 0.9350\n",
      "Epoch 142/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2331 - accuracy: 0.9200\n",
      "Epoch 142: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2331 - accuracy: 0.9200 - val_loss: 0.2195 - val_accuracy: 0.9362\n",
      "Epoch 143/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2318 - accuracy: 0.9201\n",
      "Epoch 143: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2318 - accuracy: 0.9201 - val_loss: 0.2202 - val_accuracy: 0.9360\n",
      "Epoch 144/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2352 - accuracy: 0.9190\n",
      "Epoch 144: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2352 - accuracy: 0.9190 - val_loss: 0.2220 - val_accuracy: 0.9363\n",
      "Epoch 145/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2303 - accuracy: 0.9203\n",
      "Epoch 145: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2303 - accuracy: 0.9203 - val_loss: 0.2178 - val_accuracy: 0.9360\n",
      "Epoch 146/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2320 - accuracy: 0.9203\n",
      "Epoch 146: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2320 - accuracy: 0.9203 - val_loss: 0.2219 - val_accuracy: 0.9353\n",
      "Epoch 147/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2379 - accuracy: 0.9183\n",
      "Epoch 147: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2379 - accuracy: 0.9183 - val_loss: 0.2223 - val_accuracy: 0.9349\n",
      "Epoch 148/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2333 - accuracy: 0.9192\n",
      "Epoch 148: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2333 - accuracy: 0.9192 - val_loss: 0.2203 - val_accuracy: 0.9366\n",
      "Epoch 149/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2327 - accuracy: 0.9185\n",
      "Epoch 149: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2327 - accuracy: 0.9185 - val_loss: 0.2225 - val_accuracy: 0.9350\n",
      "Epoch 150/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2327 - accuracy: 0.9194\n",
      "Epoch 150: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 105ms/step - loss: 0.2327 - accuracy: 0.9194 - val_loss: 0.2207 - val_accuracy: 0.9359\n",
      "Epoch 151/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2332 - accuracy: 0.9188\n",
      "Epoch 151: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2332 - accuracy: 0.9188 - val_loss: 0.2188 - val_accuracy: 0.9351\n",
      "Epoch 152/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2362 - accuracy: 0.9182\n",
      "Epoch 152: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2362 - accuracy: 0.9182 - val_loss: 0.2229 - val_accuracy: 0.9355\n",
      "Epoch 153/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2304 - accuracy: 0.9202\n",
      "Epoch 153: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2304 - accuracy: 0.9202 - val_loss: 0.2186 - val_accuracy: 0.9364\n",
      "Epoch 154/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2353 - accuracy: 0.9173\n",
      "Epoch 154: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2353 - accuracy: 0.9173 - val_loss: 0.2183 - val_accuracy: 0.9350\n",
      "Epoch 155/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2393 - accuracy: 0.9162\n",
      "Epoch 155: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2393 - accuracy: 0.9162 - val_loss: 0.2210 - val_accuracy: 0.9352\n",
      "Epoch 156/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2316 - accuracy: 0.9188\n",
      "Epoch 156: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2316 - accuracy: 0.9188 - val_loss: 0.2198 - val_accuracy: 0.9345\n",
      "Epoch 157/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2371 - accuracy: 0.9182\n",
      "Epoch 157: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2371 - accuracy: 0.9182 - val_loss: 0.2208 - val_accuracy: 0.9363\n",
      "Epoch 158/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2302 - accuracy: 0.9201\n",
      "Epoch 158: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2302 - accuracy: 0.9201 - val_loss: 0.2192 - val_accuracy: 0.9364\n",
      "Epoch 159/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2294 - accuracy: 0.9200\n",
      "Epoch 159: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2294 - accuracy: 0.9200 - val_loss: 0.2220 - val_accuracy: 0.9366\n",
      "Epoch 160/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2348 - accuracy: 0.9185\n",
      "Epoch 160: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2348 - accuracy: 0.9185 - val_loss: 0.2256 - val_accuracy: 0.9347\n",
      "Epoch 161/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2335 - accuracy: 0.9178\n",
      "Epoch 161: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2335 - accuracy: 0.9178 - val_loss: 0.2206 - val_accuracy: 0.9358\n",
      "Epoch 162/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2334 - accuracy: 0.9191\n",
      "Epoch 162: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2334 - accuracy: 0.9191 - val_loss: 0.2201 - val_accuracy: 0.9374\n",
      "Epoch 163/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2328 - accuracy: 0.9193\n",
      "Epoch 163: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2328 - accuracy: 0.9193 - val_loss: 0.2239 - val_accuracy: 0.9375\n",
      "Epoch 164/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2352 - accuracy: 0.9178\n",
      "Epoch 164: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2352 - accuracy: 0.9178 - val_loss: 0.2201 - val_accuracy: 0.9380\n",
      "Epoch 165/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2363 - accuracy: 0.9178\n",
      "Epoch 165: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 21s 105ms/step - loss: 0.2363 - accuracy: 0.9178 - val_loss: 0.2234 - val_accuracy: 0.9342\n",
      "Epoch 166/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2349 - accuracy: 0.9174\n",
      "Epoch 166: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2349 - accuracy: 0.9174 - val_loss: 0.2218 - val_accuracy: 0.9363\n",
      "Epoch 167/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2321 - accuracy: 0.9188\n",
      "Epoch 167: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2321 - accuracy: 0.9188 - val_loss: 0.2198 - val_accuracy: 0.9369\n",
      "Epoch 168/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2317 - accuracy: 0.9199\n",
      "Epoch 168: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2317 - accuracy: 0.9199 - val_loss: 0.2233 - val_accuracy: 0.9352\n",
      "Epoch 169/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2338 - accuracy: 0.9180\n",
      "Epoch 169: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2338 - accuracy: 0.9180 - val_loss: 0.2212 - val_accuracy: 0.9373\n",
      "Epoch 170/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2329 - accuracy: 0.9183\n",
      "Epoch 170: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2329 - accuracy: 0.9183 - val_loss: 0.2231 - val_accuracy: 0.9366\n",
      "Epoch 171/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2337 - accuracy: 0.9184\n",
      "Epoch 171: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2337 - accuracy: 0.9184 - val_loss: 0.2228 - val_accuracy: 0.9379\n",
      "Epoch 172/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2340 - accuracy: 0.9183\n",
      "Epoch 172: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2340 - accuracy: 0.9183 - val_loss: 0.2198 - val_accuracy: 0.9377\n",
      "Epoch 173/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2296 - accuracy: 0.9196\n",
      "Epoch 173: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2296 - accuracy: 0.9196 - val_loss: 0.2200 - val_accuracy: 0.9357\n",
      "Epoch 174/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2337 - accuracy: 0.9186\n",
      "Epoch 174: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2337 - accuracy: 0.9186 - val_loss: 0.2207 - val_accuracy: 0.9372\n",
      "Epoch 175/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2292 - accuracy: 0.9206\n",
      "Epoch 175: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2292 - accuracy: 0.9206 - val_loss: 0.2217 - val_accuracy: 0.9362\n",
      "Epoch 176/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2342 - accuracy: 0.9186\n",
      "Epoch 176: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2342 - accuracy: 0.9186 - val_loss: 0.2217 - val_accuracy: 0.9360\n",
      "Epoch 177/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2252 - accuracy: 0.9222\n",
      "Epoch 177: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2252 - accuracy: 0.9222 - val_loss: 0.2232 - val_accuracy: 0.9353\n",
      "Epoch 178/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2339 - accuracy: 0.9170\n",
      "Epoch 178: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2339 - accuracy: 0.9170 - val_loss: 0.2202 - val_accuracy: 0.9346\n",
      "Epoch 179/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2343 - accuracy: 0.9191\n",
      "Epoch 179: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2343 - accuracy: 0.9191 - val_loss: 0.2211 - val_accuracy: 0.9372\n",
      "Epoch 180/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2319 - accuracy: 0.9193\n",
      "Epoch 180: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 105ms/step - loss: 0.2319 - accuracy: 0.9193 - val_loss: 0.2230 - val_accuracy: 0.9354\n",
      "Epoch 181/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2334 - accuracy: 0.9196\n",
      "Epoch 181: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 21s 105ms/step - loss: 0.2334 - accuracy: 0.9196 - val_loss: 0.2197 - val_accuracy: 0.9363\n",
      "Epoch 182/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2286 - accuracy: 0.9211\n",
      "Epoch 182: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2286 - accuracy: 0.9211 - val_loss: 0.2213 - val_accuracy: 0.9367\n",
      "Epoch 183/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2279 - accuracy: 0.9210\n",
      "Epoch 183: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 105ms/step - loss: 0.2279 - accuracy: 0.9210 - val_loss: 0.2278 - val_accuracy: 0.9340\n",
      "Epoch 184/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2289 - accuracy: 0.9201\n",
      "Epoch 184: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2289 - accuracy: 0.9201 - val_loss: 0.2195 - val_accuracy: 0.9366\n",
      "Epoch 185/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2347 - accuracy: 0.9186\n",
      "Epoch 185: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2347 - accuracy: 0.9186 - val_loss: 0.2232 - val_accuracy: 0.9343\n",
      "Epoch 186/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2326 - accuracy: 0.9201\n",
      "Epoch 186: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2326 - accuracy: 0.9201 - val_loss: 0.2231 - val_accuracy: 0.9347\n",
      "Epoch 187/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2346 - accuracy: 0.9187\n",
      "Epoch 187: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2346 - accuracy: 0.9187 - val_loss: 0.2206 - val_accuracy: 0.9367\n",
      "Epoch 188/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2339 - accuracy: 0.9178\n",
      "Epoch 188: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2339 - accuracy: 0.9178 - val_loss: 0.2217 - val_accuracy: 0.9339\n",
      "Epoch 189/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2290 - accuracy: 0.9199\n",
      "Epoch 189: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2290 - accuracy: 0.9199 - val_loss: 0.2185 - val_accuracy: 0.9346\n",
      "Epoch 190/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2338 - accuracy: 0.9174\n",
      "Epoch 190: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2338 - accuracy: 0.9174 - val_loss: 0.2226 - val_accuracy: 0.9349\n",
      "Epoch 191/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2267 - accuracy: 0.9211\n",
      "Epoch 191: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2267 - accuracy: 0.9211 - val_loss: 0.2200 - val_accuracy: 0.9345\n",
      "Epoch 192/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2270 - accuracy: 0.9210\n",
      "Epoch 192: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2270 - accuracy: 0.9210 - val_loss: 0.2213 - val_accuracy: 0.9358\n",
      "Epoch 193/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2319 - accuracy: 0.9199\n",
      "Epoch 193: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2319 - accuracy: 0.9199 - val_loss: 0.2211 - val_accuracy: 0.9354\n",
      "Epoch 194/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2334 - accuracy: 0.9183\n",
      "Epoch 194: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2334 - accuracy: 0.9183 - val_loss: 0.2216 - val_accuracy: 0.9351\n",
      "Epoch 195/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2322 - accuracy: 0.9187\n",
      "Epoch 195: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2322 - accuracy: 0.9187 - val_loss: 0.2243 - val_accuracy: 0.9341\n",
      "Epoch 196/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2313 - accuracy: 0.9203\n",
      "Epoch 196: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 21s 105ms/step - loss: 0.2313 - accuracy: 0.9203 - val_loss: 0.2208 - val_accuracy: 0.9364\n",
      "Epoch 197/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2308 - accuracy: 0.9195\n",
      "Epoch 197: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2308 - accuracy: 0.9195 - val_loss: 0.2228 - val_accuracy: 0.9353\n",
      "Epoch 198/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2287 - accuracy: 0.9215\n",
      "Epoch 198: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2287 - accuracy: 0.9215 - val_loss: 0.2250 - val_accuracy: 0.9347\n",
      "Epoch 199/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2368 - accuracy: 0.9158\n",
      "Epoch 199: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2368 - accuracy: 0.9158 - val_loss: 0.2228 - val_accuracy: 0.9350\n",
      "Epoch 200/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2324 - accuracy: 0.9184\n",
      "Epoch 200: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2324 - accuracy: 0.9184 - val_loss: 0.2231 - val_accuracy: 0.9355\n",
      "Epoch 201/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2370 - accuracy: 0.9170\n",
      "Epoch 201: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2370 - accuracy: 0.9170 - val_loss: 0.2258 - val_accuracy: 0.9361\n",
      "Epoch 202/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2272 - accuracy: 0.9219\n",
      "Epoch 202: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2272 - accuracy: 0.9219 - val_loss: 0.2249 - val_accuracy: 0.9365\n",
      "Epoch 203/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2322 - accuracy: 0.9198\n",
      "Epoch 203: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2322 - accuracy: 0.9198 - val_loss: 0.2226 - val_accuracy: 0.9354\n",
      "Epoch 204/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2284 - accuracy: 0.9203\n",
      "Epoch 204: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2284 - accuracy: 0.9203 - val_loss: 0.2236 - val_accuracy: 0.9363\n",
      "Epoch 205/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2331 - accuracy: 0.9188\n",
      "Epoch 205: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2331 - accuracy: 0.9188 - val_loss: 0.2222 - val_accuracy: 0.9350\n",
      "Epoch 206/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2314 - accuracy: 0.9201\n",
      "Epoch 206: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2314 - accuracy: 0.9201 - val_loss: 0.2223 - val_accuracy: 0.9351\n",
      "Epoch 207/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2333 - accuracy: 0.9189\n",
      "Epoch 207: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 105ms/step - loss: 0.2333 - accuracy: 0.9189 - val_loss: 0.2205 - val_accuracy: 0.9373\n",
      "Epoch 208/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2323 - accuracy: 0.9189\n",
      "Epoch 208: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2323 - accuracy: 0.9189 - val_loss: 0.2212 - val_accuracy: 0.9362\n",
      "Epoch 209/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2313 - accuracy: 0.9202\n",
      "Epoch 209: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2313 - accuracy: 0.9202 - val_loss: 0.2180 - val_accuracy: 0.9365\n",
      "Epoch 210/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2274 - accuracy: 0.9218\n",
      "Epoch 210: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2274 - accuracy: 0.9218 - val_loss: 0.2218 - val_accuracy: 0.9355\n",
      "Epoch 211/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2235 - accuracy: 0.9221\n",
      "Epoch 211: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 105ms/step - loss: 0.2235 - accuracy: 0.9221 - val_loss: 0.2203 - val_accuracy: 0.9356\n",
      "Epoch 212/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2302 - accuracy: 0.9192\n",
      "Epoch 212: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2302 - accuracy: 0.9192 - val_loss: 0.2246 - val_accuracy: 0.9354\n",
      "Epoch 213/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2265 - accuracy: 0.9217\n",
      "Epoch 213: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2265 - accuracy: 0.9217 - val_loss: 0.2194 - val_accuracy: 0.9370\n",
      "Epoch 214/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2289 - accuracy: 0.9198\n",
      "Epoch 214: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2289 - accuracy: 0.9198 - val_loss: 0.2225 - val_accuracy: 0.9352\n",
      "Epoch 215/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2310 - accuracy: 0.9191\n",
      "Epoch 215: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2310 - accuracy: 0.9191 - val_loss: 0.2213 - val_accuracy: 0.9365\n",
      "Epoch 216/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2344 - accuracy: 0.9189\n",
      "Epoch 216: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2344 - accuracy: 0.9189 - val_loss: 0.2234 - val_accuracy: 0.9365\n",
      "Epoch 217/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2338 - accuracy: 0.9177\n",
      "Epoch 217: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2338 - accuracy: 0.9177 - val_loss: 0.2208 - val_accuracy: 0.9353\n",
      "Epoch 218/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2303 - accuracy: 0.9193\n",
      "Epoch 218: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2303 - accuracy: 0.9193 - val_loss: 0.2200 - val_accuracy: 0.9379\n",
      "Epoch 219/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2332 - accuracy: 0.9185\n",
      "Epoch 219: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2332 - accuracy: 0.9185 - val_loss: 0.2215 - val_accuracy: 0.9360\n",
      "Epoch 220/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2275 - accuracy: 0.9207\n",
      "Epoch 220: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2275 - accuracy: 0.9207 - val_loss: 0.2248 - val_accuracy: 0.9350\n",
      "Epoch 221/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2299 - accuracy: 0.9202\n",
      "Epoch 221: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2299 - accuracy: 0.9202 - val_loss: 0.2215 - val_accuracy: 0.9372\n",
      "Epoch 222/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2341 - accuracy: 0.9185\n",
      "Epoch 222: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2341 - accuracy: 0.9185 - val_loss: 0.2217 - val_accuracy: 0.9347\n",
      "Epoch 223/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2320 - accuracy: 0.9183\n",
      "Epoch 223: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2320 - accuracy: 0.9183 - val_loss: 0.2184 - val_accuracy: 0.9360\n",
      "Epoch 224/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2284 - accuracy: 0.9196\n",
      "Epoch 224: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2284 - accuracy: 0.9196 - val_loss: 0.2253 - val_accuracy: 0.9370\n",
      "Epoch 225/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2354 - accuracy: 0.9188\n",
      "Epoch 225: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2354 - accuracy: 0.9188 - val_loss: 0.2161 - val_accuracy: 0.9376\n",
      "Epoch 226/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2339 - accuracy: 0.9189\n",
      "Epoch 226: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 21s 105ms/step - loss: 0.2339 - accuracy: 0.9189 - val_loss: 0.2209 - val_accuracy: 0.9367\n",
      "Epoch 227/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2285 - accuracy: 0.9201\n",
      "Epoch 227: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2285 - accuracy: 0.9201 - val_loss: 0.2278 - val_accuracy: 0.9349\n",
      "Epoch 228/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2347 - accuracy: 0.9183\n",
      "Epoch 228: val_accuracy did not improve from 0.93810\n",
      "195/195 [==============================] - 20s 105ms/step - loss: 0.2347 - accuracy: 0.9183 - val_loss: 0.2204 - val_accuracy: 0.9347\n",
      "Epoch 229/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2319 - accuracy: 0.9198\n",
      "Epoch 229: val_accuracy improved from 0.93810 to 0.93880, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 24s 122ms/step - loss: 0.2319 - accuracy: 0.9198 - val_loss: 0.2203 - val_accuracy: 0.9388\n",
      "Epoch 230/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2318 - accuracy: 0.9189\n",
      "Epoch 230: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 21s 104ms/step - loss: 0.2318 - accuracy: 0.9189 - val_loss: 0.2219 - val_accuracy: 0.9371\n",
      "Epoch 231/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2263 - accuracy: 0.9208\n",
      "Epoch 231: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2263 - accuracy: 0.9208 - val_loss: 0.2219 - val_accuracy: 0.9363\n",
      "Epoch 232/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2276 - accuracy: 0.9207\n",
      "Epoch 232: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2276 - accuracy: 0.9207 - val_loss: 0.2210 - val_accuracy: 0.9367\n",
      "Epoch 233/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2240 - accuracy: 0.9218\n",
      "Epoch 233: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2240 - accuracy: 0.9218 - val_loss: 0.2211 - val_accuracy: 0.9376\n",
      "Epoch 234/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2252 - accuracy: 0.9213\n",
      "Epoch 234: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2252 - accuracy: 0.9213 - val_loss: 0.2217 - val_accuracy: 0.9361\n",
      "Epoch 235/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2300 - accuracy: 0.9196\n",
      "Epoch 235: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2300 - accuracy: 0.9196 - val_loss: 0.2225 - val_accuracy: 0.9366\n",
      "Epoch 236/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2294 - accuracy: 0.9196\n",
      "Epoch 236: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2294 - accuracy: 0.9196 - val_loss: 0.2236 - val_accuracy: 0.9363\n",
      "Epoch 237/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2286 - accuracy: 0.9203\n",
      "Epoch 237: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2286 - accuracy: 0.9203 - val_loss: 0.2230 - val_accuracy: 0.9363\n",
      "Epoch 238/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2317 - accuracy: 0.9203\n",
      "Epoch 238: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2317 - accuracy: 0.9203 - val_loss: 0.2243 - val_accuracy: 0.9352\n",
      "Epoch 239/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2302 - accuracy: 0.9198\n",
      "Epoch 239: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2302 - accuracy: 0.9198 - val_loss: 0.2276 - val_accuracy: 0.9341\n",
      "Epoch 240/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2282 - accuracy: 0.9206\n",
      "Epoch 240: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2282 - accuracy: 0.9206 - val_loss: 0.2259 - val_accuracy: 0.9360\n",
      "Epoch 241/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2304 - accuracy: 0.9198\n",
      "Epoch 241: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2304 - accuracy: 0.9198 - val_loss: 0.2229 - val_accuracy: 0.9357\n",
      "Epoch 242/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2301 - accuracy: 0.9201\n",
      "Epoch 242: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2301 - accuracy: 0.9201 - val_loss: 0.2244 - val_accuracy: 0.9351\n",
      "Epoch 243/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2297 - accuracy: 0.9197\n",
      "Epoch 243: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2297 - accuracy: 0.9197 - val_loss: 0.2211 - val_accuracy: 0.9363\n",
      "Epoch 244/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2344 - accuracy: 0.9187\n",
      "Epoch 244: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2344 - accuracy: 0.9187 - val_loss: 0.2233 - val_accuracy: 0.9358\n",
      "Epoch 245/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2297 - accuracy: 0.9203\n",
      "Epoch 245: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 21s 105ms/step - loss: 0.2297 - accuracy: 0.9203 - val_loss: 0.2253 - val_accuracy: 0.9359\n",
      "Epoch 246/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2285 - accuracy: 0.9194\n",
      "Epoch 246: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2285 - accuracy: 0.9194 - val_loss: 0.2206 - val_accuracy: 0.9340\n",
      "Epoch 247/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2278 - accuracy: 0.9202\n",
      "Epoch 247: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2278 - accuracy: 0.9202 - val_loss: 0.2206 - val_accuracy: 0.9361\n",
      "Epoch 248/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2261 - accuracy: 0.9208\n",
      "Epoch 248: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2261 - accuracy: 0.9208 - val_loss: 0.2212 - val_accuracy: 0.9362\n",
      "Epoch 249/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2239 - accuracy: 0.9215\n",
      "Epoch 249: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2239 - accuracy: 0.9215 - val_loss: 0.2229 - val_accuracy: 0.9369\n",
      "Epoch 250/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2333 - accuracy: 0.9193\n",
      "Epoch 250: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2333 - accuracy: 0.9193 - val_loss: 0.2245 - val_accuracy: 0.9354\n",
      "Epoch 251/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2300 - accuracy: 0.9202\n",
      "Epoch 251: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2300 - accuracy: 0.9202 - val_loss: 0.2270 - val_accuracy: 0.9350\n",
      "Epoch 252/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2268 - accuracy: 0.9207\n",
      "Epoch 252: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2268 - accuracy: 0.9207 - val_loss: 0.2245 - val_accuracy: 0.9359\n",
      "Epoch 253/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2276 - accuracy: 0.9216\n",
      "Epoch 253: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2276 - accuracy: 0.9216 - val_loss: 0.2219 - val_accuracy: 0.9358\n",
      "Epoch 254/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2250 - accuracy: 0.9222\n",
      "Epoch 254: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2250 - accuracy: 0.9222 - val_loss: 0.2215 - val_accuracy: 0.9353\n",
      "Epoch 255/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2311 - accuracy: 0.9182\n",
      "Epoch 255: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2311 - accuracy: 0.9182 - val_loss: 0.2228 - val_accuracy: 0.9348\n",
      "Epoch 256/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2298 - accuracy: 0.9205\n",
      "Epoch 256: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2298 - accuracy: 0.9205 - val_loss: 0.2207 - val_accuracy: 0.9359\n",
      "Epoch 257/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2261 - accuracy: 0.9216\n",
      "Epoch 257: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2261 - accuracy: 0.9216 - val_loss: 0.2214 - val_accuracy: 0.9364\n",
      "Epoch 258/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2266 - accuracy: 0.9218\n",
      "Epoch 258: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2266 - accuracy: 0.9218 - val_loss: 0.2237 - val_accuracy: 0.9347\n",
      "Epoch 259/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2311 - accuracy: 0.9186\n",
      "Epoch 259: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2311 - accuracy: 0.9186 - val_loss: 0.2238 - val_accuracy: 0.9363\n",
      "Epoch 260/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2264 - accuracy: 0.9214\n",
      "Epoch 260: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 105ms/step - loss: 0.2264 - accuracy: 0.9214 - val_loss: 0.2232 - val_accuracy: 0.9354\n",
      "Epoch 261/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2287 - accuracy: 0.9195\n",
      "Epoch 261: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2287 - accuracy: 0.9195 - val_loss: 0.2196 - val_accuracy: 0.9363\n",
      "Epoch 262/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2280 - accuracy: 0.9201\n",
      "Epoch 262: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2280 - accuracy: 0.9201 - val_loss: 0.2226 - val_accuracy: 0.9350\n",
      "Epoch 263/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2259 - accuracy: 0.9218\n",
      "Epoch 263: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2259 - accuracy: 0.9218 - val_loss: 0.2180 - val_accuracy: 0.9382\n",
      "Epoch 264/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2276 - accuracy: 0.9197\n",
      "Epoch 264: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2276 - accuracy: 0.9197 - val_loss: 0.2245 - val_accuracy: 0.9349\n",
      "Epoch 265/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2305 - accuracy: 0.9194\n",
      "Epoch 265: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2305 - accuracy: 0.9194 - val_loss: 0.2213 - val_accuracy: 0.9371\n",
      "Epoch 266/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2259 - accuracy: 0.9211\n",
      "Epoch 266: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2259 - accuracy: 0.9211 - val_loss: 0.2198 - val_accuracy: 0.9370\n",
      "Epoch 267/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2274 - accuracy: 0.9207\n",
      "Epoch 267: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2274 - accuracy: 0.9207 - val_loss: 0.2227 - val_accuracy: 0.9368\n",
      "Epoch 268/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2310 - accuracy: 0.9198\n",
      "Epoch 268: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2310 - accuracy: 0.9198 - val_loss: 0.2207 - val_accuracy: 0.9372\n",
      "Epoch 269/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2324 - accuracy: 0.9189\n",
      "Epoch 269: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2324 - accuracy: 0.9189 - val_loss: 0.2249 - val_accuracy: 0.9363\n",
      "Epoch 270/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2241 - accuracy: 0.9219\n",
      "Epoch 270: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2241 - accuracy: 0.9219 - val_loss: 0.2236 - val_accuracy: 0.9352\n",
      "Epoch 271/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2278 - accuracy: 0.9207\n",
      "Epoch 271: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2278 - accuracy: 0.9207 - val_loss: 0.2238 - val_accuracy: 0.9350\n",
      "Epoch 272/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2294 - accuracy: 0.9185\n",
      "Epoch 272: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2294 - accuracy: 0.9185 - val_loss: 0.2249 - val_accuracy: 0.9356\n",
      "Epoch 273/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2293 - accuracy: 0.9198\n",
      "Epoch 273: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2293 - accuracy: 0.9198 - val_loss: 0.2233 - val_accuracy: 0.9357\n",
      "Epoch 274/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2318 - accuracy: 0.9195\n",
      "Epoch 274: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2318 - accuracy: 0.9195 - val_loss: 0.2193 - val_accuracy: 0.9364\n",
      "Epoch 275/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2237 - accuracy: 0.9219\n",
      "Epoch 275: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 105ms/step - loss: 0.2237 - accuracy: 0.9219 - val_loss: 0.2220 - val_accuracy: 0.9369\n",
      "Epoch 276/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2273 - accuracy: 0.9211\n",
      "Epoch 276: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 105ms/step - loss: 0.2273 - accuracy: 0.9211 - val_loss: 0.2214 - val_accuracy: 0.9357\n",
      "Epoch 277/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2237 - accuracy: 0.9210\n",
      "Epoch 277: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2237 - accuracy: 0.9210 - val_loss: 0.2239 - val_accuracy: 0.9355\n",
      "Epoch 278/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2305 - accuracy: 0.9199\n",
      "Epoch 278: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2305 - accuracy: 0.9199 - val_loss: 0.2205 - val_accuracy: 0.9373\n",
      "Epoch 279/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2273 - accuracy: 0.9205\n",
      "Epoch 279: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2273 - accuracy: 0.9205 - val_loss: 0.2219 - val_accuracy: 0.9364\n",
      "Epoch 280/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2269 - accuracy: 0.9214\n",
      "Epoch 280: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2269 - accuracy: 0.9214 - val_loss: 0.2209 - val_accuracy: 0.9360\n",
      "Epoch 281/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2321 - accuracy: 0.9195\n",
      "Epoch 281: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2321 - accuracy: 0.9195 - val_loss: 0.2258 - val_accuracy: 0.9342\n",
      "Epoch 282/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2297 - accuracy: 0.9216\n",
      "Epoch 282: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2297 - accuracy: 0.9216 - val_loss: 0.2206 - val_accuracy: 0.9364\n",
      "Epoch 283/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2287 - accuracy: 0.9211\n",
      "Epoch 283: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2287 - accuracy: 0.9211 - val_loss: 0.2218 - val_accuracy: 0.9351\n",
      "Epoch 284/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2264 - accuracy: 0.9209\n",
      "Epoch 284: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2264 - accuracy: 0.9209 - val_loss: 0.2196 - val_accuracy: 0.9363\n",
      "Epoch 285/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2268 - accuracy: 0.9208\n",
      "Epoch 285: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2268 - accuracy: 0.9208 - val_loss: 0.2226 - val_accuracy: 0.9366\n",
      "Epoch 286/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2305 - accuracy: 0.9193\n",
      "Epoch 286: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2305 - accuracy: 0.9193 - val_loss: 0.2218 - val_accuracy: 0.9362\n",
      "Epoch 287/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2246 - accuracy: 0.9213\n",
      "Epoch 287: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2246 - accuracy: 0.9213 - val_loss: 0.2195 - val_accuracy: 0.9362\n",
      "Epoch 288/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2240 - accuracy: 0.9216\n",
      "Epoch 288: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2240 - accuracy: 0.9216 - val_loss: 0.2207 - val_accuracy: 0.9365\n",
      "Epoch 289/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2305 - accuracy: 0.9198\n",
      "Epoch 289: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2305 - accuracy: 0.9198 - val_loss: 0.2207 - val_accuracy: 0.9358\n",
      "Epoch 290/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2289 - accuracy: 0.9188\n",
      "Epoch 290: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2289 - accuracy: 0.9188 - val_loss: 0.2235 - val_accuracy: 0.9347\n",
      "Epoch 291/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2291 - accuracy: 0.9206\n",
      "Epoch 291: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 21s 105ms/step - loss: 0.2291 - accuracy: 0.9206 - val_loss: 0.2220 - val_accuracy: 0.9354\n",
      "Epoch 292/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2239 - accuracy: 0.9224\n",
      "Epoch 292: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 105ms/step - loss: 0.2239 - accuracy: 0.9224 - val_loss: 0.2186 - val_accuracy: 0.9353\n",
      "Epoch 293/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2201 - accuracy: 0.9241\n",
      "Epoch 293: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2201 - accuracy: 0.9241 - val_loss: 0.2214 - val_accuracy: 0.9349\n",
      "Epoch 294/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2291 - accuracy: 0.9196\n",
      "Epoch 294: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2291 - accuracy: 0.9196 - val_loss: 0.2211 - val_accuracy: 0.9352\n",
      "Epoch 295/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2274 - accuracy: 0.9207\n",
      "Epoch 295: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2274 - accuracy: 0.9207 - val_loss: 0.2241 - val_accuracy: 0.9340\n",
      "Epoch 296/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2234 - accuracy: 0.9203\n",
      "Epoch 296: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2234 - accuracy: 0.9203 - val_loss: 0.2214 - val_accuracy: 0.9367\n",
      "Epoch 297/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2301 - accuracy: 0.9209\n",
      "Epoch 297: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2301 - accuracy: 0.9209 - val_loss: 0.2197 - val_accuracy: 0.9370\n",
      "Epoch 298/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2240 - accuracy: 0.9231\n",
      "Epoch 298: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2240 - accuracy: 0.9231 - val_loss: 0.2200 - val_accuracy: 0.9356\n",
      "Epoch 299/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2307 - accuracy: 0.9193\n",
      "Epoch 299: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 21s 105ms/step - loss: 0.2307 - accuracy: 0.9193 - val_loss: 0.2209 - val_accuracy: 0.9372\n",
      "Epoch 300/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2261 - accuracy: 0.9216\n",
      "Epoch 300: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2261 - accuracy: 0.9216 - val_loss: 0.2239 - val_accuracy: 0.9364\n",
      "Epoch 301/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2275 - accuracy: 0.9214\n",
      "Epoch 301: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2275 - accuracy: 0.9214 - val_loss: 0.2198 - val_accuracy: 0.9369\n",
      "Epoch 302/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2253 - accuracy: 0.9225\n",
      "Epoch 302: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2253 - accuracy: 0.9225 - val_loss: 0.2214 - val_accuracy: 0.9365\n",
      "Epoch 303/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2211 - accuracy: 0.9228\n",
      "Epoch 303: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2211 - accuracy: 0.9228 - val_loss: 0.2195 - val_accuracy: 0.9354\n",
      "Epoch 304/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2230 - accuracy: 0.9218\n",
      "Epoch 304: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2230 - accuracy: 0.9218 - val_loss: 0.2229 - val_accuracy: 0.9351\n",
      "Epoch 305/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2245 - accuracy: 0.9224\n",
      "Epoch 305: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2245 - accuracy: 0.9224 - val_loss: 0.2219 - val_accuracy: 0.9369\n",
      "Epoch 306/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2278 - accuracy: 0.9204\n",
      "Epoch 306: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 21s 105ms/step - loss: 0.2278 - accuracy: 0.9204 - val_loss: 0.2209 - val_accuracy: 0.9353\n",
      "Epoch 307/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2261 - accuracy: 0.9220\n",
      "Epoch 307: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2261 - accuracy: 0.9220 - val_loss: 0.2196 - val_accuracy: 0.9358\n",
      "Epoch 308/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2299 - accuracy: 0.9200\n",
      "Epoch 308: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2299 - accuracy: 0.9200 - val_loss: 0.2231 - val_accuracy: 0.9356\n",
      "Epoch 309/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2252 - accuracy: 0.9220\n",
      "Epoch 309: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2252 - accuracy: 0.9220 - val_loss: 0.2236 - val_accuracy: 0.9357\n",
      "Epoch 310/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2301 - accuracy: 0.9212\n",
      "Epoch 310: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2301 - accuracy: 0.9212 - val_loss: 0.2227 - val_accuracy: 0.9341\n",
      "Epoch 311/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2257 - accuracy: 0.9208\n",
      "Epoch 311: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2257 - accuracy: 0.9208 - val_loss: 0.2219 - val_accuracy: 0.9353\n",
      "Epoch 312/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2195 - accuracy: 0.9233\n",
      "Epoch 312: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 105ms/step - loss: 0.2195 - accuracy: 0.9233 - val_loss: 0.2178 - val_accuracy: 0.9382\n",
      "Epoch 313/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2241 - accuracy: 0.9217\n",
      "Epoch 313: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2241 - accuracy: 0.9217 - val_loss: 0.2194 - val_accuracy: 0.9363\n",
      "Epoch 314/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2255 - accuracy: 0.9197\n",
      "Epoch 314: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2255 - accuracy: 0.9197 - val_loss: 0.2204 - val_accuracy: 0.9368\n",
      "Epoch 315/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2273 - accuracy: 0.9205\n",
      "Epoch 315: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2273 - accuracy: 0.9205 - val_loss: 0.2208 - val_accuracy: 0.9353\n",
      "Epoch 316/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2262 - accuracy: 0.9211\n",
      "Epoch 316: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2262 - accuracy: 0.9211 - val_loss: 0.2189 - val_accuracy: 0.9369\n",
      "Epoch 317/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2257 - accuracy: 0.9210\n",
      "Epoch 317: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2257 - accuracy: 0.9210 - val_loss: 0.2198 - val_accuracy: 0.9351\n",
      "Epoch 318/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2231 - accuracy: 0.9222\n",
      "Epoch 318: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2231 - accuracy: 0.9222 - val_loss: 0.2217 - val_accuracy: 0.9359\n",
      "Epoch 319/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2320 - accuracy: 0.9167\n",
      "Epoch 319: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2320 - accuracy: 0.9167 - val_loss: 0.2197 - val_accuracy: 0.9367\n",
      "Epoch 320/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2238 - accuracy: 0.9215\n",
      "Epoch 320: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2238 - accuracy: 0.9215 - val_loss: 0.2211 - val_accuracy: 0.9363\n",
      "Epoch 321/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2258 - accuracy: 0.9204\n",
      "Epoch 321: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 105ms/step - loss: 0.2258 - accuracy: 0.9204 - val_loss: 0.2201 - val_accuracy: 0.9359\n",
      "Epoch 322/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2291 - accuracy: 0.9195\n",
      "Epoch 322: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2291 - accuracy: 0.9195 - val_loss: 0.2172 - val_accuracy: 0.9382\n",
      "Epoch 323/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2279 - accuracy: 0.9209\n",
      "Epoch 323: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2279 - accuracy: 0.9209 - val_loss: 0.2190 - val_accuracy: 0.9364\n",
      "Epoch 324/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2237 - accuracy: 0.9216\n",
      "Epoch 324: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2237 - accuracy: 0.9216 - val_loss: 0.2198 - val_accuracy: 0.9358\n",
      "Epoch 325/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2291 - accuracy: 0.9198\n",
      "Epoch 325: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2291 - accuracy: 0.9198 - val_loss: 0.2198 - val_accuracy: 0.9371\n",
      "Epoch 326/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2287 - accuracy: 0.9184\n",
      "Epoch 326: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2287 - accuracy: 0.9184 - val_loss: 0.2210 - val_accuracy: 0.9367\n",
      "Epoch 327/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2259 - accuracy: 0.9211\n",
      "Epoch 327: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2259 - accuracy: 0.9211 - val_loss: 0.2231 - val_accuracy: 0.9351\n",
      "Epoch 328/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2262 - accuracy: 0.9210\n",
      "Epoch 328: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2262 - accuracy: 0.9210 - val_loss: 0.2197 - val_accuracy: 0.9372\n",
      "Epoch 329/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2246 - accuracy: 0.9215\n",
      "Epoch 329: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2246 - accuracy: 0.9215 - val_loss: 0.2223 - val_accuracy: 0.9361\n",
      "Epoch 330/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2203 - accuracy: 0.9239\n",
      "Epoch 330: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2203 - accuracy: 0.9239 - val_loss: 0.2196 - val_accuracy: 0.9373\n",
      "Epoch 331/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2261 - accuracy: 0.9221\n",
      "Epoch 331: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2261 - accuracy: 0.9221 - val_loss: 0.2189 - val_accuracy: 0.9361\n",
      "Epoch 332/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2246 - accuracy: 0.9220\n",
      "Epoch 332: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2246 - accuracy: 0.9220 - val_loss: 0.2249 - val_accuracy: 0.9357\n",
      "Epoch 333/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2209 - accuracy: 0.9233\n",
      "Epoch 333: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2209 - accuracy: 0.9233 - val_loss: 0.2200 - val_accuracy: 0.9374\n",
      "Epoch 334/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2258 - accuracy: 0.9211\n",
      "Epoch 334: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2258 - accuracy: 0.9211 - val_loss: 0.2237 - val_accuracy: 0.9366\n",
      "Epoch 335/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2237 - accuracy: 0.9227\n",
      "Epoch 335: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2237 - accuracy: 0.9227 - val_loss: 0.2236 - val_accuracy: 0.9362\n",
      "Epoch 336/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2230 - accuracy: 0.9241\n",
      "Epoch 336: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2230 - accuracy: 0.9241 - val_loss: 0.2231 - val_accuracy: 0.9357\n",
      "Epoch 337/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2280 - accuracy: 0.9202\n",
      "Epoch 337: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 105ms/step - loss: 0.2280 - accuracy: 0.9202 - val_loss: 0.2228 - val_accuracy: 0.9362\n",
      "Epoch 338/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2224 - accuracy: 0.9221\n",
      "Epoch 338: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2224 - accuracy: 0.9221 - val_loss: 0.2203 - val_accuracy: 0.9374\n",
      "Epoch 339/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2204 - accuracy: 0.9244\n",
      "Epoch 339: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2204 - accuracy: 0.9244 - val_loss: 0.2234 - val_accuracy: 0.9366\n",
      "Epoch 340/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2226 - accuracy: 0.9222\n",
      "Epoch 340: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2226 - accuracy: 0.9222 - val_loss: 0.2203 - val_accuracy: 0.9371\n",
      "Epoch 341/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2304 - accuracy: 0.9186\n",
      "Epoch 341: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2304 - accuracy: 0.9186 - val_loss: 0.2188 - val_accuracy: 0.9367\n",
      "Epoch 342/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2263 - accuracy: 0.9219\n",
      "Epoch 342: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2263 - accuracy: 0.9219 - val_loss: 0.2220 - val_accuracy: 0.9370\n",
      "Epoch 343/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2266 - accuracy: 0.9206\n",
      "Epoch 343: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2266 - accuracy: 0.9206 - val_loss: 0.2227 - val_accuracy: 0.9371\n",
      "Epoch 344/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2257 - accuracy: 0.9203\n",
      "Epoch 344: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2257 - accuracy: 0.9203 - val_loss: 0.2208 - val_accuracy: 0.9371\n",
      "Epoch 345/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2244 - accuracy: 0.9218\n",
      "Epoch 345: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2244 - accuracy: 0.9218 - val_loss: 0.2227 - val_accuracy: 0.9346\n",
      "Epoch 346/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2224 - accuracy: 0.9215\n",
      "Epoch 346: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2224 - accuracy: 0.9215 - val_loss: 0.2224 - val_accuracy: 0.9358\n",
      "Epoch 347/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2220 - accuracy: 0.9229\n",
      "Epoch 347: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2220 - accuracy: 0.9229 - val_loss: 0.2257 - val_accuracy: 0.9359\n",
      "Epoch 348/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2224 - accuracy: 0.9233\n",
      "Epoch 348: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2224 - accuracy: 0.9233 - val_loss: 0.2194 - val_accuracy: 0.9379\n",
      "Epoch 349/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2260 - accuracy: 0.9222\n",
      "Epoch 349: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2260 - accuracy: 0.9222 - val_loss: 0.2203 - val_accuracy: 0.9363\n",
      "Epoch 350/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2216 - accuracy: 0.9227\n",
      "Epoch 350: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2216 - accuracy: 0.9227 - val_loss: 0.2180 - val_accuracy: 0.9375\n",
      "Epoch 351/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2262 - accuracy: 0.9225\n",
      "Epoch 351: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 21s 105ms/step - loss: 0.2262 - accuracy: 0.9225 - val_loss: 0.2229 - val_accuracy: 0.9357\n",
      "Epoch 352/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2264 - accuracy: 0.9210\n",
      "Epoch 352: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 105ms/step - loss: 0.2264 - accuracy: 0.9210 - val_loss: 0.2259 - val_accuracy: 0.9356\n",
      "Epoch 353/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2238 - accuracy: 0.9214\n",
      "Epoch 353: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2238 - accuracy: 0.9214 - val_loss: 0.2222 - val_accuracy: 0.9384\n",
      "Epoch 354/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2280 - accuracy: 0.9216\n",
      "Epoch 354: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2280 - accuracy: 0.9216 - val_loss: 0.2217 - val_accuracy: 0.9359\n",
      "Epoch 355/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2249 - accuracy: 0.9220\n",
      "Epoch 355: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2249 - accuracy: 0.9220 - val_loss: 0.2194 - val_accuracy: 0.9367\n",
      "Epoch 356/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2295 - accuracy: 0.9195\n",
      "Epoch 356: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2295 - accuracy: 0.9195 - val_loss: 0.2190 - val_accuracy: 0.9376\n",
      "Epoch 357/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2253 - accuracy: 0.9216\n",
      "Epoch 357: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2253 - accuracy: 0.9216 - val_loss: 0.2202 - val_accuracy: 0.9380\n",
      "Epoch 358/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2237 - accuracy: 0.9214\n",
      "Epoch 358: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2237 - accuracy: 0.9214 - val_loss: 0.2213 - val_accuracy: 0.9364\n",
      "Epoch 359/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2243 - accuracy: 0.9241\n",
      "Epoch 359: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2243 - accuracy: 0.9241 - val_loss: 0.2247 - val_accuracy: 0.9347\n",
      "Epoch 360/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2165 - accuracy: 0.9248\n",
      "Epoch 360: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2165 - accuracy: 0.9248 - val_loss: 0.2231 - val_accuracy: 0.9354\n",
      "Epoch 361/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2311 - accuracy: 0.9213\n",
      "Epoch 361: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 105ms/step - loss: 0.2311 - accuracy: 0.9213 - val_loss: 0.2237 - val_accuracy: 0.9363\n",
      "Epoch 362/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2234 - accuracy: 0.9226\n",
      "Epoch 362: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2234 - accuracy: 0.9226 - val_loss: 0.2189 - val_accuracy: 0.9370\n",
      "Epoch 363/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2208 - accuracy: 0.9240\n",
      "Epoch 363: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2208 - accuracy: 0.9240 - val_loss: 0.2219 - val_accuracy: 0.9370\n",
      "Epoch 364/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2194 - accuracy: 0.9227\n",
      "Epoch 364: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2194 - accuracy: 0.9227 - val_loss: 0.2213 - val_accuracy: 0.9365\n",
      "Epoch 365/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2196 - accuracy: 0.9236\n",
      "Epoch 365: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 105ms/step - loss: 0.2196 - accuracy: 0.9236 - val_loss: 0.2200 - val_accuracy: 0.9378\n",
      "Epoch 366/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2240 - accuracy: 0.9214\n",
      "Epoch 366: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2240 - accuracy: 0.9214 - val_loss: 0.2192 - val_accuracy: 0.9362\n",
      "Epoch 367/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2213 - accuracy: 0.9236\n",
      "Epoch 367: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 105ms/step - loss: 0.2213 - accuracy: 0.9236 - val_loss: 0.2205 - val_accuracy: 0.9370\n",
      "Epoch 368/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2191 - accuracy: 0.9244\n",
      "Epoch 368: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2191 - accuracy: 0.9244 - val_loss: 0.2247 - val_accuracy: 0.9353\n",
      "Epoch 369/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2238 - accuracy: 0.9221\n",
      "Epoch 369: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2238 - accuracy: 0.9221 - val_loss: 0.2203 - val_accuracy: 0.9365\n",
      "Epoch 370/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2250 - accuracy: 0.9210\n",
      "Epoch 370: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2250 - accuracy: 0.9210 - val_loss: 0.2248 - val_accuracy: 0.9362\n",
      "Epoch 371/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2302 - accuracy: 0.9209\n",
      "Epoch 371: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2302 - accuracy: 0.9209 - val_loss: 0.2208 - val_accuracy: 0.9371\n",
      "Epoch 372/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2208 - accuracy: 0.9223\n",
      "Epoch 372: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2208 - accuracy: 0.9223 - val_loss: 0.2218 - val_accuracy: 0.9374\n",
      "Epoch 373/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2234 - accuracy: 0.9220\n",
      "Epoch 373: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2234 - accuracy: 0.9220 - val_loss: 0.2213 - val_accuracy: 0.9377\n",
      "Epoch 374/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2225 - accuracy: 0.9216\n",
      "Epoch 374: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2225 - accuracy: 0.9216 - val_loss: 0.2218 - val_accuracy: 0.9363\n",
      "Epoch 375/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2238 - accuracy: 0.9229\n",
      "Epoch 375: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 105ms/step - loss: 0.2238 - accuracy: 0.9229 - val_loss: 0.2207 - val_accuracy: 0.9372\n",
      "Epoch 376/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2238 - accuracy: 0.9227\n",
      "Epoch 376: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2238 - accuracy: 0.9227 - val_loss: 0.2239 - val_accuracy: 0.9366\n",
      "Epoch 377/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2241 - accuracy: 0.9230\n",
      "Epoch 377: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2241 - accuracy: 0.9230 - val_loss: 0.2191 - val_accuracy: 0.9369\n",
      "Epoch 378/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2217 - accuracy: 0.9227\n",
      "Epoch 378: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2217 - accuracy: 0.9227 - val_loss: 0.2229 - val_accuracy: 0.9367\n",
      "Epoch 379/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2229 - accuracy: 0.9225\n",
      "Epoch 379: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2229 - accuracy: 0.9225 - val_loss: 0.2218 - val_accuracy: 0.9361\n",
      "Epoch 380/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2307 - accuracy: 0.9203\n",
      "Epoch 380: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2307 - accuracy: 0.9203 - val_loss: 0.2212 - val_accuracy: 0.9372\n",
      "Epoch 381/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2280 - accuracy: 0.9193\n",
      "Epoch 381: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2280 - accuracy: 0.9193 - val_loss: 0.2231 - val_accuracy: 0.9372\n",
      "Epoch 382/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2208 - accuracy: 0.9232\n",
      "Epoch 382: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 105ms/step - loss: 0.2208 - accuracy: 0.9232 - val_loss: 0.2229 - val_accuracy: 0.9368\n",
      "Epoch 383/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2254 - accuracy: 0.9220\n",
      "Epoch 383: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 21s 105ms/step - loss: 0.2254 - accuracy: 0.9220 - val_loss: 0.2224 - val_accuracy: 0.9360\n",
      "Epoch 384/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2203 - accuracy: 0.9233\n",
      "Epoch 384: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2203 - accuracy: 0.9233 - val_loss: 0.2207 - val_accuracy: 0.9372\n",
      "Epoch 385/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2227 - accuracy: 0.9217\n",
      "Epoch 385: val_accuracy did not improve from 0.93880\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2227 - accuracy: 0.9217 - val_loss: 0.2232 - val_accuracy: 0.9365\n",
      "Epoch 386/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2237 - accuracy: 0.9214\n",
      "Epoch 386: val_accuracy improved from 0.93880 to 0.93910, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 24s 121ms/step - loss: 0.2237 - accuracy: 0.9214 - val_loss: 0.2196 - val_accuracy: 0.9391\n",
      "Epoch 387/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2195 - accuracy: 0.9232\n",
      "Epoch 387: val_accuracy did not improve from 0.93910\n",
      "195/195 [==============================] - 21s 104ms/step - loss: 0.2195 - accuracy: 0.9232 - val_loss: 0.2199 - val_accuracy: 0.9373\n",
      "Epoch 388/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2213 - accuracy: 0.9232\n",
      "Epoch 388: val_accuracy did not improve from 0.93910\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2213 - accuracy: 0.9232 - val_loss: 0.2215 - val_accuracy: 0.9365\n",
      "Epoch 389/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2252 - accuracy: 0.9214\n",
      "Epoch 389: val_accuracy did not improve from 0.93910\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2252 - accuracy: 0.9214 - val_loss: 0.2233 - val_accuracy: 0.9361\n",
      "Epoch 390/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2212 - accuracy: 0.9225\n",
      "Epoch 390: val_accuracy did not improve from 0.93910\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2212 - accuracy: 0.9225 - val_loss: 0.2235 - val_accuracy: 0.9375\n",
      "Epoch 391/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2280 - accuracy: 0.9206\n",
      "Epoch 391: val_accuracy did not improve from 0.93910\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2280 - accuracy: 0.9206 - val_loss: 0.2200 - val_accuracy: 0.9374\n",
      "Epoch 392/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2220 - accuracy: 0.9233\n",
      "Epoch 392: val_accuracy did not improve from 0.93910\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2220 - accuracy: 0.9233 - val_loss: 0.2232 - val_accuracy: 0.9375\n",
      "Epoch 393/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2239 - accuracy: 0.9227\n",
      "Epoch 393: val_accuracy did not improve from 0.93910\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2239 - accuracy: 0.9227 - val_loss: 0.2200 - val_accuracy: 0.9367\n",
      "Epoch 394/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2248 - accuracy: 0.9207\n",
      "Epoch 394: val_accuracy did not improve from 0.93910\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2248 - accuracy: 0.9207 - val_loss: 0.2219 - val_accuracy: 0.9354\n",
      "Epoch 395/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2211 - accuracy: 0.9236\n",
      "Epoch 395: val_accuracy did not improve from 0.93910\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2211 - accuracy: 0.9236 - val_loss: 0.2215 - val_accuracy: 0.9358\n",
      "Epoch 396/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2210 - accuracy: 0.9242\n",
      "Epoch 396: val_accuracy did not improve from 0.93910\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2210 - accuracy: 0.9242 - val_loss: 0.2207 - val_accuracy: 0.9360\n",
      "Epoch 397/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2241 - accuracy: 0.9217\n",
      "Epoch 397: val_accuracy did not improve from 0.93910\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2241 - accuracy: 0.9217 - val_loss: 0.2233 - val_accuracy: 0.9376\n",
      "Epoch 398/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2257 - accuracy: 0.9217\n",
      "Epoch 398: val_accuracy did not improve from 0.93910\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2257 - accuracy: 0.9217 - val_loss: 0.2217 - val_accuracy: 0.9372\n",
      "Epoch 399/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2184 - accuracy: 0.9235\n",
      "Epoch 399: val_accuracy did not improve from 0.93910\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2184 - accuracy: 0.9235 - val_loss: 0.2203 - val_accuracy: 0.9364\n",
      "Epoch 400/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2217 - accuracy: 0.9236\n",
      "Epoch 400: val_accuracy did not improve from 0.93910\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2217 - accuracy: 0.9236 - val_loss: 0.2206 - val_accuracy: 0.9371\n",
      "Epoch 401/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2183 - accuracy: 0.9244\n",
      "Epoch 401: val_accuracy did not improve from 0.93910\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2183 - accuracy: 0.9244 - val_loss: 0.2202 - val_accuracy: 0.9387\n",
      "Epoch 402/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2231 - accuracy: 0.9219\n",
      "Epoch 402: val_accuracy did not improve from 0.93910\n",
      "195/195 [==============================] - 21s 105ms/step - loss: 0.2231 - accuracy: 0.9219 - val_loss: 0.2212 - val_accuracy: 0.9384\n",
      "Epoch 403/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2225 - accuracy: 0.9240\n",
      "Epoch 403: val_accuracy did not improve from 0.93910\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2225 - accuracy: 0.9240 - val_loss: 0.2202 - val_accuracy: 0.9376\n",
      "Epoch 404/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2215 - accuracy: 0.9228\n",
      "Epoch 404: val_accuracy did not improve from 0.93910\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2215 - accuracy: 0.9228 - val_loss: 0.2194 - val_accuracy: 0.9363\n",
      "Epoch 405/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2191 - accuracy: 0.9244\n",
      "Epoch 405: val_accuracy did not improve from 0.93910\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2191 - accuracy: 0.9244 - val_loss: 0.2216 - val_accuracy: 0.9371\n",
      "Epoch 406/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2222 - accuracy: 0.9230\n",
      "Epoch 406: val_accuracy did not improve from 0.93910\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2222 - accuracy: 0.9230 - val_loss: 0.2230 - val_accuracy: 0.9356\n",
      "Epoch 407/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2189 - accuracy: 0.9230\n",
      "Epoch 407: val_accuracy did not improve from 0.93910\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2189 - accuracy: 0.9230 - val_loss: 0.2215 - val_accuracy: 0.9381\n",
      "Epoch 408/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2246 - accuracy: 0.9228\n",
      "Epoch 408: val_accuracy did not improve from 0.93910\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2246 - accuracy: 0.9228 - val_loss: 0.2215 - val_accuracy: 0.9365\n",
      "Epoch 409/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2257 - accuracy: 0.9213\n",
      "Epoch 409: val_accuracy did not improve from 0.93910\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2257 - accuracy: 0.9213 - val_loss: 0.2241 - val_accuracy: 0.9356\n",
      "Epoch 410/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2197 - accuracy: 0.9228\n",
      "Epoch 410: val_accuracy did not improve from 0.93910\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2197 - accuracy: 0.9228 - val_loss: 0.2205 - val_accuracy: 0.9377\n",
      "Epoch 411/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2228 - accuracy: 0.9222\n",
      "Epoch 411: val_accuracy did not improve from 0.93910\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2228 - accuracy: 0.9222 - val_loss: 0.2219 - val_accuracy: 0.9374\n",
      "Epoch 412/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2228 - accuracy: 0.9218\n",
      "Epoch 412: val_accuracy did not improve from 0.93910\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2228 - accuracy: 0.9218 - val_loss: 0.2239 - val_accuracy: 0.9370\n",
      "Epoch 413/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2200 - accuracy: 0.9230\n",
      "Epoch 413: val_accuracy did not improve from 0.93910\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2200 - accuracy: 0.9230 - val_loss: 0.2201 - val_accuracy: 0.9373\n",
      "Epoch 414/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2231 - accuracy: 0.9230\n",
      "Epoch 414: val_accuracy did not improve from 0.93910\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2231 - accuracy: 0.9230 - val_loss: 0.2227 - val_accuracy: 0.9375\n",
      "Epoch 415/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2199 - accuracy: 0.9226\n",
      "Epoch 415: val_accuracy did not improve from 0.93910\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2199 - accuracy: 0.9226 - val_loss: 0.2206 - val_accuracy: 0.9380\n",
      "Epoch 416/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2205 - accuracy: 0.9230\n",
      "Epoch 416: val_accuracy did not improve from 0.93910\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2205 - accuracy: 0.9230 - val_loss: 0.2210 - val_accuracy: 0.9377\n",
      "Epoch 417/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2201 - accuracy: 0.9244\n",
      "Epoch 417: val_accuracy did not improve from 0.93910\n",
      "195/195 [==============================] - 21s 105ms/step - loss: 0.2201 - accuracy: 0.9244 - val_loss: 0.2235 - val_accuracy: 0.9363\n",
      "Epoch 418/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2243 - accuracy: 0.9228\n",
      "Epoch 418: val_accuracy did not improve from 0.93910\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2243 - accuracy: 0.9228 - val_loss: 0.2223 - val_accuracy: 0.9368\n",
      "Epoch 419/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2162 - accuracy: 0.9248\n",
      "Epoch 419: val_accuracy did not improve from 0.93910\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2162 - accuracy: 0.9248 - val_loss: 0.2221 - val_accuracy: 0.9377\n",
      "Epoch 420/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2200 - accuracy: 0.9229\n",
      "Epoch 420: val_accuracy did not improve from 0.93910\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2200 - accuracy: 0.9229 - val_loss: 0.2225 - val_accuracy: 0.9373\n",
      "Epoch 421/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2232 - accuracy: 0.9223\n",
      "Epoch 421: val_accuracy did not improve from 0.93910\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2232 - accuracy: 0.9223 - val_loss: 0.2221 - val_accuracy: 0.9372\n",
      "Epoch 422/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2221 - accuracy: 0.9235\n",
      "Epoch 422: val_accuracy did not improve from 0.93910\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2221 - accuracy: 0.9235 - val_loss: 0.2200 - val_accuracy: 0.9375\n",
      "Epoch 423/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2234 - accuracy: 0.9227\n",
      "Epoch 423: val_accuracy did not improve from 0.93910\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2234 - accuracy: 0.9227 - val_loss: 0.2216 - val_accuracy: 0.9372\n",
      "Epoch 424/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2216 - accuracy: 0.9242\n",
      "Epoch 424: val_accuracy improved from 0.93910 to 0.93970, saving model to best_model-r9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model-r9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 24s 120ms/step - loss: 0.2216 - accuracy: 0.9242 - val_loss: 0.2194 - val_accuracy: 0.9397\n",
      "Epoch 425/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2236 - accuracy: 0.9217\n",
      "Epoch 425: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 21s 104ms/step - loss: 0.2236 - accuracy: 0.9217 - val_loss: 0.2211 - val_accuracy: 0.9378\n",
      "Epoch 426/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2252 - accuracy: 0.9217\n",
      "Epoch 426: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 105ms/step - loss: 0.2252 - accuracy: 0.9217 - val_loss: 0.2229 - val_accuracy: 0.9367\n",
      "Epoch 427/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2228 - accuracy: 0.9217\n",
      "Epoch 427: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2228 - accuracy: 0.9217 - val_loss: 0.2226 - val_accuracy: 0.9371\n",
      "Epoch 428/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2250 - accuracy: 0.9208\n",
      "Epoch 428: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2250 - accuracy: 0.9208 - val_loss: 0.2224 - val_accuracy: 0.9370\n",
      "Epoch 429/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2212 - accuracy: 0.9233\n",
      "Epoch 429: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2212 - accuracy: 0.9233 - val_loss: 0.2225 - val_accuracy: 0.9381\n",
      "Epoch 430/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2213 - accuracy: 0.9219\n",
      "Epoch 430: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2213 - accuracy: 0.9219 - val_loss: 0.2274 - val_accuracy: 0.9375\n",
      "Epoch 431/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2180 - accuracy: 0.9252\n",
      "Epoch 431: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2180 - accuracy: 0.9252 - val_loss: 0.2223 - val_accuracy: 0.9367\n",
      "Epoch 432/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2174 - accuracy: 0.9241\n",
      "Epoch 432: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2174 - accuracy: 0.9241 - val_loss: 0.2219 - val_accuracy: 0.9357\n",
      "Epoch 433/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2206 - accuracy: 0.9236\n",
      "Epoch 433: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 105ms/step - loss: 0.2206 - accuracy: 0.9236 - val_loss: 0.2264 - val_accuracy: 0.9364\n",
      "Epoch 434/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2213 - accuracy: 0.9223\n",
      "Epoch 434: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 21s 105ms/step - loss: 0.2213 - accuracy: 0.9223 - val_loss: 0.2218 - val_accuracy: 0.9367\n",
      "Epoch 435/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2236 - accuracy: 0.9229\n",
      "Epoch 435: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2236 - accuracy: 0.9229 - val_loss: 0.2235 - val_accuracy: 0.9363\n",
      "Epoch 436/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2208 - accuracy: 0.9235\n",
      "Epoch 436: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2208 - accuracy: 0.9235 - val_loss: 0.2218 - val_accuracy: 0.9355\n",
      "Epoch 437/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2181 - accuracy: 0.9235\n",
      "Epoch 437: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2181 - accuracy: 0.9235 - val_loss: 0.2239 - val_accuracy: 0.9352\n",
      "Epoch 438/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2218 - accuracy: 0.9244\n",
      "Epoch 438: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2218 - accuracy: 0.9244 - val_loss: 0.2250 - val_accuracy: 0.9372\n",
      "Epoch 439/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2250 - accuracy: 0.9217\n",
      "Epoch 439: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2250 - accuracy: 0.9217 - val_loss: 0.2211 - val_accuracy: 0.9365\n",
      "Epoch 440/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2199 - accuracy: 0.9240\n",
      "Epoch 440: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2199 - accuracy: 0.9240 - val_loss: 0.2217 - val_accuracy: 0.9371\n",
      "Epoch 441/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2228 - accuracy: 0.9223\n",
      "Epoch 441: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2228 - accuracy: 0.9223 - val_loss: 0.2205 - val_accuracy: 0.9374\n",
      "Epoch 442/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2235 - accuracy: 0.9232\n",
      "Epoch 442: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2235 - accuracy: 0.9232 - val_loss: 0.2236 - val_accuracy: 0.9355\n",
      "Epoch 443/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2224 - accuracy: 0.9219\n",
      "Epoch 443: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2224 - accuracy: 0.9219 - val_loss: 0.2208 - val_accuracy: 0.9373\n",
      "Epoch 444/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2228 - accuracy: 0.9225\n",
      "Epoch 444: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2228 - accuracy: 0.9225 - val_loss: 0.2220 - val_accuracy: 0.9376\n",
      "Epoch 445/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2177 - accuracy: 0.9231\n",
      "Epoch 445: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2177 - accuracy: 0.9231 - val_loss: 0.2203 - val_accuracy: 0.9381\n",
      "Epoch 446/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2202 - accuracy: 0.9232\n",
      "Epoch 446: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2202 - accuracy: 0.9232 - val_loss: 0.2243 - val_accuracy: 0.9365\n",
      "Epoch 447/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2238 - accuracy: 0.9212\n",
      "Epoch 447: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2238 - accuracy: 0.9212 - val_loss: 0.2234 - val_accuracy: 0.9368\n",
      "Epoch 448/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2195 - accuracy: 0.9235\n",
      "Epoch 448: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2195 - accuracy: 0.9235 - val_loss: 0.2211 - val_accuracy: 0.9374\n",
      "Epoch 449/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2184 - accuracy: 0.9244\n",
      "Epoch 449: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 21s 105ms/step - loss: 0.2184 - accuracy: 0.9244 - val_loss: 0.2202 - val_accuracy: 0.9369\n",
      "Epoch 450/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2192 - accuracy: 0.9245\n",
      "Epoch 450: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2192 - accuracy: 0.9245 - val_loss: 0.2220 - val_accuracy: 0.9364\n",
      "Epoch 451/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2225 - accuracy: 0.9225\n",
      "Epoch 451: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2225 - accuracy: 0.9225 - val_loss: 0.2222 - val_accuracy: 0.9365\n",
      "Epoch 452/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2189 - accuracy: 0.9243\n",
      "Epoch 452: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2189 - accuracy: 0.9243 - val_loss: 0.2209 - val_accuracy: 0.9390\n",
      "Epoch 453/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2229 - accuracy: 0.9224\n",
      "Epoch 453: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2229 - accuracy: 0.9224 - val_loss: 0.2273 - val_accuracy: 0.9362\n",
      "Epoch 454/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2167 - accuracy: 0.9242\n",
      "Epoch 454: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2167 - accuracy: 0.9242 - val_loss: 0.2211 - val_accuracy: 0.9377\n",
      "Epoch 455/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2193 - accuracy: 0.9232\n",
      "Epoch 455: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2193 - accuracy: 0.9232 - val_loss: 0.2223 - val_accuracy: 0.9368\n",
      "Epoch 456/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2220 - accuracy: 0.9224\n",
      "Epoch 456: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 105ms/step - loss: 0.2220 - accuracy: 0.9224 - val_loss: 0.2243 - val_accuracy: 0.9362\n",
      "Epoch 457/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2189 - accuracy: 0.9240\n",
      "Epoch 457: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2189 - accuracy: 0.9240 - val_loss: 0.2238 - val_accuracy: 0.9365\n",
      "Epoch 458/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2224 - accuracy: 0.9229\n",
      "Epoch 458: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2224 - accuracy: 0.9229 - val_loss: 0.2224 - val_accuracy: 0.9370\n",
      "Epoch 459/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2174 - accuracy: 0.9250\n",
      "Epoch 459: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2174 - accuracy: 0.9250 - val_loss: 0.2229 - val_accuracy: 0.9371\n",
      "Epoch 460/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2201 - accuracy: 0.9227\n",
      "Epoch 460: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2201 - accuracy: 0.9227 - val_loss: 0.2231 - val_accuracy: 0.9361\n",
      "Epoch 461/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2211 - accuracy: 0.9232\n",
      "Epoch 461: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2211 - accuracy: 0.9232 - val_loss: 0.2219 - val_accuracy: 0.9371\n",
      "Epoch 462/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2148 - accuracy: 0.9242\n",
      "Epoch 462: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2148 - accuracy: 0.9242 - val_loss: 0.2228 - val_accuracy: 0.9369\n",
      "Epoch 463/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2200 - accuracy: 0.9229\n",
      "Epoch 463: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2200 - accuracy: 0.9229 - val_loss: 0.2230 - val_accuracy: 0.9366\n",
      "Epoch 464/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2211 - accuracy: 0.9227\n",
      "Epoch 464: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2211 - accuracy: 0.9227 - val_loss: 0.2232 - val_accuracy: 0.9374\n",
      "Epoch 465/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2195 - accuracy: 0.9241\n",
      "Epoch 465: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 105ms/step - loss: 0.2195 - accuracy: 0.9241 - val_loss: 0.2243 - val_accuracy: 0.9367\n",
      "Epoch 466/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2214 - accuracy: 0.9232\n",
      "Epoch 466: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2214 - accuracy: 0.9232 - val_loss: 0.2226 - val_accuracy: 0.9377\n",
      "Epoch 467/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2227 - accuracy: 0.9227\n",
      "Epoch 467: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2227 - accuracy: 0.9227 - val_loss: 0.2215 - val_accuracy: 0.9358\n",
      "Epoch 468/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2159 - accuracy: 0.9247\n",
      "Epoch 468: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2159 - accuracy: 0.9247 - val_loss: 0.2201 - val_accuracy: 0.9369\n",
      "Epoch 469/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2171 - accuracy: 0.9248\n",
      "Epoch 469: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2171 - accuracy: 0.9248 - val_loss: 0.2215 - val_accuracy: 0.9374\n",
      "Epoch 470/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2177 - accuracy: 0.9233\n",
      "Epoch 470: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2177 - accuracy: 0.9233 - val_loss: 0.2197 - val_accuracy: 0.9376\n",
      "Epoch 471/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2181 - accuracy: 0.9239\n",
      "Epoch 471: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2181 - accuracy: 0.9239 - val_loss: 0.2226 - val_accuracy: 0.9386\n",
      "Epoch 472/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2203 - accuracy: 0.9238\n",
      "Epoch 472: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2203 - accuracy: 0.9238 - val_loss: 0.2241 - val_accuracy: 0.9376\n",
      "Epoch 473/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2188 - accuracy: 0.9246\n",
      "Epoch 473: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2188 - accuracy: 0.9246 - val_loss: 0.2224 - val_accuracy: 0.9370\n",
      "Epoch 474/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2192 - accuracy: 0.9237\n",
      "Epoch 474: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2192 - accuracy: 0.9237 - val_loss: 0.2227 - val_accuracy: 0.9365\n",
      "Epoch 475/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2241 - accuracy: 0.9229\n",
      "Epoch 475: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2241 - accuracy: 0.9229 - val_loss: 0.2231 - val_accuracy: 0.9365\n",
      "Epoch 476/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2178 - accuracy: 0.9240\n",
      "Epoch 476: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2178 - accuracy: 0.9240 - val_loss: 0.2218 - val_accuracy: 0.9368\n",
      "Epoch 477/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2170 - accuracy: 0.9240\n",
      "Epoch 477: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2170 - accuracy: 0.9240 - val_loss: 0.2195 - val_accuracy: 0.9360\n",
      "Epoch 478/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2179 - accuracy: 0.9245\n",
      "Epoch 478: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2179 - accuracy: 0.9245 - val_loss: 0.2203 - val_accuracy: 0.9368\n",
      "Epoch 479/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2162 - accuracy: 0.9247\n",
      "Epoch 479: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2162 - accuracy: 0.9247 - val_loss: 0.2192 - val_accuracy: 0.9371\n",
      "Epoch 480/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2224 - accuracy: 0.9221\n",
      "Epoch 480: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 105ms/step - loss: 0.2224 - accuracy: 0.9221 - val_loss: 0.2200 - val_accuracy: 0.9356\n",
      "Epoch 481/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2143 - accuracy: 0.9257\n",
      "Epoch 481: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2143 - accuracy: 0.9257 - val_loss: 0.2230 - val_accuracy: 0.9368\n",
      "Epoch 482/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2157 - accuracy: 0.9250\n",
      "Epoch 482: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2157 - accuracy: 0.9250 - val_loss: 0.2227 - val_accuracy: 0.9372\n",
      "Epoch 483/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2227 - accuracy: 0.9221\n",
      "Epoch 483: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2227 - accuracy: 0.9221 - val_loss: 0.2211 - val_accuracy: 0.9370\n",
      "Epoch 484/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2197 - accuracy: 0.9232\n",
      "Epoch 484: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2197 - accuracy: 0.9232 - val_loss: 0.2244 - val_accuracy: 0.9351\n",
      "Epoch 485/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2134 - accuracy: 0.9271\n",
      "Epoch 485: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2134 - accuracy: 0.9271 - val_loss: 0.2196 - val_accuracy: 0.9372\n",
      "Epoch 486/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2197 - accuracy: 0.9234\n",
      "Epoch 486: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2197 - accuracy: 0.9234 - val_loss: 0.2210 - val_accuracy: 0.9364\n",
      "Epoch 487/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2203 - accuracy: 0.9232\n",
      "Epoch 487: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2203 - accuracy: 0.9232 - val_loss: 0.2233 - val_accuracy: 0.9357\n",
      "Epoch 488/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2203 - accuracy: 0.9226\n",
      "Epoch 488: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2203 - accuracy: 0.9226 - val_loss: 0.2245 - val_accuracy: 0.9351\n",
      "Epoch 489/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2161 - accuracy: 0.9248\n",
      "Epoch 489: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2161 - accuracy: 0.9248 - val_loss: 0.2224 - val_accuracy: 0.9361\n",
      "Epoch 490/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2167 - accuracy: 0.9242\n",
      "Epoch 490: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2167 - accuracy: 0.9242 - val_loss: 0.2225 - val_accuracy: 0.9358\n",
      "Epoch 491/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2239 - accuracy: 0.9226\n",
      "Epoch 491: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2239 - accuracy: 0.9226 - val_loss: 0.2201 - val_accuracy: 0.9364\n",
      "Epoch 492/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2224 - accuracy: 0.9224\n",
      "Epoch 492: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2224 - accuracy: 0.9224 - val_loss: 0.2201 - val_accuracy: 0.9365\n",
      "Epoch 493/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2200 - accuracy: 0.9236\n",
      "Epoch 493: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2200 - accuracy: 0.9236 - val_loss: 0.2213 - val_accuracy: 0.9379\n",
      "Epoch 494/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2191 - accuracy: 0.9237\n",
      "Epoch 494: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2191 - accuracy: 0.9237 - val_loss: 0.2225 - val_accuracy: 0.9353\n",
      "Epoch 495/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2179 - accuracy: 0.9224\n",
      "Epoch 495: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 21s 105ms/step - loss: 0.2179 - accuracy: 0.9224 - val_loss: 0.2239 - val_accuracy: 0.9352\n",
      "Epoch 496/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2156 - accuracy: 0.9255\n",
      "Epoch 496: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2156 - accuracy: 0.9255 - val_loss: 0.2229 - val_accuracy: 0.9374\n",
      "Epoch 497/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2235 - accuracy: 0.9223\n",
      "Epoch 497: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2235 - accuracy: 0.9223 - val_loss: 0.2238 - val_accuracy: 0.9366\n",
      "Epoch 498/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2190 - accuracy: 0.9250\n",
      "Epoch 498: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2190 - accuracy: 0.9250 - val_loss: 0.2234 - val_accuracy: 0.9355\n",
      "Epoch 499/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2180 - accuracy: 0.9236\n",
      "Epoch 499: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2180 - accuracy: 0.9236 - val_loss: 0.2206 - val_accuracy: 0.9367\n",
      "Epoch 500/500\n",
      "195/195 [==============================] - ETA: 0s - loss: 0.2136 - accuracy: 0.9262\n",
      "Epoch 500: val_accuracy did not improve from 0.93970\n",
      "195/195 [==============================] - 20s 104ms/step - loss: 0.2136 - accuracy: 0.9262 - val_loss: 0.2251 - val_accuracy: 0.9356\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Define the ModelCheckpoint callback to save the model using the 'SavedModel' format\n",
    "checkpoint = ModelCheckpoint('best_model-r9', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max', save_format='tf')\n",
    "\n",
    "# Initialize the generator with the custom augmentations\n",
    "custom_data_generator = CustomImageDataGenerator(x_train, y_train, batch_size=256, augmentations=custom_augmentations)\n",
    "\n",
    "# Train the model using the custom data generator\n",
    "history = model.fit(custom_data_generator,\n",
    "                    steps_per_epoch=len(x_train) // 256,\n",
    "                    epochs=500, \n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[checkpoint])  # Include both checkpoint and early stopping callbacks here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a489ca36-b642-4eee-8b72-e22ee2c1bf03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38d18e6-2009-466f-8fca-06e56c431fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model-r9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbeb53c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
